{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/christianhidber/easyagents/blob/master/jupyter_notebooks/intro_logging.ipynb\" \n",
    "   target=\"_parent\">\n",
    "   <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate an agents api calls, set seeds and fix juypter output cell clearing issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages (gym, tfagents, tensorflow,....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### suppress package warnings, in colab: load additional packages for rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "if 'google.colab' in sys.modules:\n",
    "    !apt-get update >/dev/null\n",
    "    !apt-get install xvfb >/dev/null\n",
    "    !pip install pyvirtualdisplay >/dev/null    \n",
    "    \n",
    "    from pyvirtualdisplay import Display\n",
    "    Display(visible=0, size=(960, 720)).start() \n",
    "else:\n",
    "    #  for local installation\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### install easyagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install easyagents >/dev/null    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent logging \n",
    "\n",
    "Use the log.Agent() callback to investigate how easyagents interacts with a backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "backend_name             tfagents \n",
      "TFPyEnvironment          ( suite_gym.load( \"CartPole-v0\", discount=1.0) ) \n",
      "AdamOptimizer            () \n",
      "ActorDistributionNetwork () \n",
      "ValueNetwork             () \n",
      "PpoAgent                 () \n",
      "tf_agent.initialize      () \n",
      "TFUniformReplayBuffer    () \n",
      "DynamicEpisodeDriver     () \n",
      "TFPyEnvironment          ( suite_gym.load( \"CartPole-v0\", discount=1) ) \n",
      "-----                    iteration    0 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=4509.4  [actor=0.1     critic=4509.3 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    1 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=4121.6  [actor=0.1     critic=4121.5 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    2 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=5926.7  [actor=0.1     critic=5926.6 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    3 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=10212.1 [actor=0.0     critic=10212.0] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    4 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=15431.0 [actor=0.0     critic=15431.0] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    5 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=5647.9  [actor=0.0     critic=5647.8 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    6 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=3748.3  [actor=0.0     critic=3748.2 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    7 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=20032.1 [actor=0.0     critic=20032.1] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    8 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=19072.9 [actor=0.0     critic=19072.9] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    9 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=3793.1  [actor=0.0     critic=3793.1 ] \n",
      "replay_buffer.clear      () \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<easyagents.core.PpoTrainContext at 0x2124b0d0048>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1224x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([log.Agent(), duration.Fast()], default_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots clear the jupyter cell ouput before each update thereby clearing the log output as well, thus we turned them off.\n",
    "Typically each call to the backend api during training is logged. \n",
    "Note that the logging starts with 'tfagents' the default backend for the PpoAgent.\n",
    "We then see a sequence of calls performing the Agent initialisation before we enter the train loop.\n",
    "Api calls during play or evaluation are not logged.\n",
    "\n",
    "Let's take a look at the tensorforce backend:\n",
    "\n",
    "**tensorforce and keras are suspended pending tensorflow 2.0 support**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "#ppoAgent = PpoAgent('CartPole-v0', backend='tensorforce')\n",
    "#ppoAgent.train([log.Agent(), duration.Fast()], default_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "While in tensorforce we also first do a sequence of agent and policy. Note that in contrast to tfagents we do not\n",
    "build up actor and critic policy networks but instead pass a network specification to the Agent.create call.\n",
    "Moreover tensorforce implements already the train loop through its Runner class. \n",
    "Thus we only see 1 call to runner.run instead of the many api calls for tfagents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Seeding\n",
    "\n",
    "To set a seed use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import easyagents\n",
    "\n",
    "easyagents.agents.seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once set, the seed is applied before each call to train. Let's validate this using our log.Agent callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "backend_name             tfagents \n",
      "tf.random.set_seed       (seed=0) \n",
      "numpy.random.seed        (0) \n",
      "random.seed              (0) \n",
      "TFPyEnvironment          ( suite_gym.load( \"CartPole-v0\", discount=1.0) ) \n",
      "AdamOptimizer            () \n",
      "ActorDistributionNetwork () \n",
      "ValueNetwork             () \n",
      "PpoAgent                 () \n",
      "tf_agent.initialize      () \n",
      "TFUniformReplayBuffer    () \n",
      "DynamicEpisodeDriver     () \n",
      "TFPyEnvironment          ( suite_gym.load( \"CartPole-v0\", discount=1) ) \n",
      "-----                    iteration    0 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=8528.5  [actor=0.0     critic=8528.5 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    1 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=5304.3  [actor=0.1     critic=5304.3 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    2 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=8645.1  [actor=0.0     critic=8645.0 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    3 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=9818.4  [actor=0.0     critic=9818.3 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    4 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=4630.6  [actor=0.1     critic=4630.6 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    5 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=11265.8 [actor=0.0     critic=11265.8] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    6 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=26230.5 [actor=0.0     critic=26230.4] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    7 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=5172.6  [actor=0.0     critic=5172.6 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    8 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=5563.0  [actor=0.1     critic=5562.9 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    9 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=26157.9 [actor=0.0     critic=26157.9] \n",
      "replay_buffer.clear      () \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<easyagents.core.PpoTrainContext at 0x21252676508>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1224x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([log.Agent(), duration.Fast()], default_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that at the very beginning the calls to set the seeds for tensorflow, numpy and python.\n",
    "\n",
    "## Iteration & Duration logging\n",
    "Use the log.Iteration() callback to log the training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration 0  of 10       episodes_done=0   steps_done=0     rewards=(50.0,50.0,50.0) steps=(50.0,50.0,50.0) \n",
      "iteration 1  of 10       episodes_done=3   steps_done=59    loss=8528.5  [actor=0.0     critic=8528.5 ] \n",
      "iteration 2  of 10       episodes_done=6   steps_done=114   loss=5304.3  [actor=0.1     critic=5304.3 ] \n",
      "iteration 3  of 10       episodes_done=9   steps_done=178   loss=8645.1  [actor=0.0     critic=8645.0 ] \n",
      "iteration 4  of 10       episodes_done=12  steps_done=244   loss=9818.4  [actor=0.0     critic=9818.3 ] rewards=(50.0,50.0,50.0) steps=(50.0,50.0,50.0) \n",
      "iteration 5  of 10       episodes_done=15  steps_done=288   loss=4630.6  [actor=0.1     critic=4630.6 ] \n",
      "iteration 6  of 10       episodes_done=18  steps_done=361   loss=11265.8 [actor=0.0     critic=11265.8] \n",
      "iteration 7  of 10       episodes_done=21  steps_done=476   loss=26230.5 [actor=0.0     critic=26230.4] \n",
      "iteration 8  of 10       episodes_done=24  steps_done=526   loss=5172.6  [actor=0.0     critic=5172.6 ] rewards=(50.0,50.0,50.0) steps=(50.0,50.0,50.0) \n",
      "iteration 9  of 10       episodes_done=27  steps_done=582   loss=5563.0  [actor=0.1     critic=5562.9 ] \n",
      "iteration 10 of 10       episodes_done=30  steps_done=690   loss=26157.9 [actor=0.0     critic=26157.9] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<easyagents.core.PpoTrainContext at 0x2124e339288>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1224x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([log.Iteration(), duration.Fast()], default_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first line shows the result of an initial policy evaluation depicting the policy's performance before any \n",
    "training has happend. Policy evaluation happens every `num_iterations_between_eval` iterations and spans over\n",
    "`num_episodes_per_eval` episodes. For every evaluation period the result is logged again. The `steps_done`value is \n",
    "the number of training steps (excluding the steps taken during evaluation). \n",
    "To see the training duration configuration use the log.Duration() callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "duration                 num_iterations=100 num_episodes_per_iteration=10 num_max_steps_per_episode=500 num_iterations_between_plot=2 num_iterations_between_eval=5 num_episodes_per_eval=10 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<easyagents.core.PpoTrainContext at 0x212540382c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1224x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([log.Duration(), duration.Fast()], default_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gym steps logging\n",
    "Use the log.Step() callback to investigate how the agent interacts with the gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:0  :1  ] train iteration=0  step=0   play  episode=0  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.04363321  0.24146826  0.01284913 -0.30946528]\n",
      "[CartPole-v0 9:0  :2  ] train iteration=0  step=0   play  episode=0  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[-0.03880385  0.04616562  0.00665982 -0.01275795]\n",
      "[CartPole-v0 9:0  :3  ] train iteration=0  step=0   play  episode=0  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[-0.03788053  0.24119143  0.00640466 -0.30333221]\n",
      "[CartPole-v0 9:0  :4  ] train iteration=0  step=0   play  episode=0  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[-0.03305671  0.04597879  0.00033802 -0.0086363 ]\n",
      "[CartPole-v0 9:0  :5  ] train iteration=0  step=0   play  episode=0  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[-3.21371306e-02  2.41095889e-01  1.65294467e-04 -3.01212554e-01]\n",
      "[CartPole-v0 9:0  :6  ] train iteration=0  step=0   play  episode=0  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[-0.02731521  0.04597158 -0.00585896 -0.0084775 ]\n",
      "[CartPole-v0 9:0  :7  ] train iteration=0  step=0   play  episode=0  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.02639578 -0.14906586 -0.00602851  0.28235111]\n",
      "[CartPole-v0 9:0  :8  ] train iteration=0  step=0   play  episode=0  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.0293771   0.04614156 -0.00038148 -0.01222707]\n",
      "[CartPole-v0 9:0  :9  ] train iteration=0  step=0   play  episode=0  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[-0.02845427  0.24126898 -0.00062603 -0.30503033]\n",
      "[CartPole-v0 9:0  :10 ] train iteration=0  step=0   play  episode=0  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[-0.02362889  0.04615596 -0.00672663 -0.0125449 ]\n",
      "[CartPole-v0 9:0  :11 ] train iteration=0  step=0   play  episode=0  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.02270577 -0.14886888 -0.00697753  0.27800812]\n",
      "[CartPole-v0 9:0  :12 ] train iteration=0  step=0   play  episode=0  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.02568315  0.04635191 -0.00141737 -0.01686732]\n",
      "[CartPole-v0 9:0  :13 ] train iteration=0  step=0   play  episode=0  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.02475611 -0.14874968 -0.00175471  0.27536807]\n",
      "[CartPole-v0 9:0  :14 ] train iteration=0  step=0   play  episode=0  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.0277311   0.04639726  0.00375265 -0.01786777]\n",
      "[CartPole-v0 9:0  :15 ] train iteration=0  step=0   play  episode=0  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[-0.02680316 -0.14877831  0.00339529  0.27599679]\n",
      "[CartPole-v0 9:0  :16 ] train iteration=0  step=0   play  episode=0  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[-0.02977872  0.04629504  0.00891523 -0.01561333]\n",
      "[CartPole-v0 9:0  :17 ] train iteration=0  step=0   play  episode=0  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=1 observation=[-0.02885282  0.24128801  0.00860296 -0.30547012]\n",
      "[CartPole-v0 9:0  :18 ] train iteration=0  step=0   play  episode=0  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=0 observation=[-0.02402706  0.04604452  0.00249356 -0.01008649]\n",
      "[CartPole-v0 9:0  :19 ] train iteration=0  step=0   play  episode=0  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[-0.02310617  0.24113063  0.00229183 -0.30198163]\n",
      "[CartPole-v0 9:0  :20 ] train iteration=0  step=0   play  episode=0  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=0 observation=[-0.01828356  0.04597609 -0.0037478  -0.00857679]\n",
      "[CartPole-v0 9:0  :21 ] train iteration=0  step=0   play  episode=0  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.01736404 -0.14909192 -0.00391934  0.28292131]\n",
      "[CartPole-v0 9:0  :22 ] train iteration=0  step=0   play  episode=0  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.02034587  0.04608572  0.00173909 -0.01099517]\n",
      "[CartPole-v0 9:0  :23 ] train iteration=0  step=0   play  episode=0  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.01942416 -0.14906113  0.00151918  0.28223595]\n",
      "[CartPole-v0 9:0  :24 ] train iteration=0  step=0   play  episode=0  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[-0.02240538  0.04603912  0.0071639  -0.00996745]\n",
      "[CartPole-v0 9:0  :25 ] train iteration=0  step=0   play  episode=0  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[-0.0214846   0.2410576   0.00696455 -0.3003815 ]\n",
      "[CartPole-v0 9:0  :26 ] train iteration=0  step=0   play  episode=0  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[-0.01666345  0.04583708  0.00095692 -0.00551025]\n",
      "[CartPole-v0 9:0  :27 ] train iteration=0  step=0   play  episode=0  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[-0.01574671 -0.14929859  0.00084672  0.28747444]\n",
      "[CartPole-v0 9:0  :28 ] train iteration=0  step=0   play  episode=0  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[-0.01873268  0.04581128  0.00659621 -0.00494132]\n",
      "[CartPole-v0 9:0  :29 ] train iteration=0  step=0   play  episode=0  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[-0.01781645  0.24083801  0.00649738 -0.29553578]\n",
      "[CartPole-v0 9:0  :30 ] train iteration=0  step=0   play  episode=0  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[-0.01299969  0.04562404  0.00058667 -0.00081078]\n",
      "[CartPole-v0 9:0  :31 ] train iteration=0  step=0   play  episode=0  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[-0.01208721  0.24073757  0.00057045 -0.29330855]\n",
      "[CartPole-v0 9:0  :32 ] train iteration=0  step=0   play  episode=0  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[-0.00727246  0.04560749 -0.00529572 -0.00044577]\n",
      "[CartPole-v0 9:0  :33 ] train iteration=0  step=0   play  episode=0  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[-0.00636031 -0.14943811 -0.00530464  0.2905616 ]\n",
      "[CartPole-v0 9:0  :34 ] train iteration=0  step=0   play  episode=0  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[-0.00934907  0.04575908  0.0005066  -0.00378962]\n",
      "[CartPole-v0 9:0  :35 ] train iteration=0  step=0   play  episode=0  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[-0.00843389 -0.14937014  0.0004308   0.2890531 ]\n",
      "[CartPole-v0 9:0  :36 ] train iteration=0  step=0   play  episode=0  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[-0.01142129  0.04574567  0.00621186 -0.00349392]\n",
      "[CartPole-v0 9:0  :37 ] train iteration=0  step=0   play  episode=0  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.01050638  0.24077799  0.00614199 -0.29421048]\n",
      "[CartPole-v0 9:0  :38 ] train iteration=0  step=0   play  episode=0  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.00569082  0.04556901  0.00025778  0.0004032 ]\n",
      "[CartPole-v0 9:0  :39 ] train iteration=0  step=0   play  episode=0  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-4.77944066e-03  2.40687262e-01  2.65840718e-04 -2.92198385e-01]\n",
      "[CartPole-v0 9:0  :40 ] train iteration=0  step=0   play  episode=0  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[ 3.43045783e-05  4.55615213e-02 -5.57812698e-03  5.68372760e-04]\n",
      "[CartPole-v0 9:0  :41 ] train iteration=0  step=0   play  episode=0  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[ 0.00094554 -0.14947999 -0.00556676  0.29148613]\n",
      "[CartPole-v0 9:0  :42 ] train iteration=0  step=0   play  episode=0  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[-0.00204406  0.04572089  0.00026296 -0.00294728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:0  :43 ] train iteration=0  step=0   play  episode=0  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[-1.12964693e-03 -1.49404829e-01  2.04017434e-04  2.89818605e-01]\n",
      "[CartPole-v0 9:0  :44 ] train iteration=0  step=0   play  episode=0  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[-0.00411774  0.04571421  0.00600039 -0.00279997]\n",
      "[CartPole-v0 9:0  :45 ] train iteration=0  step=0   play  episode=0  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.00320346  0.2407496   0.00594439 -0.29358368]\n",
      "[CartPole-v0 9:0  :46 ] train iteration=0  step=0   play  episode=0  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[1.61153266e-03 4.55434012e-02 7.27166229e-05 9.68084346e-04]\n",
      "[CartPole-v0 9:0  :47 ] train iteration=0  step=0   play  episode=0  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[ 2.52240068e-03  2.40664309e-01  9.20783098e-05 -2.91691899e-01]\n",
      "[CartPole-v0 9:0  :48 ] train iteration=0  step=0   play  episode=0  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[ 0.00733569  0.04554105 -0.00574176  0.00102007]\n",
      "[CartPole-v0 9:0  :49 ] train iteration=0  step=0   play  episode=0  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[ 0.00824651 -0.14949809 -0.00572136  0.29188588]\n",
      "[CartPole-v0 9:1  :50 ] train iteration=0  step=0   play  episode=0  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.00525655  0.04570497  0.00011636 -0.00259598]\n",
      "[CartPole-v0 9:1  :1  ] train iteration=0  step=0   play  episode=1  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.03940542  0.21258198 -0.01040263 -0.2790682 ]\n",
      "[CartPole-v0 9:1  :2  ] train iteration=0  step=0   play  episode=1  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[-0.03515378  0.01760996 -0.015984    0.01031569]\n",
      "[CartPole-v0 9:1  :3  ] train iteration=0  step=0   play  episode=1  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[-0.03480158  0.21295746 -0.01577768 -0.28736722]\n",
      "[CartPole-v0 9:1  :4  ] train iteration=0  step=0   play  episode=1  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[-0.03054243  0.01806402 -0.02152503  0.0002981 ]\n",
      "[CartPole-v0 9:1  :5  ] train iteration=0  step=0   play  episode=1  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[-0.03018115  0.21348795 -0.02151907 -0.29909776]\n",
      "[CartPole-v0 9:1  :6  ] train iteration=0  step=0   play  episode=1  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[-0.02591139  0.01867924 -0.02750102 -0.01327846]\n",
      "[CartPole-v0 9:1  :7  ] train iteration=0  step=0   play  episode=1  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.02553781 -0.17603773 -0.02776659  0.27060228]\n",
      "[CartPole-v0 9:1  :8  ] train iteration=0  step=0   play  episode=1  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.02905856  0.01946922 -0.02235455 -0.03070743]\n",
      "[CartPole-v0 9:1  :9  ] train iteration=0  step=0   play  episode=1  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.02866918 -0.17532514 -0.02296869  0.25483941]\n",
      "[CartPole-v0 9:1  :10 ] train iteration=0  step=0   play  episode=1  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.03217568  0.0201171  -0.01787191 -0.04499883]\n",
      "[CartPole-v0 9:1  :11 ] train iteration=0  step=0   play  episode=1  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.03177334 -0.17474408 -0.01877188  0.2419922 ]\n",
      "[CartPole-v0 9:1  :12 ] train iteration=0  step=0   play  episode=1  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.03526822  0.02064091 -0.01393204 -0.05655226]\n",
      "[CartPole-v0 9:1  :13 ] train iteration=0  step=0   play  episode=1  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.0348554  -0.17427853 -0.01506308  0.23170265]\n",
      "[CartPole-v0 9:1  :14 ] train iteration=0  step=0   play  episode=1  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.03834097  0.02105538 -0.01042903 -0.06569336]\n",
      "[CartPole-v0 9:1  :15 ] train iteration=0  step=0   play  episode=1  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[-0.03791987  0.21632529 -0.0117429  -0.36164838]\n",
      "[CartPole-v0 9:1  :16 ] train iteration=0  step=0   play  episode=1  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[-0.03359336  0.0213722  -0.01897587 -0.07269124]\n",
      "[CartPole-v0 9:1  :17 ] train iteration=0  step=0   play  episode=1  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.03316592 -0.17347264 -0.02042969  0.21394483]\n",
      "[CartPole-v0 9:1  :18 ] train iteration=0  step=0   play  episode=1  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.03663537  0.02193535 -0.01615079 -0.08511189]\n",
      "[CartPole-v0 9:1  :19 ] train iteration=0  step=0   play  episode=1  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[-0.03619666  0.21728504 -0.01785303 -0.38284634]\n",
      "[CartPole-v0 9:1  :20 ] train iteration=0  step=0   play  episode=1  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=0 observation=[-0.03185096  0.02242107 -0.02550996 -0.09584547]\n",
      "[CartPole-v0 9:1  :21 ] train iteration=0  step=0   play  episode=1  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=1 observation=[-0.03140254  0.21789917 -0.02742687 -0.39646635]\n",
      "[CartPole-v0 9:1  :22 ] train iteration=0  step=0   play  episode=1  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=0 observation=[-0.02704456  0.02317688 -0.03535619 -0.11255524]\n",
      "[CartPole-v0 9:1  :23 ] train iteration=0  step=0   play  episode=1  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=1 observation=[-0.02658102  0.21878714 -0.0376073  -0.41617982]\n",
      "[CartPole-v0 9:1  :24 ] train iteration=0  step=0   play  episode=1  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=0 observation=[-0.02220528  0.0242178  -0.0459309  -0.13558611]\n",
      "[CartPole-v0 9:1  :25 ] train iteration=0  step=0   play  episode=1  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[-0.02172092  0.21996652 -0.04864262 -0.44239846]\n",
      "[CartPole-v0 9:1  :26 ] train iteration=0  step=0   play  episode=1  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[-0.01732159  0.02556542 -0.05749059 -0.16543701]\n",
      "[CartPole-v0 9:1  :27 ] train iteration=0  step=0   play  episode=1  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=1 observation=[-0.01681028  0.2214612  -0.06079933 -0.47568814]\n",
      "[CartPole-v0 9:1  :28 ] train iteration=0  step=0   play  episode=1  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[-0.01238106  0.02724811 -0.07031309 -0.20277076]\n",
      "[CartPole-v0 9:1  :29 ] train iteration=0  step=0   play  episode=1  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[-0.0118361  -0.16680151 -0.07436851  0.06692941]\n",
      "[CartPole-v0 9:1  :30 ] train iteration=0  step=0   play  episode=1  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[-0.01517213  0.02930353 -0.07302992 -0.24825926]\n",
      "[CartPole-v0 9:1  :31 ] train iteration=0  step=0   play  episode=1  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[-0.01458606 -0.1647036  -0.0779951   0.02052402]\n",
      "[CartPole-v0 9:1  :32 ] train iteration=0  step=0   play  episode=1  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[-0.01788013  0.03144522 -0.07758462 -0.29571207]\n",
      "[CartPole-v0 9:1  :33 ] train iteration=0  step=0   play  episode=1  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[-0.01725122 -0.16248988 -0.08349886 -0.0284715 ]\n",
      "[CartPole-v0 9:1  :34 ] train iteration=0  step=0   play  episode=1  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[-0.02050102 -0.3563213  -0.08406829  0.23674252]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:1  :35 ] train iteration=0  step=0   play  episode=1  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.02762745 -0.16010519 -0.07933344 -0.08122918]\n",
      "[CartPole-v0 9:1  :36 ] train iteration=0  step=0   play  episode=1  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.03082955 -0.35400555 -0.08095803  0.18540699]\n",
      "[CartPole-v0 9:1  :37 ] train iteration=0  step=0   play  episode=1  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.03790966 -0.1578242  -0.07724989 -0.13167687]\n",
      "[CartPole-v0 9:1  :38 ] train iteration=0  step=0   play  episode=1  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.04106615 -0.35175947 -0.07988342  0.1356696 ]\n",
      "[CartPole-v0 9:1  :39 ] train iteration=0  step=0   play  episode=1  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.04810133 -0.15558958 -0.07717003 -0.18110763]\n",
      "[CartPole-v0 9:1  :40 ] train iteration=0  step=0   play  episode=1  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.05121313 -0.34952731 -0.08079218  0.08626772]\n",
      "[CartPole-v0 9:1  :41 ] train iteration=0  step=0   play  episode=1  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[-0.05820367 -0.1533458  -0.07906683 -0.23077172]\n",
      "[CartPole-v0 9:1  :42 ] train iteration=0  step=0   play  episode=1  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[-0.06127059 -0.34725412 -0.08368226  0.03596063]\n",
      "[CartPole-v0 9:1  :43 ] train iteration=0  step=0   play  episode=1  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[-0.06821567 -0.15103805 -0.08296305 -0.28190743]\n",
      "[CartPole-v0 9:1  :44 ] train iteration=0  step=0   play  episode=1  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[-0.07123643 -0.34488467 -0.0886012  -0.01650076]\n",
      "[CartPole-v0 9:1  :45 ] train iteration=0  step=0   play  episode=1  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.07813413 -0.14861115 -0.08893122 -0.33577089]\n",
      "[CartPole-v0 9:1  :46 ] train iteration=0  step=0   play  episode=1  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.08110635 -0.34236236 -0.09564663 -0.0724039 ]\n",
      "[CartPole-v0 9:1  :47 ] train iteration=0  step=0   play  episode=1  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[-0.0879536  -0.53599222 -0.09709471  0.18863611]\n",
      "[CartPole-v0 9:1  :48 ] train iteration=0  step=0   play  episode=1  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[-0.09867344 -0.33962492 -0.09332199 -0.13302852]\n",
      "[CartPole-v0 9:1  :49 ] train iteration=0  step=0   play  episode=1  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[-0.10546594 -0.5332948  -0.09598256  0.12881536]\n",
      "[CartPole-v0 9:2  :50 ] train iteration=0  step=0   play  episode=1  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[-0.11613183 -0.33693827 -0.09340625 -0.19253932]\n",
      "[CartPole-v0 9:2  :1  ] train iteration=0  step=0   play  episode=2  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.04396213  0.19844869 -0.04501504 -0.25903102]\n",
      "[CartPole-v0 9:2  :2  ] train iteration=0  step=0   play  episode=2  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[-0.03999315  0.00399731 -0.05019566  0.01912062]\n",
      "[CartPole-v0 9:2  :3  ] train iteration=0  step=0   play  episode=2  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[-0.03991321  0.19980185 -0.04981325 -0.28896758]\n",
      "[CartPole-v0 9:2  :4  ] train iteration=0  step=0   play  episode=2  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[-0.03591717  0.00542432 -0.0555926  -0.01240199]\n",
      "[CartPole-v0 9:2  :5  ] train iteration=0  step=0   play  episode=2  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[-0.03580869 -0.18885812 -0.05584064  0.26223564]\n",
      "[CartPole-v0 9:2  :6  ] train iteration=0  step=0   play  episode=2  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[-0.03958585  0.00701462 -0.05059593 -0.04752413]\n",
      "[CartPole-v0 9:2  :7  ] train iteration=0  step=0   play  episode=2  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.03944556 -0.18734669 -0.05154641  0.22877589]\n",
      "[CartPole-v0 9:2  :8  ] train iteration=0  step=0   play  episode=2  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.04319249  0.00847254 -0.04697089 -0.07971075]\n",
      "[CartPole-v0 9:2  :9  ] train iteration=0  step=0   play  episode=2  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.04302304 -0.1859457  -0.04856511  0.1977906 ]\n",
      "[CartPole-v0 9:2  :10 ] train iteration=0  step=0   play  episode=2  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.04674195  0.00983604 -0.0446093  -0.10980828]\n",
      "[CartPole-v0 9:2  :11 ] train iteration=0  step=0   play  episode=2  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.04654523 -0.18461923 -0.04680546  0.16847366]\n",
      "[CartPole-v0 9:2  :12 ] train iteration=0  step=0   play  episode=2  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.05023762  0.01114035 -0.04343599 -0.1385999 ]\n",
      "[CartPole-v0 9:2  :13 ] train iteration=0  step=0   play  episode=2  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.05001481 -0.18333343 -0.04620799  0.14006947]\n",
      "[CartPole-v0 9:2  :14 ] train iteration=0  step=0   play  episode=2  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.05368148  0.01241882 -0.0434066  -0.16682581]\n",
      "[CartPole-v0 9:2  :15 ] train iteration=0  step=0   play  episode=2  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[-0.0534331   0.20813436 -0.04674311 -0.47288013]\n",
      "[CartPole-v0 9:2  :16 ] train iteration=0  step=0   play  episode=2  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[-0.04927041  0.01370267 -0.05620072 -0.19528861]\n",
      "[CartPole-v0 9:2  :17 ] train iteration=0  step=0   play  episode=2  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.04899636 -0.18057222 -0.06010649  0.0791493 ]\n",
      "[CartPole-v0 9:2  :18 ] train iteration=0  step=0   play  episode=2  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.05260781  0.01535757 -0.0585235  -0.23187532]\n",
      "[CartPole-v0 9:2  :19 ] train iteration=0  step=0   play  episode=2  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[-0.05230065 -0.17888143 -0.06316101  0.04178828]\n",
      "[CartPole-v0 9:2  :20 ] train iteration=0  step=0   play  episode=2  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[-0.05587828  0.0170867  -0.06232524 -0.27013477]\n",
      "[CartPole-v0 9:2  :21 ] train iteration=0  step=0   play  episode=2  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.05553655 -0.17709304 -0.06772794  0.00225755]\n",
      "[CartPole-v0 9:2  :22 ] train iteration=0  step=0   play  episode=2  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.05907841  0.01893157 -0.06768279 -0.31100203]\n",
      "[CartPole-v0 9:2  :23 ] train iteration=0  step=0   play  episode=2  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.05869978 -0.1751641  -0.07390283 -0.04040868]\n",
      "[CartPole-v0 9:2  :24 ] train iteration=0  step=0   play  episode=2  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=0 observation=[-0.06220306 -0.36915276 -0.074711    0.2280724 ]\n",
      "[CartPole-v0 9:2  :25 ] train iteration=0  step=0   play  episode=2  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[-0.06958611 -0.17304706 -0.07014955 -0.08721018]\n",
      "[CartPole-v0 9:2  :26 ] train iteration=0  step=0   play  episode=2  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[-0.07304706 -0.36709702 -0.07189376  0.18254181]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:2  :27 ] train iteration=0  step=0   play  episode=2  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=1 observation=[-0.080389   -0.17102392 -0.06824292 -0.13192664]\n",
      "[CartPole-v0 9:2  :28 ] train iteration=0  step=0   play  episode=2  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[-0.08380947 -0.36510533 -0.07088145  0.13846999]\n",
      "[CartPole-v0 9:2  :29 ] train iteration=0  step=0   play  episode=2  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[-0.09111158 -0.16904352 -0.06811205 -0.17570595]\n",
      "[CartPole-v0 9:2  :30 ] train iteration=0  step=0   play  episode=2  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[-0.09449245 -0.36312793 -0.07162617  0.09473616]\n",
      "[CartPole-v0 9:2  :31 ] train iteration=0  step=0   play  episode=2  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[-0.10175501 -0.16705637 -0.06973145 -0.21965717]\n",
      "[CartPole-v0 9:2  :32 ] train iteration=0  step=0   play  episode=2  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[-0.10509614 -0.36111585 -0.07412459  0.0502402 ]\n",
      "[CartPole-v0 9:2  :33 ] train iteration=0  step=0   play  episode=2  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=1 observation=[-0.11231845 -0.16501361 -0.07311979 -0.2648781 ]\n",
      "[CartPole-v0 9:2  :34 ] train iteration=0  step=0   play  episode=2  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[-0.11561873 -0.35901989 -0.07841735  0.00387565]\n",
      "[CartPole-v0 9:2  :35 ] train iteration=0  step=0   play  episode=2  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.12279912 -0.16286601 -0.07833984 -0.31248207]\n",
      "[CartPole-v0 9:2  :36 ] train iteration=0  step=0   play  episode=2  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.12605645 -0.35678959 -0.08458948 -0.0454972 ]\n",
      "[CartPole-v0 9:2  :37 ] train iteration=0  step=0   play  episode=2  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.13319224 -0.16056295 -0.08549942 -0.3636244 ]\n",
      "[CartPole-v0 9:2  :38 ] train iteration=0  step=0   play  episode=2  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.1364035  -0.35437228 -0.09277191 -0.09907855]\n",
      "[CartPole-v0 9:2  :39 ] train iteration=0  step=0   play  episode=2  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[-0.14349094 -0.54805063 -0.09475348  0.16295386]\n",
      "[CartPole-v0 9:2  :40 ] train iteration=0  step=0   play  episode=2  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[-0.15445195 -0.35170895 -0.09149441 -0.15805342]\n",
      "[CartPole-v0 9:2  :41 ] train iteration=0  step=0   play  episode=2  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[-0.16148613 -0.54540996 -0.09465547  0.10442097]\n",
      "[CartPole-v0 9:2  :42 ] train iteration=0  step=0   play  episode=2  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[-0.17239433 -0.34906794 -0.09256706 -0.21656084]\n",
      "[CartPole-v0 9:2  :43 ] train iteration=0  step=0   play  episode=2  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[-0.17937569 -0.54275306 -0.09689827  0.04554713]\n",
      "[CartPole-v0 9:2  :44 ] train iteration=0  step=0   play  episode=2  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[-0.19023075 -0.34638481 -0.09598733 -0.27606704]\n",
      "[CartPole-v0 9:2  :45 ] train iteration=0  step=0   play  episode=2  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=0 observation=[-0.19715845 -0.54001559 -0.10150867 -0.01513482]\n",
      "[CartPole-v0 9:2  :46 ] train iteration=0  step=0   play  episode=2  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=1 observation=[-0.20795876 -0.34359544 -0.10181137 -0.33804074]\n",
      "[CartPole-v0 9:2  :47 ] train iteration=0  step=0   play  episode=2  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[-0.21483067 -0.53713238 -0.10857218 -0.07911946]\n",
      "[CartPole-v0 9:2  :48 ] train iteration=0  step=0   play  episode=2  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[-0.22557332 -0.34063504 -0.11015457 -0.40398751]\n",
      "[CartPole-v0 9:2  :49 ] train iteration=0  step=0   play  episode=2  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[-0.23238602 -0.53403644 -0.11823432 -0.14796367]\n",
      "[CartPole-v0 9:3  :50 ] train iteration=0  step=0   play  episode=2  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.24306675 -0.72728427 -0.12119359  0.10520436]\n",
      "[CartPole-v0 8:0  :1  ] train iteration=0  step=1    reward=1.0   done=False action=1 observation=[-0.04363321  0.24146826  0.01284913 -0.30946528]\n",
      "[CartPole-v0 8:0  :2  ] train iteration=0  step=2    reward=1.0   done=False action=0 observation=[-0.03880385  0.04616562  0.00665982 -0.01275795]\n",
      "[CartPole-v0 8:0  :3  ] train iteration=0  step=3    reward=1.0   done=False action=0 observation=[-0.03788053 -0.14905121  0.00640466  0.28201876]\n",
      "[CartPole-v0 8:0  :4  ] train iteration=0  step=4    reward=1.0   done=False action=0 observation=[-0.04086156 -0.34426393  0.01204504  0.57671479]\n",
      "[CartPole-v0 8:0  :5  ] train iteration=0  step=5    reward=1.0   done=False action=1 observation=[-0.04774684 -0.14931286  0.02357934  0.28785057]\n",
      "[CartPole-v0 8:0  :6  ] train iteration=0  step=6    reward=1.0   done=False action=0 observation=[-0.05073309 -0.344763    0.02933635  0.58787595]\n",
      "[CartPole-v0 8:0  :7  ] train iteration=0  step=7    reward=1.0   done=False action=1 observation=[-0.05762835 -0.1500639   0.04109387  0.30457661]\n",
      "[CartPole-v0 8:0  :8  ] train iteration=0  step=8    reward=1.0   done=False action=0 observation=[-0.06062963 -0.34574665  0.0471854   0.60993113]\n",
      "[CartPole-v0 8:0  :9  ] train iteration=0  step=9    reward=1.0   done=False action=1 observation=[-0.06754457 -0.15131493  0.05938402  0.33247553]\n",
      "[CartPole-v0 8:0  :10 ] train iteration=0  step=10   reward=1.0   done=False action=0 observation=[-0.07057086 -0.34722964  0.06603353  0.64327823]\n",
      "[CartPole-v0 8:0  :11 ] train iteration=0  step=11   reward=1.0   done=False action=0 observation=[-0.07751546 -0.54320678  0.0788991   0.95600302]\n",
      "[CartPole-v0 8:0  :12 ] train iteration=0  step=12   reward=1.0   done=False action=0 observation=[-0.08837959 -0.73929616  0.09801916  1.27239434]\n",
      "[CartPole-v0 8:0  :13 ] train iteration=0  step=13   reward=1.0   done=False action=1 observation=[-0.10316552 -0.54555216  0.12346704  1.0119448 ]\n",
      "[CartPole-v0 8:0  :14 ] train iteration=0  step=14   reward=1.0   done=False action=0 observation=[-0.11407656 -0.74208572  0.14370594  1.34070818]\n",
      "[CartPole-v0 8:0  :15 ] train iteration=0  step=15   reward=1.0   done=False action=1 observation=[-0.12891827 -0.54903504  0.1705201   1.09622135]\n",
      "[CartPole-v0 8:0  :16 ] train iteration=0  step=16   reward=1.0   done=False action=1 observation=[-0.13989897 -0.35651816  0.19244453  0.86152456]\n",
      "[CartPole-v0 8:1  :17 ] train iteration=0  step=17   reward=1.0   done=True  action=0 observation=[-0.14702934 -0.55366623  0.20967502  1.20801763]\n",
      "[CartPole-v0 8:1  :1  ] train iteration=0  step=18   reward=1.0   done=False action=1 observation=[-0.03940542  0.21258198 -0.01040263 -0.2790682 ]\n",
      "[CartPole-v0 8:1  :2  ] train iteration=0  step=19   reward=1.0   done=False action=0 observation=[-0.03515378  0.01760996 -0.015984    0.01031569]\n",
      "[CartPole-v0 8:1  :3  ] train iteration=0  step=20   reward=1.0   done=False action=1 observation=[-0.03480158  0.21295746 -0.01577768 -0.28736722]\n",
      "[CartPole-v0 8:1  :4  ] train iteration=0  step=21   reward=1.0   done=False action=0 observation=[-0.03054243  0.01806402 -0.02152503  0.0002981 ]\n",
      "[CartPole-v0 8:1  :5  ] train iteration=0  step=22   reward=1.0   done=False action=0 observation=[-0.03018115 -0.17674272 -0.02151907  0.28611266]\n",
      "[CartPole-v0 8:1  :6  ] train iteration=0  step=23   reward=1.0   done=False action=1 observation=[-0.03371601  0.01867941 -0.01579681 -0.01327879]\n",
      "[CartPole-v0 8:1  :7  ] train iteration=0  step=24   reward=1.0   done=False action=1 observation=[-0.03334242  0.2140243  -0.01606239 -0.31090364]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:1  :8  ] train iteration=0  step=25   reward=1.0   done=False action=0 observation=[-0.02906193  0.01913484 -0.02228046 -0.02332929]\n",
      "[CartPole-v0 8:1  :9  ] train iteration=0  step=26   reward=1.0   done=False action=1 observation=[-0.02867924  0.21456911 -0.02274705 -0.32295785]\n",
      "[CartPole-v0 8:1  :10 ] train iteration=0  step=27   reward=1.0   done=False action=1 observation=[-0.02438785  0.41000746 -0.0292062  -0.62272659]\n",
      "[CartPole-v0 8:1  :11 ] train iteration=0  step=28   reward=1.0   done=False action=0 observation=[-0.01618771  0.21530523 -0.04166074 -0.3393832 ]\n",
      "[CartPole-v0 8:1  :12 ] train iteration=0  step=29   reward=1.0   done=False action=1 observation=[-0.0118816   0.41099445 -0.0484484  -0.64490705]\n",
      "[CartPole-v0 8:1  :13 ] train iteration=0  step=30   reward=1.0   done=False action=0 observation=[-0.00366171  0.21657994 -0.06134654 -0.36786574]\n",
      "[CartPole-v0 8:1  :14 ] train iteration=0  step=31   reward=1.0   done=False action=0 observation=[ 0.00066989  0.0223809  -0.06870386 -0.09513971]\n",
      "[CartPole-v0 8:1  :15 ] train iteration=0  step=32   reward=1.0   done=False action=0 observation=[ 0.00111751 -0.17169252 -0.07060665  0.17510058]\n",
      "[CartPole-v0 8:1  :16 ] train iteration=0  step=33   reward=1.0   done=False action=1 observation=[-0.00231635  0.02436517 -0.06710464 -0.1389943 ]\n",
      "[CartPole-v0 8:1  :17 ] train iteration=0  step=34   reward=1.0   done=False action=0 observation=[-0.00182904 -0.1697347  -0.06988452  0.13178625]\n",
      "[CartPole-v0 8:1  :18 ] train iteration=0  step=35   reward=1.0   done=False action=0 observation=[-0.00522374 -0.36378961 -0.0672488   0.40162878]\n",
      "[CartPole-v0 8:1  :19 ] train iteration=0  step=36   reward=1.0   done=False action=1 observation=[-0.01249953 -0.16778146 -0.05921622  0.08852487]\n",
      "[CartPole-v0 8:1  :20 ] train iteration=0  step=37   reward=1.0   done=False action=1 observation=[-0.01585516  0.0281371  -0.05744573 -0.22223726]\n",
      "[CartPole-v0 8:1  :21 ] train iteration=0  step=38   reward=1.0   done=False action=1 observation=[-0.01529242  0.22403108 -0.06189047 -0.53247328]\n",
      "[CartPole-v0 8:1  :22 ] train iteration=0  step=39   reward=1.0   done=False action=0 observation=[-0.01081179  0.02983171 -0.07253994 -0.25991613]\n",
      "[CartPole-v0 8:1  :23 ] train iteration=0  step=40   reward=1.0   done=False action=1 observation=[-0.01021516  0.2259102  -0.07773826 -0.57456843]\n",
      "[CartPole-v0 8:1  :24 ] train iteration=0  step=41   reward=1.0   done=False action=1 observation=[-0.00569696  0.42203099 -0.08922963 -0.89069319]\n",
      "[CartPole-v0 8:1  :25 ] train iteration=0  step=42   reward=1.0   done=False action=0 observation=[ 0.00274366  0.22822558 -0.10704349 -0.62734031]\n",
      "[CartPole-v0 8:1  :26 ] train iteration=0  step=43   reward=1.0   done=False action=1 observation=[ 0.00730818  0.4246659  -0.1195903  -0.95172497]\n",
      "[CartPole-v0 8:1  :27 ] train iteration=0  step=44   reward=1.0   done=False action=1 observation=[ 0.01580149  0.62117655 -0.1386248  -1.27946141]\n",
      "[CartPole-v0 8:1  :28 ] train iteration=0  step=45   reward=1.0   done=False action=0 observation=[ 0.02822502  0.42806642 -0.16421403 -1.03320027]\n",
      "[CartPole-v0 8:1  :29 ] train iteration=0  step=46   reward=1.0   done=False action=0 observation=[ 0.03678635  0.2354638  -0.18487803 -0.79624515]\n",
      "[CartPole-v0 8:1  :30 ] train iteration=0  step=47   reward=1.0   done=False action=0 observation=[ 0.04149563  0.04329472 -0.20080293 -0.56694878]\n",
      "[CartPole-v0 8:2  :31 ] train iteration=0  step=48   reward=1.0   done=True  action=1 observation=[ 0.04236152  0.24058284 -0.21214191 -0.91557486]\n",
      "[CartPole-v0 8:2  :1  ] train iteration=0  step=49   reward=1.0   done=False action=1 observation=[-0.04396213  0.19844869 -0.04501504 -0.25903102]\n",
      "[CartPole-v0 8:2  :2  ] train iteration=0  step=50   reward=1.0   done=False action=1 observation=[-0.03999315  0.3941834  -0.05019566 -0.56556562]\n",
      "[CartPole-v0 8:2  :3  ] train iteration=0  step=51   reward=1.0   done=False action=1 observation=[-0.03210949  0.5899723  -0.06150698 -0.8736304 ]\n",
      "[CartPole-v0 8:2  :4  ] train iteration=0  step=52   reward=1.0   done=False action=1 observation=[-0.02031004  0.7858742  -0.07897958 -1.18499923]\n",
      "[CartPole-v0 8:2  :5  ] train iteration=0  step=53   reward=1.0   done=False action=0 observation=[-0.00459256  0.59186051 -0.10267957 -0.91808175]\n",
      "[CartPole-v0 8:2  :6  ] train iteration=0  step=54   reward=1.0   done=False action=0 observation=[ 0.00724465  0.39826534 -0.1210412  -0.65935325]\n",
      "[CartPole-v0 8:2  :7  ] train iteration=0  step=55   reward=1.0   done=False action=1 observation=[ 0.01520996  0.59484537 -0.13422827 -0.98756514]\n",
      "[CartPole-v0 8:2  :8  ] train iteration=0  step=56   reward=1.0   done=False action=1 observation=[ 0.02710687  0.79148429 -0.15397957 -1.31921506]\n",
      "[CartPole-v0 8:2  :9  ] train iteration=0  step=57   reward=1.0   done=False action=0 observation=[ 0.04293655  0.59860746 -0.18036387 -1.07841416]\n",
      "[CartPole-v0 8:2  :10 ] train iteration=0  step=58   reward=1.0   done=False action=1 observation=[ 0.0549087   0.795593   -0.20193216 -1.42183929]\n",
      "[CartPole-v0 8:3  :11 ] train iteration=0  step=59   reward=1.0   done=True  action=1 observation=[ 0.07082056  0.99255756 -0.23036894 -1.77024833]\n",
      "[CartPole-v0 8:3  :1  ] train iteration=1  step=1    reward=1.0   done=False action=1 observation=[-0.00384741  0.23602739 -0.04506642 -0.26458976]\n",
      "[CartPole-v0 8:3  :2  ] train iteration=1  step=2    reward=1.0   done=False action=0 observation=[ 0.00087314  0.04157668 -0.05035822  0.01354511]\n",
      "[CartPole-v0 8:3  :3  ] train iteration=1  step=3    reward=1.0   done=False action=0 observation=[ 0.00170468 -0.15278825 -0.05008731  0.28992386]\n",
      "[CartPole-v0 8:3  :4  ] train iteration=1  step=4    reward=1.0   done=False action=1 observation=[-0.00135109  0.04301081 -0.04428884 -0.01812591]\n",
      "[CartPole-v0 8:3  :5  ] train iteration=1  step=5    reward=1.0   done=False action=1 observation=[-0.00049087  0.23873901 -0.04465135 -0.32444698]\n",
      "[CartPole-v0 8:3  :6  ] train iteration=1  step=6    reward=1.0   done=False action=0 observation=[ 0.00428391  0.04428034 -0.05114029 -0.04617284]\n",
      "[CartPole-v0 8:3  :7  ] train iteration=1  step=7    reward=1.0   done=False action=1 observation=[ 0.00516951  0.24009689 -0.05206375 -0.35454235]\n",
      "[CartPole-v0 8:3  :8  ] train iteration=1  step=8    reward=1.0   done=False action=1 observation=[ 0.00997145  0.43591898 -0.0591546  -0.6631773 ]\n",
      "[CartPole-v0 8:3  :9  ] train iteration=1  step=9    reward=1.0   done=False action=1 observation=[ 0.01868983  0.63181185 -0.07241814 -0.97388395]\n",
      "[CartPole-v0 8:3  :10 ] train iteration=1  step=10   reward=1.0   done=False action=1 observation=[ 0.03132607  0.82782672 -0.09189582 -1.28840794]\n",
      "[CartPole-v0 8:3  :11 ] train iteration=1  step=11   reward=1.0   done=False action=0 observation=[ 0.0478826   0.6339861  -0.11766398 -1.02585323]\n",
      "[CartPole-v0 8:3  :12 ] train iteration=1  step=12   reward=1.0   done=False action=1 observation=[ 0.06056232  0.83046135 -0.13818105 -1.35304177]\n",
      "[CartPole-v0 8:3  :13 ] train iteration=1  step=13   reward=1.0   done=False action=0 observation=[ 0.07717155  0.6373181  -0.16524188 -1.10658448]\n",
      "[CartPole-v0 8:3  :14 ] train iteration=1  step=14   reward=1.0   done=False action=0 observation=[ 0.08991791  0.44470787 -0.18737357 -0.8699649 ]\n",
      "[CartPole-v0 8:3  :15 ] train iteration=1  step=15   reward=1.0   done=False action=1 observation=[ 0.09881207  0.64181657 -0.20477287 -1.21521897]\n",
      "[CartPole-v0 8:4  :16 ] train iteration=1  step=16   reward=1.0   done=True  action=1 observation=[ 0.1116484   0.83890459 -0.22907725 -1.56445778]\n",
      "[CartPole-v0 8:4  :1  ] train iteration=1  step=17   reward=1.0   done=False action=1 observation=[ 0.02719217  0.14678731 -0.00691121 -0.27544406]\n",
      "[CartPole-v0 8:4  :2  ] train iteration=1  step=18   reward=1.0   done=False action=1 observation=[ 0.03012792  0.34200718 -0.0124201  -0.57029875]\n",
      "[CartPole-v0 8:4  :3  ] train iteration=1  step=19   reward=1.0   done=False action=0 observation=[ 0.03696806  0.14706159 -0.02382607 -0.28155434]\n",
      "[CartPole-v0 8:4  :4  ] train iteration=1  step=20   reward=1.0   done=False action=0 observation=[ 0.03990929 -0.04771254 -0.02945716  0.00351974]\n",
      "[CartPole-v0 8:4  :5  ] train iteration=1  step=21   reward=1.0   done=False action=0 observation=[ 0.03895504 -0.24239992 -0.02938676  0.28676496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:4  :6  ] train iteration=1  step=22   reward=1.0   done=False action=1 observation=[ 0.03410704 -0.04687147 -0.02365146 -0.01503955]\n",
      "[CartPole-v0 8:4  :7  ] train iteration=1  step=23   reward=1.0   done=False action=1 observation=[ 0.03316961  0.14858155 -0.02395225 -0.31508996]\n",
      "[CartPole-v0 8:4  :8  ] train iteration=1  step=24   reward=1.0   done=False action=1 observation=[ 0.03614124  0.34403635 -0.03025405 -0.61522936]\n",
      "[CartPole-v0 8:4  :9  ] train iteration=1  step=25   reward=1.0   done=False action=1 observation=[ 0.04302197  0.53956767 -0.04255864 -0.91728544]\n",
      "[CartPole-v0 8:4  :10 ] train iteration=1  step=26   reward=1.0   done=False action=0 observation=[ 0.05381332  0.34504617 -0.06090435 -0.63827587]\n",
      "[CartPole-v0 8:4  :11 ] train iteration=1  step=27   reward=1.0   done=False action=0 observation=[ 0.06071425  0.15082398 -0.07366987 -0.36537755]\n",
      "[CartPole-v0 8:4  :12 ] train iteration=1  step=28   reward=1.0   done=False action=1 observation=[ 0.06373073  0.34691133 -0.08097742 -0.68035013]\n",
      "[CartPole-v0 8:4  :13 ] train iteration=1  step=29   reward=1.0   done=False action=1 observation=[ 0.07066895  0.54305911 -0.09458442 -0.99738902]\n",
      "[CartPole-v0 8:4  :14 ] train iteration=1  step=30   reward=1.0   done=False action=1 observation=[ 0.08153014  0.73930972 -0.1145322  -1.31821552]\n",
      "[CartPole-v0 8:4  :15 ] train iteration=1  step=31   reward=1.0   done=False action=0 observation=[ 0.09631633  0.54580718 -0.14089651 -1.06346224]\n",
      "[CartPole-v0 8:4  :16 ] train iteration=1  step=32   reward=1.0   done=False action=1 observation=[ 0.10723247  0.7424844  -0.16216576 -1.39684128]\n",
      "[CartPole-v0 8:4  :17 ] train iteration=1  step=33   reward=1.0   done=False action=1 observation=[ 0.12208216  0.93920891 -0.19010258 -1.73552452]\n",
      "[CartPole-v0 8:5  :18 ] train iteration=1  step=34   reward=1.0   done=True  action=0 observation=[ 0.14086634  0.74669578 -0.22481307 -1.50751119]\n",
      "[CartPole-v0 8:5  :1  ] train iteration=1  step=35   reward=1.0   done=False action=1 observation=[ 0.03702274  0.22412742  0.02434186 -0.32344455]\n",
      "[CartPole-v0 8:5  :2  ] train iteration=1  step=36   reward=1.0   done=False action=0 observation=[ 0.04150529  0.02866746  0.01787297 -0.02318568]\n",
      "[CartPole-v0 8:5  :3  ] train iteration=1  step=37   reward=1.0   done=False action=1 observation=[ 0.04207864  0.2235286   0.01740926 -0.31017632]\n",
      "[CartPole-v0 8:5  :4  ] train iteration=1  step=38   reward=1.0   done=False action=0 observation=[ 0.04654921  0.02816299  0.01120573 -0.01205425]\n",
      "[CartPole-v0 8:5  :5  ] train iteration=1  step=39   reward=1.0   done=False action=1 observation=[ 0.04711247  0.22312246  0.01096465 -0.30118068]\n",
      "[CartPole-v0 8:5  :6  ] train iteration=1  step=40   reward=1.0   done=False action=1 observation=[ 0.05157492  0.41808643  0.00494103 -0.59038551]\n",
      "[CartPole-v0 8:5  :7  ] train iteration=1  step=41   reward=1.0   done=False action=0 observation=[ 0.05993665  0.22289564 -0.00686668 -0.29615026]\n",
      "[CartPole-v0 8:5  :8  ] train iteration=1  step=42   reward=1.0   done=False action=1 observation=[ 0.06439456  0.41811481 -0.01278968 -0.59099089]\n",
      "[CartPole-v0 8:5  :9  ] train iteration=1  step=43   reward=1.0   done=False action=0 observation=[ 0.07275686  0.22317424 -0.0246095  -0.30236401]\n",
      "[CartPole-v0 8:5  :10 ] train iteration=1  step=44   reward=1.0   done=False action=0 observation=[ 0.07722034  0.02841151 -0.03065678 -0.01754285]\n",
      "[CartPole-v0 8:5  :11 ] train iteration=1  step=45   reward=1.0   done=False action=1 observation=[ 0.07778857  0.2239594  -0.03100764 -0.31973853]\n",
      "[CartPole-v0 8:5  :12 ] train iteration=1  step=46   reward=1.0   done=False action=1 observation=[ 0.08226776  0.41950892 -0.03740241 -0.62203659]\n",
      "[CartPole-v0 8:5  :13 ] train iteration=1  step=47   reward=1.0   done=False action=1 observation=[ 0.09065794  0.61513264 -0.04984314 -0.9262607 ]\n",
      "[CartPole-v0 8:5  :14 ] train iteration=1  step=48   reward=1.0   done=False action=0 observation=[ 0.10296059  0.42071794 -0.06836835 -0.64964863]\n",
      "[CartPole-v0 8:5  :15 ] train iteration=1  step=49   reward=1.0   done=False action=1 observation=[ 0.11137495  0.61672228 -0.08136133 -0.96305292]\n",
      "[CartPole-v0 8:5  :16 ] train iteration=1  step=50   reward=1.0   done=False action=1 observation=[ 0.1237094   0.81283761 -0.10062238 -1.28014663]\n",
      "[CartPole-v0 8:5  :17 ] train iteration=1  step=51   reward=1.0   done=False action=0 observation=[ 0.13996615  0.61913143 -0.12622532 -1.02059014]\n",
      "[CartPole-v0 8:5  :18 ] train iteration=1  step=52   reward=1.0   done=False action=0 observation=[ 0.15234878  0.42589672 -0.14663712 -0.77005587]\n",
      "[CartPole-v0 8:5  :19 ] train iteration=1  step=53   reward=1.0   done=False action=1 observation=[ 0.16086671  0.62269968 -0.16203824 -1.10504918]\n",
      "[CartPole-v0 8:5  :20 ] train iteration=1  step=54   reward=1.0   done=False action=1 observation=[ 0.1733207   0.81953797 -0.18413922 -1.44386992]\n",
      "[CartPole-v0 8:6  :21 ] train iteration=1  step=55   reward=1.0   done=True  action=0 observation=[ 0.18971146  0.62709722 -0.21301662 -1.21392035]\n",
      "[CartPole-v0 8:6  :1  ] train iteration=2  step=1    reward=1.0   done=False action=1 observation=[ 0.00256538  0.23563461 -0.00928383 -0.30537031]\n",
      "[CartPole-v0 8:6  :2  ] train iteration=2  step=2    reward=1.0   done=False action=0 observation=[ 0.00727807  0.04064618 -0.01539124 -0.01562968]\n",
      "[CartPole-v0 8:6  :3  ] train iteration=2  step=3    reward=1.0   done=False action=0 observation=[ 0.00809099 -0.1542517  -0.01570383  0.27215767]\n",
      "[CartPole-v0 8:6  :4  ] train iteration=2  step=4    reward=1.0   done=False action=1 observation=[ 0.00500596  0.04109077 -0.01026068 -0.02543664]\n",
      "[CartPole-v0 8:6  :5  ] train iteration=2  step=5    reward=1.0   done=False action=0 observation=[ 0.00582777 -0.15388254 -0.01076941  0.26399135]\n",
      "[CartPole-v0 8:6  :6  ] train iteration=2  step=6    reward=1.0   done=False action=1 observation=[ 0.00275012  0.04139146 -0.00548958 -0.03206881]\n",
      "[CartPole-v0 8:6  :7  ] train iteration=2  step=7    reward=1.0   done=False action=0 observation=[ 0.00357795 -0.15365134 -0.00613096  0.25887705]\n",
      "[CartPole-v0 8:6  :8  ] train iteration=2  step=8    reward=1.0   done=False action=0 observation=[ 5.04925683e-04 -3.48685234e-01 -9.53416337e-04  5.49619899e-01]\n",
      "[CartPole-v0 8:6  :9  ] train iteration=2  step=9    reward=1.0   done=False action=1 observation=[-0.00646878 -0.1535499   0.01003898  0.25663673]\n",
      "[CartPole-v0 8:6  :10 ] train iteration=2  step=10   reward=1.0   done=False action=1 observation=[-0.00953978  0.04142729  0.01517172 -0.03286291]\n",
      "[CartPole-v0 8:6  :11 ] train iteration=2  step=11   reward=1.0   done=False action=0 observation=[-0.00871123 -0.15390891  0.01451446  0.26456798]\n",
      "[CartPole-v0 8:6  :12 ] train iteration=2  step=12   reward=1.0   done=False action=1 observation=[-0.01178941  0.0410029   0.01980582 -0.02350184]\n",
      "[CartPole-v0 8:6  :13 ] train iteration=2  step=13   reward=1.0   done=False action=0 observation=[-0.01096935 -0.1543974   0.01933578  0.27536366]\n",
      "[CartPole-v0 8:6  :14 ] train iteration=2  step=14   reward=1.0   done=False action=1 observation=[-0.0140573   0.04044342  0.02484305 -0.01115857]\n",
      "[CartPole-v0 8:6  :15 ] train iteration=2  step=15   reward=1.0   done=False action=0 observation=[-0.01324843 -0.15502584  0.02461988  0.28925795]\n",
      "[CartPole-v0 8:6  :16 ] train iteration=2  step=16   reward=1.0   done=False action=0 observation=[-0.01634895 -0.35049006  0.03040504  0.58960294]\n",
      "[CartPole-v0 8:6  :17 ] train iteration=2  step=17   reward=1.0   done=False action=1 observation=[-0.02335875 -0.15580675  0.0421971   0.30665065]\n",
      "[CartPole-v0 8:6  :18 ] train iteration=2  step=18   reward=1.0   done=False action=0 observation=[-0.02647488 -0.3515038   0.04833011  0.61233719]\n",
      "[CartPole-v0 8:6  :19 ] train iteration=2  step=19   reward=1.0   done=False action=0 observation=[-0.03350496 -0.54726669  0.06057686  0.91984217]\n",
      "[CartPole-v0 8:6  :20 ] train iteration=2  step=20   reward=1.0   done=False action=0 observation=[-0.04445029 -0.74315277  0.0789737   1.23093105]\n",
      "[CartPole-v0 8:6  :21 ] train iteration=2  step=21   reward=1.0   done=False action=1 observation=[-0.05931335 -0.54913045  0.10359232  0.96399881]\n",
      "[CartPole-v0 8:6  :22 ] train iteration=2  step=22   reward=1.0   done=False action=0 observation=[-0.07029596 -0.74548009  0.1228723   1.28734604]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:6  :23 ] train iteration=2  step=23   reward=1.0   done=False action=0 observation=[-0.08520556 -0.94193243  0.14861922  1.6158365 ]\n",
      "[CartPole-v0 8:6  :24 ] train iteration=2  step=24   reward=1.0   done=False action=0 observation=[-0.10404421 -1.13846208  0.18093595  1.95091468]\n",
      "[CartPole-v0 8:7  :25 ] train iteration=2  step=25   reward=1.0   done=True  action=0 observation=[-0.12681345 -1.3349888   0.21995424  2.29379792]\n",
      "[CartPole-v0 8:7  :1  ] train iteration=2  step=26   reward=1.0   done=False action=0 observation=[ 0.0404217  -0.21039115 -0.0010204   0.26814947]\n",
      "[CartPole-v0 8:7  :2  ] train iteration=2  step=27   reward=1.0   done=False action=1 observation=[ 0.03621387 -0.01525465  0.00434259 -0.02485513]\n",
      "[CartPole-v0 8:7  :3  ] train iteration=2  step=28   reward=1.0   done=False action=1 observation=[ 0.03590878  0.17980475  0.00384548 -0.31616476]\n",
      "[CartPole-v0 8:7  :4  ] train iteration=2  step=29   reward=1.0   done=False action=1 observation=[ 0.03950488  0.37487172 -0.00247781 -0.60763248]\n",
      "[CartPole-v0 8:7  :5  ] train iteration=2  step=30   reward=1.0   done=False action=0 observation=[ 0.04700231  0.1797845  -0.01463046 -0.31573102]\n",
      "[CartPole-v0 8:7  :6  ] train iteration=2  step=31   reward=1.0   done=False action=0 observation=[ 0.050598   -0.01512603 -0.02094508 -0.02769772]\n",
      "[CartPole-v0 8:7  :7  ] train iteration=2  step=32   reward=1.0   done=False action=0 observation=[ 0.05029548 -0.20994145 -0.02149904  0.25830391]\n",
      "[CartPole-v0 8:7  :8  ] train iteration=2  step=33   reward=1.0   done=False action=0 observation=[ 0.04609665 -0.40474998 -0.01633296  0.54412895]\n",
      "[CartPole-v0 8:7  :9  ] train iteration=2  step=34   reward=1.0   done=False action=0 observation=[ 0.03800165 -0.59963865 -0.00545038  0.83162128]\n",
      "[CartPole-v0 8:7  :10 ] train iteration=2  step=35   reward=1.0   done=False action=1 observation=[ 0.02600888 -0.40444263  0.01118205  0.53722921]\n",
      "[CartPole-v0 8:7  :11 ] train iteration=2  step=36   reward=1.0   done=False action=0 observation=[ 0.01792003 -0.59972     0.02192663  0.8334144 ]\n",
      "[CartPole-v0 8:7  :12 ] train iteration=2  step=37   reward=1.0   done=False action=1 observation=[ 0.00592563 -0.40490441  0.03859492  0.54770716]\n",
      "[CartPole-v0 8:7  :13 ] train iteration=2  step=38   reward=1.0   done=False action=1 observation=[-0.00217246 -0.21034532  0.04954906  0.26742995]\n",
      "[CartPole-v0 8:7  :14 ] train iteration=2  step=39   reward=1.0   done=False action=1 observation=[-0.00637937 -0.01596424  0.05489766 -0.00922235]\n",
      "[CartPole-v0 8:7  :15 ] train iteration=2  step=40   reward=1.0   done=False action=0 observation=[-0.00669865 -0.21182877  0.05471321  0.30026364]\n",
      "[CartPole-v0 8:7  :16 ] train iteration=2  step=41   reward=1.0   done=False action=1 observation=[-0.01093523 -0.01752763  0.06071849  0.02532572]\n",
      "[CartPole-v0 8:7  :17 ] train iteration=2  step=42   reward=1.0   done=False action=1 observation=[-0.01128578  0.17667338  0.061225   -0.24759872]\n",
      "[CartPole-v0 8:7  :18 ] train iteration=2  step=43   reward=1.0   done=False action=0 observation=[-0.00775231 -0.0192671   0.05627303  0.06375022]\n",
      "[CartPole-v0 8:7  :19 ] train iteration=2  step=44   reward=1.0   done=False action=1 observation=[-0.00813766  0.17500477  0.05754803 -0.21066078]\n",
      "[CartPole-v0 8:7  :20 ] train iteration=2  step=45   reward=1.0   done=False action=0 observation=[-0.00463756 -0.02089077  0.05333482  0.09960588]\n",
      "[CartPole-v0 8:7  :21 ] train iteration=2  step=46   reward=1.0   done=False action=0 observation=[-0.00505538 -0.21673493  0.05532693  0.4086274 ]\n",
      "[CartPole-v0 8:7  :22 ] train iteration=2  step=47   reward=1.0   done=False action=0 observation=[-0.00939007 -0.4125959   0.06349948  0.71822713]\n",
      "[CartPole-v0 8:7  :23 ] train iteration=2  step=48   reward=1.0   done=False action=0 observation=[-0.01764199 -0.60853641  0.07786402  1.03020185]\n",
      "[CartPole-v0 8:7  :24 ] train iteration=2  step=49   reward=1.0   done=False action=0 observation=[-0.02981272 -0.8046032   0.09846806  1.34627984]\n",
      "[CartPole-v0 8:7  :25 ] train iteration=2  step=50   reward=1.0   done=False action=0 observation=[-0.04590478 -1.00081562  0.12539366  1.66807563]\n",
      "[CartPole-v0 8:7  :26 ] train iteration=2  step=51   reward=1.0   done=False action=0 observation=[-0.0659211  -1.1971529   0.15875517  1.99703844]\n",
      "[CartPole-v0 8:7  :27 ] train iteration=2  step=52   reward=1.0   done=False action=0 observation=[-0.08986416 -1.39353933  0.19869594  2.33439191]\n",
      "[CartPole-v0 8:8  :28 ] train iteration=2  step=53   reward=1.0   done=True  action=1 observation=[-0.11773494 -1.20069293  0.24538378  2.10884673]\n",
      "[CartPole-v0 8:8  :1  ] train iteration=2  step=54   reward=1.0   done=False action=1 observation=[-0.01310465  0.24140094 -0.05026826 -0.33018624]\n",
      "[CartPole-v0 8:8  :2  ] train iteration=2  step=55   reward=1.0   done=False action=1 observation=[-0.00827663  0.43720108 -0.05687199 -0.63828811]\n",
      "[CartPole-v0 8:8  :3  ] train iteration=2  step=56   reward=1.0   done=False action=1 observation=[ 4.67389353e-04  6.33068003e-01 -6.96377488e-02 -9.48324833e-01]\n",
      "[CartPole-v0 8:8  :4  ] train iteration=2  step=57   reward=1.0   done=False action=0 observation=[ 0.01312875  0.43894925 -0.08860425 -0.6783094 ]\n",
      "[CartPole-v0 8:8  :5  ] train iteration=2  step=58   reward=1.0   done=False action=0 observation=[ 0.02190773  0.24516268 -0.10217043 -0.4147854 ]\n",
      "[CartPole-v0 8:8  :6  ] train iteration=2  step=59   reward=1.0   done=False action=1 observation=[ 0.02681099  0.44157311 -0.11046614 -0.73785054]\n",
      "[CartPole-v0 8:8  :7  ] train iteration=2  step=60   reward=1.0   done=False action=1 observation=[ 0.03564245  0.63803319 -0.12522315 -1.0631555 ]\n",
      "[CartPole-v0 8:8  :8  ] train iteration=2  step=61   reward=1.0   done=False action=1 observation=[ 0.04840311  0.83457026 -0.14648626 -1.39237219]\n",
      "[CartPole-v0 8:8  :9  ] train iteration=2  step=62   reward=1.0   done=False action=0 observation=[ 0.06509452  0.64154405 -0.17433371 -1.14884692]\n",
      "[CartPole-v0 8:8  :10 ] train iteration=2  step=63   reward=1.0   done=False action=1 observation=[ 0.0779254   0.83845902 -0.19731064 -1.4907371 ]\n",
      "[CartPole-v0 8:9  :11 ] train iteration=2  step=64   reward=1.0   done=True  action=0 observation=[ 0.09469458  0.64620948 -0.22712539 -1.26559168]\n",
      "[CartPole-v0 8:9  :1  ] train iteration=3  step=1    reward=1.0   done=False action=0 observation=[ 0.00529372 -0.1528915  -0.04368514  0.24099938]\n",
      "[CartPole-v0 8:9  :2  ] train iteration=3  step=2    reward=1.0   done=False action=1 observation=[ 0.00223589  0.04282638 -0.03886516 -0.0651367 ]\n",
      "[CartPole-v0 8:9  :3  ] train iteration=3  step=3    reward=1.0   done=False action=1 observation=[ 0.00309242  0.23848338 -0.04016789 -0.36982405]\n",
      "[CartPole-v0 8:9  :4  ] train iteration=3  step=4    reward=1.0   done=False action=1 observation=[ 0.00786208  0.43415233 -0.04756437 -0.67489691]\n",
      "[CartPole-v0 8:9  :5  ] train iteration=3  step=5    reward=1.0   done=False action=1 observation=[ 0.01654513  0.62990189 -0.06106231 -0.98216782]\n",
      "[CartPole-v0 8:9  :6  ] train iteration=3  step=6    reward=1.0   done=False action=0 observation=[ 0.02914317  0.43564898 -0.08070567 -0.70927268]\n",
      "[CartPole-v0 8:9  :7  ] train iteration=3  step=7    reward=1.0   done=False action=0 observation=[ 0.03785615  0.2417321  -0.09489112 -0.44304586]\n",
      "[CartPole-v0 8:9  :8  ] train iteration=3  step=8    reward=1.0   done=False action=0 observation=[ 0.04269079  0.04807194 -0.10375204 -0.18171861]\n",
      "[CartPole-v0 8:9  :9  ] train iteration=3  step=9    reward=1.0   done=False action=0 observation=[ 0.04365223 -0.14542419 -0.10738641  0.07651642]\n",
      "[CartPole-v0 8:9  :10 ] train iteration=3  step=10   reward=1.0   done=False action=1 observation=[ 0.04074374  0.05106026 -0.10585608 -0.24802348]\n",
      "[CartPole-v0 8:9  :11 ] train iteration=3  step=11   reward=1.0   done=False action=0 observation=[ 0.04176495 -0.14240318 -0.11081655  0.00948372]\n",
      "[CartPole-v0 8:9  :12 ] train iteration=3  step=12   reward=1.0   done=False action=0 observation=[ 0.03891689 -0.33577581 -0.11062688  0.26525004]\n",
      "[CartPole-v0 8:9  :13 ] train iteration=3  step=13   reward=1.0   done=False action=1 observation=[ 0.03220137 -0.13926305 -0.10532187 -0.06017519]\n",
      "[CartPole-v0 8:9  :14 ] train iteration=3  step=14   reward=1.0   done=False action=0 observation=[ 0.02941611 -0.3327296  -0.10652538  0.19750915]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:9  :15 ] train iteration=3  step=15   reward=1.0   done=False action=0 observation=[ 0.02276152 -0.52617938 -0.1025752   0.45477972]\n",
      "[CartPole-v0 8:9  :16 ] train iteration=3  step=16   reward=1.0   done=False action=1 observation=[ 0.01223793 -0.32976799 -0.0934796   0.13160696]\n",
      "[CartPole-v0 8:9  :17 ] train iteration=3  step=17   reward=1.0   done=False action=0 observation=[ 0.00564257 -0.52343521 -0.09084746  0.39339646]\n",
      "[CartPole-v0 8:9  :18 ] train iteration=3  step=18   reward=1.0   done=False action=1 observation=[-0.00482613 -0.32714944 -0.08297953  0.07350953]\n",
      "[CartPole-v0 8:9  :19 ] train iteration=3  step=19   reward=1.0   done=False action=0 observation=[-0.01136912 -0.5209898  -0.08150934  0.33890162]\n",
      "[CartPole-v0 8:9  :20 ] train iteration=3  step=20   reward=1.0   done=False action=1 observation=[-0.02178892 -0.32480834 -0.07473131  0.0216692 ]\n",
      "[CartPole-v0 8:9  :21 ] train iteration=3  step=21   reward=1.0   done=False action=0 observation=[-0.02828509 -0.51878343 -0.07429793  0.28986919]\n",
      "[CartPole-v0 8:9  :22 ] train iteration=3  step=22   reward=1.0   done=False action=1 observation=[-0.03866076 -0.32268501 -0.06850054 -0.02529046]\n",
      "[CartPole-v0 8:9  :23 ] train iteration=3  step=23   reward=1.0   done=False action=1 observation=[-0.04511446 -0.12665097 -0.06900635 -0.3387753 ]\n",
      "[CartPole-v0 8:9  :24 ] train iteration=3  step=24   reward=1.0   done=False action=0 observation=[-0.04764747 -0.32072662 -0.07578186 -0.06862645]\n",
      "[CartPole-v0 8:9  :25 ] train iteration=3  step=25   reward=1.0   done=False action=0 observation=[-0.05406201 -0.5146849  -0.07715439  0.19921742]\n",
      "[CartPole-v0 8:9  :26 ] train iteration=3  step=26   reward=1.0   done=False action=1 observation=[-0.0643557  -0.31854907 -0.07317004 -0.11677198]\n",
      "[CartPole-v0 8:9  :27 ] train iteration=3  step=27   reward=1.0   done=False action=1 observation=[-0.07072669 -0.12245915 -0.07550548 -0.43161264]\n",
      "[CartPole-v0 8:9  :28 ] train iteration=3  step=28   reward=1.0   done=False action=1 observation=[-0.07317587  0.07364619 -0.08413773 -0.74711006]\n",
      "[CartPole-v0 8:9  :29 ] train iteration=3  step=29   reward=1.0   done=False action=1 observation=[-0.07170295  0.26982197 -0.09907993 -1.06504009]\n",
      "[CartPole-v0 8:9  :30 ] train iteration=3  step=30   reward=1.0   done=False action=1 observation=[-0.06630651  0.46610559 -0.12038073 -1.38710341]\n",
      "[CartPole-v0 8:9  :31 ] train iteration=3  step=31   reward=1.0   done=False action=1 observation=[-0.05698439  0.66250468 -0.1481228  -1.71487654]\n",
      "[CartPole-v0 8:9  :32 ] train iteration=3  step=32   reward=1.0   done=False action=1 observation=[-0.0437343   0.85898344 -0.18242033 -2.04975651]\n",
      "[CartPole-v0 8:10 :33 ] train iteration=3  step=33   reward=1.0   done=True  action=1 observation=[-0.02655463  1.05544722 -0.22341546 -2.39289706]\n",
      "[CartPole-v0 8:10 :1  ] train iteration=3  step=34   reward=1.0   done=False action=0 observation=[ 0.0389085  -0.21310224 -0.01856664  0.26851371]\n",
      "[CartPole-v0 8:10 :2  ] train iteration=3  step=35   reward=1.0   done=False action=0 observation=[ 0.03464646 -0.40795437 -0.01319637  0.55528325]\n",
      "[CartPole-v0 8:10 :3  ] train iteration=3  step=36   reward=1.0   done=False action=1 observation=[ 0.02648737 -0.21264964 -0.0020907   0.25847205]\n",
      "[CartPole-v0 8:10 :4  ] train iteration=3  step=37   reward=1.0   done=False action=0 observation=[ 0.02223438 -0.40774169  0.00307874  0.55049481]\n",
      "[CartPole-v0 8:10 :5  ] train iteration=3  step=38   reward=1.0   done=False action=1 observation=[ 0.01407954 -0.21266311  0.01408863  0.25878348]\n",
      "[CartPole-v0 8:10 :6  ] train iteration=3  step=39   reward=1.0   done=False action=0 observation=[ 0.00982628 -0.40798333  0.0192643   0.55587666]\n",
      "[CartPole-v0 8:10 :7  ] train iteration=3  step=40   reward=1.0   done=False action=0 observation=[ 0.00166662 -0.60337038  0.03038184  0.8545662 ]\n",
      "[CartPole-v0 8:10 :8  ] train iteration=3  step=41   reward=1.0   done=False action=1 observation=[-0.01040079 -0.40867539  0.04747316  0.57158937]\n",
      "[CartPole-v0 8:10 :9  ] train iteration=3  step=42   reward=1.0   done=False action=0 observation=[-0.0185743  -0.60442977  0.05890495  0.87884199]\n",
      "[CartPole-v0 8:10 :10 ] train iteration=3  step=43   reward=1.0   done=False action=1 observation=[-0.0306629  -0.41015555  0.07648179  0.60524413]\n",
      "[CartPole-v0 8:10 :11 ] train iteration=3  step=44   reward=1.0   done=False action=1 observation=[-0.03886601 -0.21618174  0.08858667  0.33759772]\n",
      "[CartPole-v0 8:10 :12 ] train iteration=3  step=45   reward=1.0   done=False action=1 observation=[-0.04318964 -0.02242475  0.09533862  0.0741123 ]\n",
      "[CartPole-v0 8:10 :13 ] train iteration=3  step=46   reward=1.0   done=False action=0 observation=[-0.04363814 -0.21877502  0.09682087  0.3952873 ]\n",
      "[CartPole-v0 8:10 :14 ] train iteration=3  step=47   reward=1.0   done=False action=0 observation=[-0.04801364 -0.41512786  0.10472662  0.71685803]\n",
      "[CartPole-v0 8:10 :15 ] train iteration=3  step=48   reward=1.0   done=False action=0 observation=[-0.05631619 -0.61153134  0.11906378  1.04058253]\n",
      "[CartPole-v0 8:10 :16 ] train iteration=3  step=49   reward=1.0   done=False action=1 observation=[-0.06854682 -0.41817498  0.13987543  0.78752346]\n",
      "[CartPole-v0 8:10 :17 ] train iteration=3  step=50   reward=1.0   done=False action=1 observation=[-0.07691032 -0.22522306  0.1556259   0.54191172]\n",
      "[CartPole-v0 8:10 :18 ] train iteration=3  step=51   reward=1.0   done=False action=0 observation=[-0.08141478 -0.42215047  0.16646413  0.87930249]\n",
      "[CartPole-v0 8:10 :19 ] train iteration=3  step=52   reward=1.0   done=False action=0 observation=[-0.08985779 -0.61909526  0.18405018  1.21935082]\n",
      "[CartPole-v0 8:10 :20 ] train iteration=3  step=53   reward=1.0   done=False action=0 observation=[-0.1022397  -0.8160494   0.2084372   1.56359812]\n",
      "[CartPole-v0 8:11 :21 ] train iteration=3  step=54   reward=1.0   done=True  action=1 observation=[-0.11856068 -0.62393926  0.23970916  1.34250786]\n",
      "[CartPole-v0 8:11 :1  ] train iteration=3  step=55   reward=1.0   done=False action=0 observation=[ 0.01928599 -0.15215952  0.04925264  0.28219978]\n",
      "[CartPole-v0 8:11 :2  ] train iteration=3  step=56   reward=1.0   done=False action=0 observation=[ 0.0162428  -0.34794814  0.05489664  0.59000099]\n",
      "[CartPole-v0 8:11 :3  ] train iteration=3  step=57   reward=1.0   done=False action=1 observation=[ 0.00928384 -0.15363607  0.06669666  0.31510348]\n",
      "[CartPole-v0 8:11 :4  ] train iteration=3  step=58   reward=1.0   done=False action=0 observation=[ 0.00621112 -0.34964156  0.07299873  0.62805229]\n",
      "[CartPole-v0 8:11 :5  ] train iteration=3  step=59   reward=1.0   done=False action=0 observation=[-7.81715258e-04 -5.45702323e-01  8.55597734e-02  9.42802782e-01]\n",
      "[CartPole-v0 8:11 :6  ] train iteration=3  step=60   reward=1.0   done=False action=1 observation=[-0.01169576 -0.35183093  0.10441583  0.67818336]\n",
      "[CartPole-v0 8:11 :7  ] train iteration=3  step=61   reward=1.0   done=False action=0 observation=[-0.01873238 -0.54823661  0.1179795   1.00182984]\n",
      "[CartPole-v0 8:11 :8  ] train iteration=3  step=62   reward=1.0   done=False action=1 observation=[-0.02969711 -0.35487177  0.13801609  0.74840441]\n",
      "[CartPole-v0 8:11 :9  ] train iteration=3  step=63   reward=1.0   done=False action=0 observation=[-0.03679455 -0.5516004   0.15298418  1.0811393 ]\n",
      "[CartPole-v0 8:11 :10 ] train iteration=3  step=64   reward=1.0   done=False action=0 observation=[-0.04782656 -0.74837416  0.17460697  1.4176548 ]\n",
      "[CartPole-v0 8:11 :11 ] train iteration=3  step=65   reward=1.0   done=False action=0 observation=[-0.06279404 -0.94517445  0.20296006  1.75944068]\n",
      "[CartPole-v0 8:12 :12 ] train iteration=3  step=66   reward=1.0   done=True  action=0 observation=[-0.08169753 -1.14193414  0.23814888  2.10778368]\n",
      "[CartPole-v0 9:3  :1  ] train iteration=4  step=66  play  episode=0  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.00344703  0.20741807  0.0451034  -0.25832186]\n",
      "[CartPole-v0 9:3  :2  ] train iteration=4  step=66  play  episode=0  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[0.00070133 0.01168219 0.03993696 0.04823926]\n",
      "[CartPole-v0 9:3  :3  ] train iteration=4  step=66  play  episode=0  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.00093498  0.2062094   0.04090175 -0.23158054]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:3  :4  ] train iteration=4  step=66  play  episode=0  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[0.00505916 0.01052759 0.03627014 0.07371844]\n",
      "[CartPole-v0 9:3  :5  ] train iteration=4  step=66  play  episode=0  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.00526972  0.2051113   0.0377445  -0.20730408]\n",
      "[CartPole-v0 9:3  :6  ] train iteration=4  step=66  play  episode=0  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[0.00937194 0.00947052 0.03359842 0.09704233]\n",
      "[CartPole-v0 9:3  :7  ] train iteration=4  step=66  play  episode=0  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.00956135  0.20409522  0.03553927 -0.18485388]\n",
      "[CartPole-v0 9:3  :8  ] train iteration=4  step=66  play  episode=0  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[0.01364326 0.00848327 0.03184219 0.11882511]\n",
      "[CartPole-v0 9:3  :9  ] train iteration=4  step=66  play  episode=0  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.01381292  0.20313487  0.03421869 -0.16364426]\n",
      "[CartPole-v0 9:3  :10 ] train iteration=4  step=66  play  episode=0  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[0.01787562 0.0075402  0.03094581 0.13963433]\n",
      "[CartPole-v0 9:3  :11 ] train iteration=4  step=66  play  episode=0  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.01802642  0.20220558  0.0337385  -0.14312732]\n",
      "[CartPole-v0 9:3  :12 ] train iteration=4  step=66  play  episode=0  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[0.02207053 0.00661709 0.03087595 0.16000568]\n",
      "[CartPole-v0 9:3  :13 ] train iteration=4  step=66  play  episode=0  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=1 observation=[ 0.02220288  0.20128372  0.03407606 -0.12277899]\n",
      "[CartPole-v0 9:3  :14 ] train iteration=4  step=66  play  episode=0  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=0 observation=[0.02622855 0.00569056 0.03162048 0.18045685]\n",
      "[CartPole-v0 9:3  :15 ] train iteration=4  step=66  play  episode=0  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.02634236  0.20034609  0.03522962 -0.10208562]\n",
      "[CartPole-v0 9:3  :16 ] train iteration=4  step=66  play  episode=0  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[0.03034928 0.00473743 0.03318791 0.20150068]\n",
      "[CartPole-v0 9:3  :17 ] train iteration=4  step=66  play  episode=0  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=1 observation=[ 0.03044403  0.1993694   0.03721792 -0.08053106]\n",
      "[CartPole-v0 9:3  :18 ] train iteration=4  step=66  play  episode=0  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=0 observation=[0.03443142 0.00373424 0.0356073  0.22365801]\n",
      "[CartPole-v0 9:3  :19 ] train iteration=4  step=66  play  episode=0  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[ 0.03450611  0.19832965  0.04008046 -0.05758376]\n",
      "[CartPole-v0 9:3  :20 ] train iteration=4  step=66  play  episode=0  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=0 observation=[0.0384727  0.00265662 0.03892878 0.24747057]\n",
      "[CartPole-v0 9:3  :21 ] train iteration=4  step=66  play  episode=0  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=1 observation=[ 0.03852583  0.19720161  0.0438782  -0.03268364]\n",
      "[CartPole-v0 9:3  :22 ] train iteration=4  step=66  play  episode=0  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=0 observation=[0.04246986 0.00147878 0.04322452 0.27351406]\n",
      "[CartPole-v0 9:3  :23 ] train iteration=4  step=66  play  episode=0  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=1 observation=[ 0.04249944  0.19595819  0.0486948  -0.00522851]\n",
      "[CartPole-v0 9:3  :24 ] train iteration=4  step=66  play  episode=0  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=0 observation=[4.64186021e-02 1.72929076e-04 4.85902346e-02 3.02411879e-01]\n",
      "[CartPole-v0 9:3  :25 ] train iteration=4  step=66  play  episode=0  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[0.04642206 0.1945699  0.05463847 0.0254405 ]\n",
      "[CartPole-v0 9:3  :26 ] train iteration=4  step=66  play  episode=0  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[ 0.05031346 -0.00129131  0.05514728  0.33484961]\n",
      "[CartPole-v0 9:3  :27 ] train iteration=4  step=66  play  episode=0  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=1 observation=[0.05028763 0.19300418 0.06184427 0.0600545 ]\n",
      "[CartPole-v0 9:3  :28 ] train iteration=4  step=66  play  episode=0  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[ 0.05414772 -0.00294746  0.06304536  0.37159068]\n",
      "[CartPole-v0 9:3  :29 ] train iteration=4  step=66  play  episode=0  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[0.05408877 0.19122481 0.07047718 0.09943397]\n",
      "[CartPole-v0 9:3  :30 ] train iteration=4  step=66  play  episode=0  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[ 0.05791326 -0.00483272  0.07246586  0.41349336]\n",
      "[CartPole-v0 9:3  :31 ] train iteration=4  step=66  play  episode=0  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[0.05781661 0.18919125 0.08073572 0.14450754]\n",
      "[CartPole-v0 9:3  :32 ] train iteration=4  step=66  play  episode=0  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[ 0.06160043  0.38306973  0.08362588 -0.12165236]\n",
      "[CartPole-v0 9:3  :33 ] train iteration=4  step=66  play  episode=0  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[0.06926183 0.18685543 0.08119283 0.19619792]\n",
      "[CartPole-v0 9:3  :34 ] train iteration=4  step=66  play  episode=0  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[ 0.07299894  0.3807278   0.08511679 -0.06980814]\n",
      "[CartPole-v0 9:3  :35 ] train iteration=4  step=66  play  episode=0  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[0.08061349 0.18449521 0.08372062 0.24846925]\n",
      "[CartPole-v0 9:3  :36 ] train iteration=4  step=66  play  episode=0  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[ 0.0843034   0.37832795  0.08869001 -0.01667638]\n",
      "[CartPole-v0 9:3  :37 ] train iteration=4  step=66  play  episode=0  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=0 observation=[0.09186996 0.18205341 0.08835648 0.30261897]\n",
      "[CartPole-v0 9:3  :38 ] train iteration=4  step=66  play  episode=0  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=1 observation=[0.09551102 0.37581227 0.09440886 0.03905744]\n",
      "[CartPole-v0 9:3  :39 ] train iteration=4  step=66  play  episode=0  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[0.10302727 0.1794722  0.09519001 0.35997103]\n",
      "[CartPole-v0 9:3  :40 ] train iteration=4  step=66  play  episode=0  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[0.10661671 0.37312123 0.10238943 0.09875612]\n",
      "[CartPole-v0 9:3  :41 ] train iteration=4  step=66  play  episode=0  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[0.11407914 0.17669223 0.10436455 0.42190643]\n",
      "[CartPole-v0 9:3  :42 ] train iteration=4  step=66  play  episode=0  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[0.11761298 0.37019272 0.11280268 0.16386246]\n",
      "[CartPole-v0 9:3  :43 ] train iteration=4  step=66  play  episode=0  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[ 0.12501684  0.56353431  0.11607993 -0.09121304]\n",
      "[CartPole-v0 9:3  :44 ] train iteration=4  step=66  play  episode=0  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[0.13628752 0.3669564  0.11425567 0.23572036]\n",
      "[CartPole-v0 9:3  :45 ] train iteration=4  step=66  play  episode=0  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[ 0.14362665  0.5602763   0.11897008 -0.01885068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:3  :46 ] train iteration=4  step=66  play  episode=0  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[0.15483218 0.3636669  0.11859306 0.30887355]\n",
      "[CartPole-v0 9:3  :47 ] train iteration=4  step=66  play  episode=0  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[0.16210552 0.55691703 0.12477053 0.05581911]\n",
      "[CartPole-v0 9:3  :48 ] train iteration=4  step=66  play  episode=0  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[0.17324386 0.36024744 0.12588692 0.38511763]\n",
      "[CartPole-v0 9:3  :49 ] train iteration=4  step=66  play  episode=0  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=1 observation=[0.18044881 0.5533784  0.13358927 0.13462672]\n",
      "[CartPole-v0 9:4  :50 ] train iteration=4  step=66  play  episode=0  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.19151637  0.74635906  0.1362818  -0.11310661]\n",
      "[CartPole-v0 9:4  :1  ] train iteration=4  step=66  play  episode=1  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.00384741  0.23602739 -0.04506642 -0.26458976]\n",
      "[CartPole-v0 9:4  :2  ] train iteration=4  step=66  play  episode=1  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.00087314  0.04157668 -0.05035822  0.01354511]\n",
      "[CartPole-v0 9:4  :3  ] train iteration=4  step=66  play  episode=1  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=0 observation=[ 0.00170468 -0.15278825 -0.05008731  0.28992386]\n",
      "[CartPole-v0 9:4  :4  ] train iteration=4  step=66  play  episode=1  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=1 observation=[-0.00135109  0.04301081 -0.04428884 -0.01812591]\n",
      "[CartPole-v0 9:4  :5  ] train iteration=4  step=66  play  episode=1  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[-0.00049087 -0.15144893 -0.04465135  0.26026101]\n",
      "[CartPole-v0 9:4  :6  ] train iteration=4  step=66  play  episode=1  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[-0.00351985  0.04428105 -0.03944613 -0.04616447]\n",
      "[CartPole-v0 9:4  :7  ] train iteration=4  step=66  play  episode=1  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.00263423 -0.15025372 -0.04036942  0.23381653]\n",
      "[CartPole-v0 9:4  :8  ] train iteration=4  step=66  play  episode=1  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.00563931  0.04542109 -0.03569309 -0.07132193]\n",
      "[CartPole-v0 9:4  :9  ] train iteration=4  step=66  play  episode=1  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.00473088 -0.14917145 -0.03711953  0.20988942]\n",
      "[CartPole-v0 9:4  :10 ] train iteration=4  step=66  play  episode=1  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.00771431  0.04646105 -0.03292174 -0.09426782]\n",
      "[CartPole-v0 9:4  :11 ] train iteration=4  step=66  play  episode=1  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.00678509 -0.14817395 -0.0348071   0.18784923]\n",
      "[CartPole-v0 9:4  :12 ] train iteration=4  step=66  play  episode=1  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.00974857  0.04742825 -0.03105011 -0.11560757]\n",
      "[CartPole-v0 9:4  :13 ] train iteration=4  step=66  play  episode=1  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.00880001 -0.14723536 -0.03336227  0.16711983]\n",
      "[CartPole-v0 9:4  :14 ] train iteration=4  step=66  play  episode=1  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.01174471  0.04834787 -0.03001987 -0.13589845]\n",
      "[CartPole-v0 9:4  :15 ] train iteration=4  step=66  play  episode=1  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[-0.01077776 -0.14633152 -0.03273784  0.14716455]\n",
      "[CartPole-v0 9:4  :16 ] train iteration=4  step=66  play  episode=1  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[-0.01370439  0.04924358 -0.02979455 -0.15566412]\n",
      "[CartPole-v0 9:4  :17 ] train iteration=4  step=66  play  episode=1  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.01271951 -0.14543939 -0.03290783  0.12747243]\n",
      "[CartPole-v0 9:4  :18 ] train iteration=4  step=66  play  episode=1  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.0156283   0.05013816 -0.03035838 -0.17540821]\n",
      "[CartPole-v0 9:4  :19 ] train iteration=4  step=66  play  episode=1  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[-0.01462554 -0.14453647 -0.03386655  0.10754518]\n",
      "[CartPole-v0 9:4  :20 ] train iteration=4  step=66  play  episode=1  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[-0.01751627  0.05105402 -0.03171564 -0.19562718]\n",
      "[CartPole-v0 9:4  :21 ] train iteration=4  step=66  play  episode=1  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.01649519 -0.14360025 -0.03562819  0.08688455]\n",
      "[CartPole-v0 9:4  :22 ] train iteration=4  step=66  play  episode=1  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.01936719  0.05201381 -0.03389049 -0.21682279]\n",
      "[CartPole-v0 9:4  :23 ] train iteration=4  step=66  play  episode=1  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.01832692 -0.14260768 -0.03822695  0.06497991]\n",
      "[CartPole-v0 9:4  :24 ] train iteration=4  step=66  play  episode=1  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[-0.02117907  0.0530409  -0.03692735 -0.23951455]\n",
      "[CartPole-v0 9:4  :25 ] train iteration=4  step=66  play  episode=1  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[-0.02011825 -0.1415346  -0.04171764  0.04129555]\n",
      "[CartPole-v0 9:4  :26 ] train iteration=4  step=66  play  episode=1  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[-0.02294894  0.05415997 -0.04089173 -0.26425234]\n",
      "[CartPole-v0 9:4  :27 ] train iteration=4  step=66  play  episode=1  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[-0.02186574 -0.14035518 -0.04617678  0.01525767]\n",
      "[CartPole-v0 9:4  :28 ] train iteration=4  step=66  play  episode=1  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[-0.02467285  0.05539754 -0.04587163 -0.29162957]\n",
      "[CartPole-v0 9:4  :29 ] train iteration=4  step=66  play  episode=1  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[-0.0235649  -0.13904136 -0.05170422 -0.01375956]\n",
      "[CartPole-v0 9:4  :30 ] train iteration=4  step=66  play  episode=1  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[-0.02634572  0.05678251 -0.05197941 -0.32229708]\n",
      "[CartPole-v0 9:4  :31 ] train iteration=4  step=66  play  episode=1  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[-0.02521007 -0.1375622  -0.05842535 -0.04644881]\n",
      "[CartPole-v0 9:4  :32 ] train iteration=4  step=66  play  episode=1  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[-0.02796132  0.05834675 -0.05935433 -0.35697811]\n",
      "[CartPole-v0 9:4  :33 ] train iteration=4  step=66  play  episode=1  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[-0.02679438 -0.13588334 -0.06649389 -0.08358595]\n",
      "[CartPole-v0 9:4  :34 ] train iteration=4  step=66  play  episode=1  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[-0.02951205  0.06012565 -0.06816561 -0.39648449]\n",
      "[CartPole-v0 9:4  :35 ] train iteration=4  step=66  play  episode=1  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[-0.02830954 -0.13396629 -0.0760953  -0.12604789]\n",
      "[CartPole-v0 9:4  :36 ] train iteration=4  step=66  play  episode=1  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.03098886 -0.32792029 -0.07861626  0.14169077]\n",
      "[CartPole-v0 9:4  :37 ] train iteration=4  step=66  play  episode=1  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.03754727 -0.13176557 -0.07578244 -0.1747219 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:4  :38 ] train iteration=4  step=66  play  episode=1  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.04018258 -0.32572575 -0.07927688  0.09312462]\n",
      "[CartPole-v0 9:4  :39 ] train iteration=4  step=66  play  episode=1  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.0466971  -0.1295623  -0.07741439 -0.2234794 ]\n",
      "[CartPole-v0 9:4  :40 ] train iteration=4  step=66  play  episode=1  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.04928834 -0.32349734 -0.08188397  0.04381481]\n",
      "[CartPole-v0 9:4  :41 ] train iteration=4  step=66  play  episode=1  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[-0.05575829 -0.12730249 -0.08100768 -0.2735384 ]\n",
      "[CartPole-v0 9:4  :42 ] train iteration=4  step=66  play  episode=1  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[-0.05830434 -0.32118077 -0.08647845 -0.00746489]\n",
      "[CartPole-v0 9:4  :43 ] train iteration=4  step=66  play  episode=1  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[-0.06472795 -0.12493189 -0.08662774 -0.32613114]\n",
      "[CartPole-v0 9:4  :44 ] train iteration=4  step=66  play  episode=1  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[-0.06722659 -0.31872051 -0.09315037 -0.06197493]\n",
      "[CartPole-v0 9:4  :45 ] train iteration=4  step=66  play  episode=1  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.073601   -0.122395   -0.09438986 -0.38253311]\n",
      "[CartPole-v0 9:4  :46 ] train iteration=4  step=66  play  episode=1  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.0760489  -0.31605887 -0.10204053 -0.12103986]\n",
      "[CartPole-v0 9:4  :47 ] train iteration=4  step=66  play  episode=1  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[-0.08237008 -0.11963423 -0.10446132 -0.44409211]\n",
      "[CartPole-v0 9:4  :48 ] train iteration=4  step=66  play  episode=1  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[-0.08476276 -0.31313505 -0.11334317 -0.18607887]\n",
      "[CartPole-v0 9:4  :49 ] train iteration=4  step=66  play  episode=1  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=1 observation=[-0.09102546 -0.11658926 -0.11706474 -0.51225745]\n",
      "[CartPole-v0 9:5  :50 ] train iteration=4  step=66  play  episode=1  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.09335725 -0.30988459 -0.12730989 -0.25863738]\n",
      "[CartPole-v0 9:5  :1  ] train iteration=4  step=66  play  episode=2  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 0.02719217  0.14678731 -0.00691121 -0.27544406]\n",
      "[CartPole-v0 9:5  :2  ] train iteration=4  step=66  play  episode=2  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.03012792 -0.04823536 -0.0124201   0.01505108]\n",
      "[CartPole-v0 9:5  :3  ] train iteration=4  step=66  play  episode=2  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.02916321  0.14706249 -0.01211907 -0.28152452]\n",
      "[CartPole-v0 9:5  :4  ] train iteration=4  step=66  play  episode=2  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.03210446 -0.04788451 -0.01774956  0.0073116 ]\n",
      "[CartPole-v0 9:5  :5  ] train iteration=4  step=66  play  episode=2  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.03114677  0.14748743 -0.01760333 -0.29091826]\n",
      "[CartPole-v0 9:5  :6  ] train iteration=4  step=66  play  episode=2  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[ 0.03409652 -0.04737915 -0.0234217  -0.00383879]\n",
      "[CartPole-v0 9:5  :7  ] train iteration=4  step=66  play  episode=2  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.03314893  0.14807074 -0.02349847 -0.30381856]\n",
      "[CartPole-v0 9:5  :8  ] train iteration=4  step=66  play  episode=2  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[ 0.03611035 -0.04670858 -0.02957484 -0.01863815]\n",
      "[CartPole-v0 9:5  :9  ] train iteration=4  step=66  play  episode=2  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.03517618  0.14882475 -0.02994761 -0.32050362]\n",
      "[CartPole-v0 9:5  :10 ] train iteration=4  step=66  play  episode=2  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.03815267 -0.0458582  -0.03635768 -0.03741343]\n",
      "[CartPole-v0 9:5  :11 ] train iteration=4  step=66  play  episode=2  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.03723551  0.14976576 -0.03710595 -0.34134224]\n",
      "[CartPole-v0 9:5  :12 ] train iteration=4  step=66  play  episode=2  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[ 0.04023082 -0.04480915 -0.04393279 -0.06058742]\n",
      "[CartPole-v0 9:5  :13 ] train iteration=4  step=66  play  episode=2  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=1 observation=[ 0.03933464  0.15091427 -0.04514454 -0.36680136]\n",
      "[CartPole-v0 9:5  :14 ] train iteration=4  step=66  play  episode=2  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=0 observation=[ 0.04235292 -0.04353807 -0.05248057 -0.08868802]\n",
      "[CartPole-v0 9:5  :15 ] train iteration=4  step=66  play  episode=2  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.04148216  0.15229531 -0.05425433 -0.39745587]\n",
      "[CartPole-v0 9:5  :16 ] train iteration=4  step=66  play  episode=2  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[ 0.04452807 -0.04201662 -0.06220345 -0.12235978]\n",
      "[CartPole-v0 9:5  :17 ] train iteration=4  step=66  play  episode=2  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[ 0.04368774 -0.23619479 -0.06465064  0.15006813]\n",
      "[CartPole-v0 9:5  :18 ] train iteration=4  step=66  play  episode=2  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[ 0.03896384 -0.04020951 -0.06164928 -0.16228968]\n",
      "[CartPole-v0 9:5  :19 ] train iteration=4  step=66  play  episode=2  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[ 0.03815965 -0.23439721 -0.06489507  0.1103251 ]\n",
      "[CartPole-v0 9:5  :20 ] train iteration=4  step=66  play  episode=2  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[ 0.03347171 -0.03840826 -0.06268857 -0.20210527]\n",
      "[CartPole-v0 9:5  :21 ] train iteration=4  step=66  play  episode=2  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[ 0.03270354 -0.23258025 -0.06673068  0.07016224]\n",
      "[CartPole-v0 9:5  :22 ] train iteration=4  step=66  play  episode=2  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[ 0.02805194 -0.03656821 -0.06532743 -0.24280569]\n",
      "[CartPole-v0 9:5  :23 ] train iteration=4  step=66  play  episode=2  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[ 0.02732057 -0.23069916 -0.07018355  0.02857697]\n",
      "[CartPole-v0 9:5  :24 ] train iteration=4  step=66  play  episode=2  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[ 0.02270659 -0.03464457 -0.06961201 -0.28539794]\n",
      "[CartPole-v0 9:5  :25 ] train iteration=4  step=66  play  episode=2  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[ 0.0220137  -0.22870824 -0.07531997 -0.01545687]\n",
      "[CartPole-v0 9:5  :26 ] train iteration=4  step=66  play  episode=2  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[ 0.01743953 -0.42267373 -0.0756291   0.25254333]\n",
      "[CartPole-v0 9:5  :27 ] train iteration=4  step=66  play  episode=2  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=1 observation=[ 0.00898606 -0.2265579  -0.07057824 -0.06300328]\n",
      "[CartPole-v0 9:5  :28 ] train iteration=4  step=66  play  episode=2  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[ 0.0044549  -0.42060068 -0.0718383   0.20660347]\n",
      "[CartPole-v0 9:5  :29 ] train iteration=4  step=66  play  episode=2  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[-0.00395711 -0.2245289  -0.06770623 -0.10784791]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:5  :30 ] train iteration=4  step=66  play  episode=2  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[-0.00844769 -0.02850533 -0.06986319 -0.42110001]\n",
      "[CartPole-v0 9:5  :31 ] train iteration=4  step=66  play  episode=2  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[-0.0090178  -0.22257147 -0.07828519 -0.15123398]\n",
      "[CartPole-v0 9:5  :32 ] train iteration=4  step=66  play  episode=2  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[-0.01346923 -0.41649025 -0.08130987  0.11576096]\n",
      "[CartPole-v0 9:5  :33 ] train iteration=4  step=66  play  episode=2  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=1 observation=[-0.02179903 -0.22030308 -0.07899465 -0.2014263 ]\n",
      "[CartPole-v0 9:5  :34 ] train iteration=4  step=66  play  episode=2  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[-0.02620509 -0.41421161 -0.08302318  0.06532916]\n",
      "[CartPole-v0 9:5  :35 ] train iteration=4  step=66  play  episode=2  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.03448933 -0.21800353 -0.08171659 -0.25235   ]\n",
      "[CartPole-v0 9:5  :36 ] train iteration=4  step=66  play  episode=2  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.0388494  -0.41186931 -0.08676359  0.01348034]\n",
      "[CartPole-v0 9:5  :37 ] train iteration=4  step=66  play  episode=2  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.04708678 -0.21561712 -0.08649399 -0.30526711]\n",
      "[CartPole-v0 9:5  :38 ] train iteration=4  step=66  play  episode=2  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.05139912 -0.40940684 -0.09259933 -0.04106673]\n",
      "[CartPole-v0 9:5  :39 ] train iteration=4  step=66  play  episode=2  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.05958726 -0.21308743 -0.09342066 -0.36146954]\n",
      "[CartPole-v0 9:5  :40 ] train iteration=4  step=66  play  episode=2  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.06384901 -0.40676594 -0.10065006 -0.09964432]\n",
      "[CartPole-v0 9:5  :41 ] train iteration=4  step=66  play  episode=2  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[-0.07198433 -0.21035632 -0.10264294 -0.42230891]\n",
      "[CartPole-v0 9:5  :42 ] train iteration=4  step=66  play  episode=2  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[-0.07619146 -0.4038857  -0.11108912 -0.16366677]\n",
      "[CartPole-v0 9:5  :43 ] train iteration=4  step=66  play  episode=2  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[-0.08426917 -0.20736327 -0.11436246 -0.48922642]\n",
      "[CartPole-v0 9:5  :44 ] train iteration=4  step=66  play  episode=2  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[-0.08841643 -0.40070179 -0.12414698 -0.23466237]\n",
      "[CartPole-v0 9:5  :45 ] train iteration=4  step=66  play  episode=2  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.09643047 -0.20404492 -0.12884023 -0.56378289]\n",
      "[CartPole-v0 9:5  :46 ] train iteration=4  step=66  play  episode=2  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.10051137 -0.39714609 -0.14011589 -0.31430621]\n",
      "[CartPole-v0 9:5  :47 ] train iteration=4  step=66  play  episode=2  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[-0.10845429 -0.20033521 -0.14640201 -0.64768878]\n",
      "[CartPole-v0 9:5  :48 ] train iteration=4  step=66  play  episode=2  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[-0.11246099 -0.39314688 -0.15935579 -0.40445381]\n",
      "[CartPole-v0 9:5  :49 ] train iteration=4  step=66  play  episode=2  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=1 observation=[-0.12032393 -0.19616628 -0.16744486 -0.74283358]\n",
      "[CartPole-v0 9:6  :50 ] train iteration=4  step=66  play  episode=2  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.12424726 -0.38863001 -0.18230154 -0.50717479]\n",
      "[CartPole-v0 8:12 :1  ] train iteration=4  step=1    reward=1.0   done=False action=0 observation=[ 0.00648396 -0.23746151  0.02922442  0.28708252]\n",
      "[CartPole-v0 8:12 :2  ] train iteration=4  step=2    reward=1.0   done=False action=0 observation=[ 0.00173473 -0.43298778  0.03496607  0.58883745]\n",
      "[CartPole-v0 8:12 :3  ] train iteration=4  step=3    reward=1.0   done=False action=0 observation=[-0.00692502 -0.62858147  0.04674282  0.89232658]\n",
      "[CartPole-v0 8:12 :4  ] train iteration=4  step=4    reward=1.0   done=False action=0 observation=[-0.01949665 -0.82430524  0.06458935  1.19932895]\n",
      "[CartPole-v0 8:12 :5  ] train iteration=4  step=5    reward=1.0   done=False action=0 observation=[-0.03598276 -1.02020063  0.08857593  1.5115354 ]\n",
      "[CartPole-v0 8:12 :6  ] train iteration=4  step=6    reward=1.0   done=False action=0 observation=[-0.05638677 -1.21627681  0.11880664  1.83050394]\n",
      "[CartPole-v0 8:12 :7  ] train iteration=4  step=7    reward=1.0   done=False action=0 observation=[-0.0807123  -1.41249746  0.15541672  2.15760715]\n",
      "[CartPole-v0 8:12 :8  ] train iteration=4  step=8    reward=1.0   done=False action=0 observation=[-0.10896225 -1.60876547  0.19856886  2.49396957]\n",
      "[CartPole-v0 8:13 :9  ] train iteration=4  step=9    reward=1.0   done=True  action=0 observation=[-0.14113756 -1.80490539  0.24844825  2.84039455]\n",
      "[CartPole-v0 8:13 :1  ] train iteration=4  step=10   reward=1.0   done=False action=0 observation=[ 0.04257711 -0.16977579 -0.04044967  0.30465062]\n",
      "[CartPole-v0 8:13 :2  ] train iteration=4  step=11   reward=1.0   done=False action=1 observation=[ 0.03918159  0.02589856 -0.03435666 -0.00050978]\n",
      "[CartPole-v0 8:13 :3  ] train iteration=4  step=12   reward=1.0   done=False action=0 observation=[ 0.03969956 -0.16871425 -0.03436685  0.28113829]\n",
      "[CartPole-v0 8:13 :4  ] train iteration=4  step=13   reward=1.0   done=False action=1 observation=[ 0.03632528  0.02688064 -0.02874409 -0.02218266]\n",
      "[CartPole-v0 8:13 :5  ] train iteration=4  step=14   reward=1.0   done=False action=0 observation=[ 0.03686289 -0.16781756 -0.02918774  0.26129439]\n",
      "[CartPole-v0 8:13 :6  ] train iteration=4  step=15   reward=1.0   done=False action=1 observation=[ 0.03350654  0.02770862 -0.02396185 -0.04044993]\n",
      "[CartPole-v0 8:13 :7  ] train iteration=4  step=16   reward=1.0   done=False action=1 observation=[ 0.03406071  0.22316584 -0.02477085 -0.34059571]\n",
      "[CartPole-v0 8:13 :8  ] train iteration=4  step=17   reward=1.0   done=False action=1 observation=[ 0.03852403  0.41863132 -0.03158277 -0.64098587]\n",
      "[CartPole-v0 8:13 :9  ] train iteration=4  step=18   reward=1.0   done=False action=1 observation=[ 0.04689665  0.61417899 -0.04440248 -0.94344488]\n",
      "[CartPole-v0 8:13 :10 ] train iteration=4  step=19   reward=1.0   done=False action=1 observation=[ 0.05918023  0.80987014 -0.06327138 -1.24974233]\n",
      "[CartPole-v0 8:13 :11 ] train iteration=4  step=20   reward=1.0   done=False action=0 observation=[ 0.07537764  0.61561366 -0.08826623 -0.97753003]\n",
      "[CartPole-v0 8:13 :12 ] train iteration=4  step=21   reward=1.0   done=False action=0 observation=[ 0.08768991  0.42177904 -0.10781683 -0.71382657]\n",
      "[CartPole-v0 8:13 :13 ] train iteration=4  step=22   reward=1.0   done=False action=0 observation=[ 0.09612549  0.22830182 -0.12209336 -0.45693268]\n",
      "[CartPole-v0 8:13 :14 ] train iteration=4  step=23   reward=1.0   done=False action=0 observation=[ 0.10069153  0.0350984  -0.13123201 -0.20509123]\n",
      "[CartPole-v0 8:13 :15 ] train iteration=4  step=24   reward=1.0   done=False action=1 observation=[ 0.1013935   0.23182902 -0.13533384 -0.53612132]\n",
      "[CartPole-v0 8:13 :16 ] train iteration=4  step=25   reward=1.0   done=False action=1 observation=[ 0.10603008  0.42856835 -0.14605626 -0.86819876]\n",
      "[CartPole-v0 8:13 :17 ] train iteration=4  step=26   reward=1.0   done=False action=0 observation=[ 0.11460144  0.23570329 -0.16342024 -0.62476942]\n",
      "[CartPole-v0 8:13 :18 ] train iteration=4  step=27   reward=1.0   done=False action=0 observation=[ 0.11931551  0.0431944  -0.17591563 -0.38768539]\n",
      "[CartPole-v0 8:13 :19 ] train iteration=4  step=28   reward=1.0   done=False action=1 observation=[ 0.1201794   0.24032007 -0.18366934 -0.7302633 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:13 :20 ] train iteration=4  step=29   reward=1.0   done=False action=0 observation=[ 0.1249858   0.04814739 -0.1982746  -0.50054844]\n",
      "[CartPole-v0 8:13 :21 ] train iteration=4  step=30   reward=1.0   done=False action=0 observation=[ 0.12594875 -0.14370842 -0.20828557 -0.27631456]\n",
      "[CartPole-v0 8:14 :22 ] train iteration=4  step=31   reward=1.0   done=True  action=1 observation=[ 0.12307458  0.05368203 -0.21381186 -0.62679504]\n",
      "[CartPole-v0 8:14 :1  ] train iteration=4  step=32   reward=1.0   done=False action=1 observation=[-0.047718    0.1816533  -0.00634079 -0.29623005]\n",
      "[CartPole-v0 8:14 :2  ] train iteration=4  step=33   reward=1.0   done=False action=0 observation=[-0.04408493 -0.01337768 -0.01226539 -0.00555363]\n",
      "[CartPole-v0 8:14 :3  ] train iteration=4  step=34   reward=1.0   done=False action=0 observation=[-0.04435249 -0.2083216  -0.01237646  0.28323432]\n",
      "[CartPole-v0 8:14 :4  ] train iteration=4  step=35   reward=1.0   done=False action=1 observation=[-0.04851892 -0.01302533 -0.00671177 -0.01332624]\n",
      "[CartPole-v0 8:14 :5  ] train iteration=4  step=36   reward=1.0   done=False action=1 observation=[-0.04877942  0.18219223 -0.0069783  -0.30811923]\n",
      "[CartPole-v0 8:14 :6  ] train iteration=4  step=37   reward=1.0   done=False action=1 observation=[-0.04513558  0.37741292 -0.01314068 -0.60299473]\n",
      "[CartPole-v0 8:14 :7  ] train iteration=4  step=38   reward=1.0   done=False action=1 observation=[-0.03758732  0.57271617 -0.02520058 -0.89978757]\n",
      "[CartPole-v0 8:14 :8  ] train iteration=4  step=39   reward=1.0   done=False action=1 observation=[-0.026133    0.7681704  -0.04319633 -1.20028401]\n",
      "[CartPole-v0 8:14 :9  ] train iteration=4  step=40   reward=1.0   done=False action=1 observation=[-0.01076959  0.96382369 -0.06720201 -1.50618595]\n",
      "[CartPole-v0 8:14 :10 ] train iteration=4  step=41   reward=1.0   done=False action=1 observation=[ 0.00850688  1.15969327 -0.09732573 -1.81906966]\n",
      "[CartPole-v0 8:14 :11 ] train iteration=4  step=42   reward=1.0   done=False action=1 observation=[ 0.03170075  1.35575305 -0.13370712 -2.1403362 ]\n",
      "[CartPole-v0 8:14 :12 ] train iteration=4  step=43   reward=1.0   done=False action=0 observation=[ 0.05881581  1.16218179 -0.17651385 -1.89176376]\n",
      "[CartPole-v0 8:15 :13 ] train iteration=4  step=44   reward=1.0   done=True  action=1 observation=[ 0.08205945  1.35872641 -0.21434912 -2.23362578]\n",
      "[CartPole-v0 8:15 :1  ] train iteration=5  step=1    reward=1.0   done=False action=1 observation=[-0.04450532  0.22301279 -0.04892444 -0.31919023]\n",
      "[CartPole-v0 8:15 :2  ] train iteration=5  step=2    reward=1.0   done=False action=1 observation=[-0.04004506  0.41879615 -0.05530825 -0.62689192]\n",
      "[CartPole-v0 8:15 :3  ] train iteration=5  step=3    reward=1.0   done=False action=0 observation=[-0.03166914  0.22448803 -0.06784609 -0.35212776]\n",
      "[CartPole-v0 8:15 :4  ] train iteration=5  step=4    reward=1.0   done=False action=0 observation=[-0.02717938  0.03039318 -0.07488864 -0.08158675]\n",
      "[CartPole-v0 8:15 :5  ] train iteration=5  step=5    reward=1.0   done=False action=0 observation=[-0.02657151 -0.1635798  -0.07652038  0.18656052]\n",
      "[CartPole-v0 8:15 :6  ] train iteration=5  step=6    reward=1.0   done=False action=0 observation=[-0.02984311 -0.35752828 -0.07278917  0.45415688]\n",
      "[CartPole-v0 8:15 :7  ] train iteration=5  step=7    reward=1.0   done=False action=1 observation=[-0.03699367 -0.16145662 -0.06370603  0.13944706]\n",
      "[CartPole-v0 8:15 :8  ] train iteration=5  step=8    reward=1.0   done=False action=1 observation=[-0.04022281  0.03451717 -0.06091709 -0.17263423]\n",
      "[CartPole-v0 8:15 :9  ] train iteration=5  step=9    reward=1.0   done=False action=0 observation=[-0.03953246 -0.1596824  -0.06436977  0.10022627]\n",
      "[CartPole-v0 8:15 :10 ] train iteration=5  step=10   reward=1.0   done=False action=0 observation=[-0.04272611 -0.3538256  -0.06236525  0.3719263 ]\n",
      "[CartPole-v0 8:15 :11 ] train iteration=5  step=11   reward=1.0   done=False action=0 observation=[-0.04980262 -0.54800868 -0.05492672  0.64431116]\n",
      "[CartPole-v0 8:15 :12 ] train iteration=5  step=12   reward=1.0   done=False action=1 observation=[-0.0607628  -0.352166   -0.0420405   0.33484983]\n",
      "[CartPole-v0 8:15 :13 ] train iteration=5  step=13   reward=1.0   done=False action=1 observation=[-0.06780612 -0.15647173 -0.0353435   0.02921152]\n",
      "[CartPole-v0 8:15 :14 ] train iteration=5  step=14   reward=1.0   done=False action=1 observation=[-0.07093555  0.03913878 -0.03475927 -0.27440982]\n",
      "[CartPole-v0 8:15 :15 ] train iteration=5  step=15   reward=1.0   done=False action=1 observation=[-0.07015278  0.23473899 -0.04024747 -0.57785008]\n",
      "[CartPole-v0 8:15 :16 ] train iteration=5  step=16   reward=1.0   done=False action=0 observation=[-0.065458    0.04020356 -0.05180447 -0.2981128 ]\n",
      "[CartPole-v0 8:15 :17 ] train iteration=5  step=17   reward=1.0   done=False action=0 observation=[-0.06465393 -0.15414313 -0.05776672 -0.02220756]\n",
      "[CartPole-v0 8:15 :18 ] train iteration=5  step=18   reward=1.0   done=False action=1 observation=[-0.06773679  0.04175763 -0.05821087 -0.33254252]\n",
      "[CartPole-v0 8:15 :19 ] train iteration=5  step=19   reward=1.0   done=False action=0 observation=[-0.06690164 -0.15248955 -0.06486173 -0.05876961]\n",
      "[CartPole-v0 8:15 :20 ] train iteration=5  step=20   reward=1.0   done=False action=0 observation=[-0.06995143 -0.34662443 -0.06603712  0.21276441]\n",
      "[CartPole-v0 8:15 :21 ] train iteration=5  step=21   reward=1.0   done=False action=1 observation=[-0.07688391 -0.15062353 -0.06178183 -0.09999693]\n",
      "[CartPole-v0 8:15 :22 ] train iteration=5  step=22   reward=1.0   done=False action=1 observation=[-0.07989639  0.04532695 -0.06378177 -0.41151417]\n",
      "[CartPole-v0 8:15 :23 ] train iteration=5  step=23   reward=1.0   done=False action=0 observation=[-0.07898985 -0.14883557 -0.07201205 -0.13960173]\n",
      "[CartPole-v0 8:15 :24 ] train iteration=5  step=24   reward=1.0   done=False action=1 observation=[-0.08196656  0.04723993 -0.07480409 -0.45410597]\n",
      "[CartPole-v0 8:15 :25 ] train iteration=5  step=25   reward=1.0   done=False action=0 observation=[-0.08102176 -0.14674897 -0.08388621 -0.18590825]\n",
      "[CartPole-v0 8:15 :26 ] train iteration=5  step=26   reward=1.0   done=False action=0 observation=[-0.08395674 -0.34057677 -0.08760437  0.07917746]\n",
      "[CartPole-v0 8:15 :27 ] train iteration=5  step=27   reward=1.0   done=False action=1 observation=[-0.09076827 -0.14431532 -0.08602082 -0.23980853]\n",
      "[CartPole-v0 8:15 :28 ] train iteration=5  step=28   reward=1.0   done=False action=1 observation=[-0.09365458  0.05192341 -0.09081699 -0.55833717]\n",
      "[CartPole-v0 8:15 :29 ] train iteration=5  step=29   reward=1.0   done=False action=0 observation=[-0.09261611 -0.14181423 -0.10198373 -0.29559182]\n",
      "[CartPole-v0 8:15 :30 ] train iteration=5  step=30   reward=1.0   done=False action=0 observation=[-0.0954524  -0.33534561 -0.10789557 -0.03673436]\n",
      "[CartPole-v0 8:15 :31 ] train iteration=5  step=31   reward=1.0   done=False action=1 observation=[-0.10215931 -0.13885513 -0.10863026 -0.36141596]\n",
      "[CartPole-v0 8:15 :32 ] train iteration=5  step=32   reward=1.0   done=False action=1 observation=[-0.10493641  0.05762971 -0.11585858 -0.68628047]\n",
      "[CartPole-v0 8:15 :33 ] train iteration=5  step=33   reward=1.0   done=False action=1 observation=[-0.10378382  0.25415313 -0.12958419 -1.01307561]\n",
      "[CartPole-v0 8:15 :34 ] train iteration=5  step=34   reward=1.0   done=False action=1 observation=[-0.09870075  0.45074319 -0.1498457  -1.34347951]\n",
      "[CartPole-v0 8:15 :35 ] train iteration=5  step=35   reward=1.0   done=False action=1 observation=[-0.08968589  0.64739856 -0.17671529 -1.67904697]\n",
      "[CartPole-v0 8:16 :36 ] train iteration=5  step=36   reward=1.0   done=True  action=0 observation=[-0.07673792  0.45471074 -0.21029623 -1.4462008 ]\n",
      "[CartPole-v0 8:16 :1  ] train iteration=5  step=37   reward=1.0   done=False action=0 observation=[ 0.01319962 -0.18486501 -0.00309821  0.31524012]\n",
      "[CartPole-v0 8:16 :2  ] train iteration=5  step=38   reward=1.0   done=False action=1 observation=[0.00950232 0.01030094 0.00320659 0.02158174]\n",
      "[CartPole-v0 8:16 :3  ] train iteration=5  step=39   reward=1.0   done=False action=1 observation=[ 0.00970834  0.20537676  0.00363822 -0.27008775]\n",
      "[CartPole-v0 8:16 :4  ] train iteration=5  step=40   reward=1.0   done=False action=0 observation=[ 0.01381588  0.01020308 -0.00176353  0.02374047]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:16 :5  ] train iteration=5  step=41   reward=1.0   done=False action=1 observation=[ 0.01401994  0.20535028 -0.00128872 -0.26949835]\n",
      "[CartPole-v0 8:16 :6  ] train iteration=5  step=42   reward=1.0   done=False action=1 observation=[ 0.01812694  0.40049059 -0.00667869 -0.56258747]\n",
      "[CartPole-v0 8:16 :7  ] train iteration=5  step=43   reward=1.0   done=False action=1 observation=[ 0.02613676  0.59570562 -0.01793044 -0.85736701]\n",
      "[CartPole-v0 8:16 :8  ] train iteration=5  step=44   reward=1.0   done=False action=0 observation=[ 0.03805087  0.40083249 -0.03507778 -0.57037556]\n",
      "[CartPole-v0 8:16 :9  ] train iteration=5  step=45   reward=1.0   done=False action=0 observation=[ 0.04606752  0.20621958 -0.04648529 -0.28894652]\n",
      "[CartPole-v0 8:16 :10 ] train iteration=5  step=46   reward=1.0   done=False action=1 observation=[ 0.05019191  0.40197252 -0.05226422 -0.5959205 ]\n",
      "[CartPole-v0 8:16 :11 ] train iteration=5  step=47   reward=1.0   done=False action=0 observation=[ 0.05823136  0.20761946 -0.06418263 -0.32014767]\n",
      "[CartPole-v0 8:16 :12 ] train iteration=5  step=48   reward=1.0   done=False action=1 observation=[ 0.06238375  0.40359396 -0.07058558 -0.63236089]\n",
      "[CartPole-v0 8:16 :13 ] train iteration=5  step=49   reward=1.0   done=False action=1 observation=[ 0.07045563  0.59962599 -0.0832328  -0.94641165]\n",
      "[CartPole-v0 8:16 :14 ] train iteration=5  step=50   reward=1.0   done=False action=0 observation=[ 0.08244815  0.40571763 -0.10216103 -0.68099823]\n",
      "[CartPole-v0 8:16 :15 ] train iteration=5  step=51   reward=1.0   done=False action=1 observation=[ 0.0905625   0.60209896 -0.115781   -1.00401748]\n",
      "[CartPole-v0 8:16 :16 ] train iteration=5  step=52   reward=1.0   done=False action=0 observation=[ 0.10260448  0.40869792 -0.13586135 -0.7498218 ]\n",
      "[CartPole-v0 8:16 :17 ] train iteration=5  step=53   reward=1.0   done=False action=1 observation=[ 0.11077844  0.60540609 -0.15085778 -1.08198554]\n",
      "[CartPole-v0 8:16 :18 ] train iteration=5  step=54   reward=1.0   done=False action=0 observation=[ 0.12288656  0.41256204 -0.17249749 -0.84018894]\n",
      "[CartPole-v0 8:16 :19 ] train iteration=5  step=55   reward=1.0   done=False action=0 observation=[ 0.1311378   0.22016172 -0.18930127 -0.60633467]\n",
      "[CartPole-v0 8:16 :20 ] train iteration=5  step=56   reward=1.0   done=False action=0 observation=[ 0.13554104  0.0281203  -0.20142797 -0.37874127]\n",
      "[CartPole-v0 8:16 :21 ] train iteration=5  step=57   reward=1.0   done=False action=0 observation=[ 0.13610344 -0.1636567  -0.20900279 -0.155712  ]\n",
      "[CartPole-v0 8:17 :22 ] train iteration=5  step=58   reward=1.0   done=True  action=0 observation=[ 0.13283031 -0.35526911 -0.21211703  0.06445145]\n",
      "[CartPole-v0 8:17 :1  ] train iteration=5  step=59   reward=1.0   done=False action=0 observation=[-0.00901395 -0.19560802 -0.01849655  0.24772046]\n",
      "[CartPole-v0 8:17 :2  ] train iteration=5  step=60   reward=1.0   done=False action=1 observation=[-0.01292611 -0.00022686 -0.01354214 -0.05073882]\n",
      "[CartPole-v0 8:17 :3  ] train iteration=5  step=61   reward=1.0   done=False action=0 observation=[-0.01293065 -0.19515204 -0.01455692  0.23764087]\n",
      "[CartPole-v0 8:17 :4  ] train iteration=5  step=62   reward=1.0   done=False action=0 observation=[-0.01683369 -0.39006303 -0.0098041   0.5256968 ]\n",
      "[CartPole-v0 8:17 :5  ] train iteration=5  step=63   reward=1.0   done=False action=0 observation=[-2.46349521e-02 -5.85045661e-01  7.09838136e-04  8.15274327e-01]\n",
      "[CartPole-v0 8:17 :6  ] train iteration=5  step=64   reward=1.0   done=False action=0 observation=[-0.03633587 -0.78017732  0.01701532  1.10818044]\n",
      "[CartPole-v0 8:17 :7  ] train iteration=5  step=65   reward=1.0   done=False action=1 observation=[-0.05193941 -0.58528309  0.03917893  0.82088368]\n",
      "[CartPole-v0 8:17 :8  ] train iteration=5  step=66   reward=1.0   done=False action=0 observation=[-0.06364507 -0.78091864  0.05559661  1.12562746]\n",
      "[CartPole-v0 8:17 :9  ] train iteration=5  step=67   reward=1.0   done=False action=1 observation=[-0.07926345 -0.58656761  0.07810916  0.85088833]\n",
      "[CartPole-v0 8:17 :10 ] train iteration=5  step=68   reward=1.0   done=False action=0 observation=[-0.0909948  -0.78266273  0.09512692  1.16707493]\n",
      "[CartPole-v0 8:17 :11 ] train iteration=5  step=69   reward=1.0   done=False action=0 observation=[-0.10664805 -0.97888497  0.11846842  1.48800272]\n",
      "[CartPole-v0 8:17 :12 ] train iteration=5  step=70   reward=1.0   done=False action=1 observation=[-0.12622575 -0.78538865  0.14822848  1.23454091]\n",
      "[CartPole-v0 8:17 :13 ] train iteration=5  step=71   reward=1.0   done=False action=0 observation=[-0.14193353 -0.98207192  0.17291929  1.56975041]\n",
      "[CartPole-v0 8:17 :14 ] train iteration=5  step=72   reward=1.0   done=False action=0 observation=[-0.16157496 -1.1787849   0.2043143   1.91100472]\n",
      "[CartPole-v0 8:18 :15 ] train iteration=5  step=73   reward=1.0   done=True  action=0 observation=[-0.18515066 -1.37544089  0.2425344   2.2595045 ]\n",
      "[CartPole-v0 8:18 :1  ] train iteration=6  step=1    reward=1.0   done=False action=1 observation=[-0.00649145  0.22647799 -0.0027861  -0.31866249]\n",
      "[CartPole-v0 8:18 :2  ] train iteration=6  step=2    reward=1.0   done=False action=0 observation=[-0.00196189  0.03139583 -0.00915935 -0.0268595 ]\n",
      "[CartPole-v0 8:18 :3  ] train iteration=6  step=3    reward=1.0   done=False action=1 observation=[-0.00133398  0.22664792 -0.00969654 -0.32241817]\n",
      "[CartPole-v0 8:18 :4  ] train iteration=6  step=4    reward=1.0   done=False action=0 observation=[ 0.00319898  0.03166539 -0.0161449  -0.03280884]\n",
      "[CartPole-v0 8:18 :5  ] train iteration=6  step=5    reward=1.0   done=False action=0 observation=[ 0.00383229 -0.16322137 -0.01680108  0.25473679]\n",
      "[CartPole-v0 8:18 :6  ] train iteration=6  step=6    reward=1.0   done=False action=1 observation=[ 0.00056786  0.03213639 -0.01170634 -0.04319778]\n",
      "[CartPole-v0 8:18 :7  ] train iteration=6  step=7    reward=1.0   done=False action=1 observation=[ 0.00121059  0.22742424 -0.0125703  -0.33955105]\n",
      "[CartPole-v0 8:18 :8  ] train iteration=6  step=8    reward=1.0   done=False action=0 observation=[ 0.00575907  0.03248338 -0.01936132 -0.05085845]\n",
      "[CartPole-v0 8:18 :9  ] train iteration=6  step=9    reward=1.0   done=False action=1 observation=[ 0.00640874  0.22787753 -0.02037849 -0.3495866 ]\n",
      "[CartPole-v0 8:18 :10 ] train iteration=6  step=10   reward=1.0   done=False action=1 observation=[ 0.01096629  0.42328329 -0.02737022 -0.64862524]\n",
      "[CartPole-v0 8:18 :11 ] train iteration=6  step=11   reward=1.0   done=False action=1 observation=[ 0.01943196  0.61877563 -0.04034272 -0.94979976]\n",
      "[CartPole-v0 8:18 :12 ] train iteration=6  step=12   reward=1.0   done=False action=1 observation=[ 0.03180747  0.81441674 -0.05933872 -1.2548802 ]\n",
      "[CartPole-v0 8:18 :13 ] train iteration=6  step=13   reward=1.0   done=False action=0 observation=[ 0.0480958   0.62010269 -0.08443632 -0.98135747]\n",
      "[CartPole-v0 8:18 :14 ] train iteration=6  step=14   reward=1.0   done=False action=0 observation=[ 0.06049786  0.4262076  -0.10406347 -0.71634579]\n",
      "[CartPole-v0 8:18 :15 ] train iteration=6  step=15   reward=1.0   done=False action=0 observation=[ 0.06902201  0.23266812 -0.11839039 -0.45814653]\n",
      "[CartPole-v0 8:18 :16 ] train iteration=6  step=16   reward=1.0   done=False action=0 observation=[ 0.07367537  0.03940134 -0.12755332 -0.20500117]\n",
      "[CartPole-v0 8:18 :17 ] train iteration=6  step=17   reward=1.0   done=False action=0 observation=[ 0.0744634  -0.15368768 -0.13165334  0.04488033]\n",
      "[CartPole-v0 8:18 :18 ] train iteration=6  step=18   reward=1.0   done=False action=0 observation=[ 0.07138965 -0.34670015 -0.13075573  0.29329925]\n",
      "[CartPole-v0 8:18 :19 ] train iteration=6  step=19   reward=1.0   done=False action=0 observation=[ 0.06445564 -0.539739   -0.12488975  0.542053  ]\n",
      "[CartPole-v0 8:18 :20 ] train iteration=6  step=20   reward=1.0   done=False action=0 observation=[ 0.05366086 -0.73290481 -0.11404869  0.79292278]\n",
      "[CartPole-v0 8:18 :21 ] train iteration=6  step=21   reward=1.0   done=False action=0 observation=[ 0.03900277 -0.92629183 -0.09819023  1.04766112]\n",
      "[CartPole-v0 8:18 :22 ] train iteration=6  step=22   reward=1.0   done=False action=0 observation=[ 0.02047693 -1.11998339 -0.07723701  1.30797745]\n",
      "[CartPole-v0 8:18 :23 ] train iteration=6  step=23   reward=1.0   done=False action=0 observation=[-0.00192274 -1.3140463  -0.05107746  1.57551886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:18 :24 ] train iteration=6  step=24   reward=1.0   done=False action=1 observation=[-0.02820366 -1.11835406 -0.01956708  1.26735308]\n",
      "[CartPole-v0 8:18 :25 ] train iteration=6  step=25   reward=1.0   done=False action=0 observation=[-0.05057074 -1.31322066  0.00577998  1.55384468]\n",
      "[CartPole-v0 8:18 :26 ] train iteration=6  step=26   reward=1.0   done=False action=1 observation=[-0.07683516 -1.11816847  0.03685687  1.26297057]\n",
      "[CartPole-v0 8:18 :27 ] train iteration=6  step=27   reward=1.0   done=False action=1 observation=[-0.09919853 -0.92353661  0.06211628  0.98205453]\n",
      "[CartPole-v0 8:18 :28 ] train iteration=6  step=28   reward=1.0   done=False action=1 observation=[-0.11766926 -0.72929957  0.08175737  0.70951132]\n",
      "[CartPole-v0 8:18 :29 ] train iteration=6  step=29   reward=1.0   done=False action=1 observation=[-0.13225525 -0.53539944  0.0959476   0.44364253]\n",
      "[CartPole-v0 8:18 :30 ] train iteration=6  step=30   reward=1.0   done=False action=1 observation=[-0.14296324 -0.34175673  0.10482045  0.18267978]\n",
      "[CartPole-v0 8:18 :31 ] train iteration=6  step=31   reward=1.0   done=False action=1 observation=[-0.14979837 -0.14827864  0.10847405 -0.07518365]\n",
      "[CartPole-v0 8:18 :32 ] train iteration=6  step=32   reward=1.0   done=False action=0 observation=[-0.15276395 -0.34477498  0.10697037  0.24965735]\n",
      "[CartPole-v0 8:18 :33 ] train iteration=6  step=33   reward=1.0   done=False action=1 observation=[-0.15965945 -0.15133032  0.11196352 -0.00746173]\n",
      "[CartPole-v0 8:18 :34 ] train iteration=6  step=34   reward=1.0   done=False action=1 observation=[-0.16268605  0.04202269  0.11181428 -0.26282672]\n",
      "[CartPole-v0 8:18 :35 ] train iteration=6  step=35   reward=1.0   done=False action=1 observation=[-0.1618456   0.23538576  0.10655775 -0.51825513]\n",
      "[CartPole-v0 8:18 :36 ] train iteration=6  step=36   reward=1.0   done=False action=0 observation=[-0.15713788  0.03893762  0.09619265 -0.19398556]\n",
      "[CartPole-v0 8:18 :37 ] train iteration=6  step=37   reward=1.0   done=False action=1 observation=[-0.15635913  0.23256136  0.09231294 -0.45484145]\n",
      "[CartPole-v0 8:18 :38 ] train iteration=6  step=38   reward=1.0   done=False action=1 observation=[-0.1517079   0.42626508  0.08321611 -0.71705843]\n",
      "[CartPole-v0 8:18 :39 ] train iteration=6  step=39   reward=1.0   done=False action=0 observation=[-0.1431826   0.23009606  0.06887494 -0.39938584]\n",
      "[CartPole-v0 8:18 :40 ] train iteration=6  step=40   reward=1.0   done=False action=0 observation=[-0.13858068  0.0340681   0.06088722 -0.08580784]\n",
      "[CartPole-v0 8:18 :41 ] train iteration=6  step=41   reward=1.0   done=False action=0 observation=[-0.13789932 -0.16187138  0.05917107  0.22544654]\n",
      "[CartPole-v0 8:18 :42 ] train iteration=6  step=42   reward=1.0   done=False action=1 observation=[-0.14113675  0.03235718  0.06368    -0.04800028]\n",
      "[CartPole-v0 8:18 :43 ] train iteration=6  step=43   reward=1.0   done=False action=1 observation=[-0.1404896   0.22651095  0.06271999 -0.31993137]\n",
      "[CartPole-v0 8:18 :44 ] train iteration=6  step=44   reward=1.0   done=False action=1 observation=[-0.13595938  0.4206862   0.05632136 -0.59219396]\n",
      "[CartPole-v0 8:18 :45 ] train iteration=6  step=45   reward=1.0   done=False action=0 observation=[-0.12754566  0.2248229   0.04447748 -0.28231513]\n",
      "[CartPole-v0 8:18 :46 ] train iteration=6  step=46   reward=1.0   done=False action=1 observation=[-0.1230492   0.41928315  0.03883118 -0.56064496]\n",
      "[CartPole-v0 8:18 :47 ] train iteration=6  step=47   reward=1.0   done=False action=1 observation=[-0.11466354  0.61383921  0.02761828 -0.84084557]\n",
      "[CartPole-v0 8:18 :48 ] train iteration=6  step=48   reward=1.0   done=False action=1 observation=[-0.10238676  0.80857346  0.01080137 -1.1247168 ]\n",
      "[CartPole-v0 8:18 :49 ] train iteration=6  step=49   reward=1.0   done=False action=0 observation=[-0.08621529  0.61331161 -0.01169297 -0.82866557]\n",
      "[CartPole-v0 8:19 :50 ] train iteration=6  step=50   reward=1.0   done=True  action=0 observation=[-0.07394905  0.41835145 -0.02826628 -0.53968298]\n",
      "[CartPole-v0 8:19 :1  ] train iteration=6  step=51   reward=1.0   done=False action=1 observation=[-0.04589619  0.17428554  0.01451498 -0.25352143]\n",
      "[CartPole-v0 8:19 :2  ] train iteration=6  step=52   reward=1.0   done=False action=0 observation=[-0.04241048 -0.02104063  0.00944455  0.04370421]\n",
      "[CartPole-v0 8:19 :3  ] train iteration=6  step=53   reward=1.0   done=False action=0 observation=[-0.04283129 -0.21629673  0.01031864  0.33935195]\n",
      "[CartPole-v0 8:19 :4  ] train iteration=6  step=54   reward=1.0   done=False action=1 observation=[-0.04715723 -0.02132311  0.01710568  0.04994072]\n",
      "[CartPole-v0 8:19 :5  ] train iteration=6  step=55   reward=1.0   done=False action=1 observation=[-0.04758369  0.17354944  0.01810449 -0.23729652]\n",
      "[CartPole-v0 8:19 :6  ] train iteration=6  step=56   reward=1.0   done=False action=0 observation=[-0.0441127  -0.02182642  0.01335856  0.06104167]\n",
      "[CartPole-v0 8:19 :7  ] train iteration=6  step=57   reward=1.0   done=False action=1 observation=[-0.04454923  0.17310148  0.01457939 -0.22739678]\n",
      "[CartPole-v0 8:19 :8  ] train iteration=6  step=58   reward=1.0   done=False action=1 observation=[-0.0410872   0.36801207  0.01003146 -0.51544541]\n",
      "[CartPole-v0 8:19 :9  ] train iteration=6  step=59   reward=1.0   done=False action=1 observation=[-3.37269591e-02  5.62991331e-01 -2.77451236e-04 -8.04950388e-01]\n",
      "[CartPole-v0 8:19 :10 ] train iteration=6  step=60   reward=1.0   done=False action=0 observation=[-0.02246713  0.36787318 -0.01637646 -0.51235475]\n",
      "[CartPole-v0 8:19 :11 ] train iteration=6  step=61   reward=1.0   done=False action=1 observation=[-0.01510967  0.56322193 -0.02662355 -0.81015304]\n",
      "[CartPole-v0 8:19 :12 ] train iteration=6  step=62   reward=1.0   done=False action=0 observation=[-0.00384523  0.36847467 -0.04282661 -0.52596207]\n",
      "[CartPole-v0 8:19 :13 ] train iteration=6  step=63   reward=1.0   done=False action=0 observation=[ 0.00352426  0.1739807  -0.05334586 -0.24707579]\n",
      "[CartPole-v0 8:19 :14 ] train iteration=6  step=64   reward=1.0   done=False action=0 observation=[ 0.00700388 -0.0203404  -0.05828737  0.02831496]\n",
      "[CartPole-v0 8:19 :15 ] train iteration=6  step=65   reward=1.0   done=False action=1 observation=[ 0.00659707  0.17556689 -0.05772107 -0.28217372]\n",
      "[CartPole-v0 8:19 :16 ] train iteration=6  step=66   reward=1.0   done=False action=1 observation=[ 0.01010841  0.37146263 -0.06336455 -0.59248853]\n",
      "[CartPole-v0 8:19 :17 ] train iteration=6  step=67   reward=1.0   done=False action=1 observation=[ 0.01753766  0.56741171 -0.07521432 -0.90443901]\n",
      "[CartPole-v0 8:19 :18 ] train iteration=6  step=68   reward=1.0   done=False action=0 observation=[ 0.02888589  0.37338458 -0.0933031  -0.63631332]\n",
      "[CartPole-v0 8:19 :19 ] train iteration=6  step=69   reward=1.0   done=False action=0 observation=[ 0.03635359  0.1796792  -0.10602936 -0.37441039]\n",
      "[CartPole-v0 8:19 :20 ] train iteration=6  step=70   reward=1.0   done=False action=0 observation=[ 0.03994717 -0.01378942 -0.11351757 -0.11695144]\n",
      "[CartPole-v0 8:19 :21 ] train iteration=6  step=71   reward=1.0   done=False action=0 observation=[ 0.03967138 -0.20711732 -0.1158566   0.13787142]\n",
      "[CartPole-v0 8:19 :22 ] train iteration=6  step=72   reward=1.0   done=False action=1 observation=[ 0.03552903 -0.01054299 -0.11309917 -0.18899905]\n",
      "[CartPole-v0 8:19 :23 ] train iteration=6  step=73   reward=1.0   done=False action=0 observation=[ 0.03531817 -0.20388048 -0.11687915  0.06597405]\n",
      "[CartPole-v0 8:19 :24 ] train iteration=6  step=74   reward=1.0   done=False action=1 observation=[ 0.03124056 -0.00729364 -0.11555967 -0.26117865]\n",
      "[CartPole-v0 8:19 :25 ] train iteration=6  step=75   reward=1.0   done=False action=0 observation=[ 0.03109469 -0.20059265 -0.12078325 -0.00706296]\n",
      "[CartPole-v0 8:19 :26 ] train iteration=6  step=76   reward=1.0   done=False action=0 observation=[ 0.02708284 -0.39379396 -0.12092451  0.24520368]\n",
      "[CartPole-v0 8:19 :27 ] train iteration=6  step=77   reward=1.0   done=False action=1 observation=[ 0.01920696 -0.19717106 -0.11602043 -0.08304214]\n",
      "[CartPole-v0 8:19 :28 ] train iteration=6  step=78   reward=1.0   done=False action=1 observation=[ 0.01526354 -0.00059363 -0.11768127 -0.4099595 ]\n",
      "[CartPole-v0 8:19 :29 ] train iteration=6  step=79   reward=1.0   done=False action=0 observation=[ 0.01525167 -0.1938677  -0.12588046 -0.15657204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:19 :30 ] train iteration=6  step=80   reward=1.0   done=False action=0 observation=[ 0.01137431 -0.38698362 -0.1290119   0.09389862]\n",
      "[CartPole-v0 8:19 :31 ] train iteration=6  step=81   reward=1.0   done=False action=1 observation=[ 0.00363464 -0.19027126 -0.12713393 -0.23654213]\n",
      "[CartPole-v0 8:19 :32 ] train iteration=6  step=82   reward=1.0   done=False action=0 observation=[-1.70785535e-04 -3.83369290e-01 -1.31864775e-01  1.34905062e-02]\n",
      "[CartPole-v0 8:19 :33 ] train iteration=6  step=83   reward=1.0   done=False action=0 observation=[-0.00783817 -0.57637783 -0.13159497  0.2618339 ]\n",
      "[CartPole-v0 8:19 :34 ] train iteration=6  step=84   reward=1.0   done=False action=0 observation=[-0.01936573 -0.76939983 -0.12635829  0.51028621]\n",
      "[CartPole-v0 8:19 :35 ] train iteration=6  step=85   reward=1.0   done=False action=1 observation=[-0.03475372 -0.57274549 -0.11615256  0.1806059 ]\n",
      "[CartPole-v0 8:19 :36 ] train iteration=6  step=86   reward=1.0   done=False action=0 observation=[-0.04620863 -0.76603032 -0.11254044  0.43450747]\n",
      "[CartPole-v0 8:19 :37 ] train iteration=6  step=87   reward=1.0   done=False action=0 observation=[-0.06152924 -0.95939412 -0.1038503   0.68970124]\n",
      "[CartPole-v0 8:19 :38 ] train iteration=6  step=88   reward=1.0   done=False action=0 observation=[-0.08071712 -1.15293331 -0.09005627  0.94796884]\n",
      "[CartPole-v0 8:19 :39 ] train iteration=6  step=89   reward=1.0   done=False action=1 observation=[-0.10377579 -0.95672177 -0.07109689  0.62840342]\n",
      "[CartPole-v0 8:19 :40 ] train iteration=6  step=90   reward=1.0   done=False action=1 observation=[-0.12291022 -0.76068337 -0.05852883  0.31420382]\n",
      "[CartPole-v0 8:19 :41 ] train iteration=6  step=91   reward=1.0   done=False action=1 observation=[-0.13812389 -0.56477863 -0.05224475  0.00365223]\n",
      "[CartPole-v0 8:19 :42 ] train iteration=6  step=92   reward=1.0   done=False action=1 observation=[-0.14941946 -0.36894785 -0.0521717  -0.3050461 ]\n",
      "[CartPole-v0 8:19 :43 ] train iteration=6  step=93   reward=1.0   done=False action=0 observation=[-0.15679842 -0.563289   -0.05827263 -0.02926254]\n",
      "[CartPole-v0 8:19 :44 ] train iteration=6  step=94   reward=1.0   done=False action=0 observation=[-0.1680642  -0.75752897 -0.05885788  0.24448041]\n",
      "[CartPole-v0 8:19 :45 ] train iteration=6  step=95   reward=1.0   done=False action=1 observation=[-0.18321478 -0.56161789 -0.05396827 -0.06617157]\n",
      "[CartPole-v0 8:19 :46 ] train iteration=6  step=96   reward=1.0   done=False action=1 observation=[-0.19444714 -0.36576539 -0.0552917  -0.37538157]\n",
      "[CartPole-v0 8:19 :47 ] train iteration=6  step=97   reward=1.0   done=False action=0 observation=[-0.20176245 -0.56006017 -0.06279933 -0.10063226]\n",
      "[CartPole-v0 8:19 :48 ] train iteration=6  step=98   reward=1.0   done=False action=1 observation=[-0.21296365 -0.36409704 -0.06481198 -0.41244838]\n",
      "[CartPole-v0 8:19 :49 ] train iteration=6  step=99   reward=1.0   done=False action=1 observation=[-0.22024559 -0.16811909 -0.07306094 -0.72483949]\n",
      "[CartPole-v0 8:20 :50 ] train iteration=6  step=100  reward=1.0   done=True  action=1 observation=[-0.22360797  0.02793308 -0.08755773 -1.03959403]\n",
      "[CartPole-v0 8:20 :1  ] train iteration=6  step=101  reward=1.0   done=False action=1 observation=[-0.02938871  0.18113548  0.02413068 -0.31075176]\n",
      "[CartPole-v0 8:20 :2  ] train iteration=6  step=102  reward=1.0   done=False action=0 observation=[-0.025766   -0.01432181  0.01791565 -0.01055745]\n",
      "[CartPole-v0 8:20 :3  ] train iteration=6  step=103  reward=1.0   done=False action=1 observation=[-0.02605244  0.18053868  0.0177045  -0.29753437]\n",
      "[CartPole-v0 8:20 :4  ] train iteration=6  step=104  reward=1.0   done=False action=1 observation=[-0.02244167  0.37540384  0.01175381 -0.58458144]\n",
      "[CartPole-v0 8:20 :5  ] train iteration=6  step=105  reward=1.0   done=False action=0 observation=[-1.49335898e-02  1.80119231e-01  6.21803334e-05 -2.88219221e-01]\n",
      "[CartPole-v0 8:20 :6  ] train iteration=6  step=106  reward=1.0   done=False action=1 observation=[-0.01133121  0.3752403  -0.0057022  -0.58088254]\n",
      "[CartPole-v0 8:20 :7  ] train iteration=6  step=107  reward=1.0   done=False action=1 observation=[-0.0038264   0.57044168 -0.01731985 -0.87535629]\n",
      "[CartPole-v0 8:20 :8  ] train iteration=6  step=108  reward=1.0   done=False action=1 observation=[ 0.00758243  0.76579474 -0.03482698 -1.17343371]\n",
      "[CartPole-v0 8:20 :9  ] train iteration=6  step=109  reward=1.0   done=False action=0 observation=[ 0.02289833  0.57114235 -0.05829565 -0.89186924]\n",
      "[CartPole-v0 8:20 :10 ] train iteration=6  step=110  reward=1.0   done=False action=1 observation=[ 0.03432118  0.76700459 -0.07613304 -1.20229275]\n",
      "[CartPole-v0 8:20 :11 ] train iteration=6  step=111  reward=1.0   done=False action=1 observation=[ 0.04966127  0.96302395 -0.10017889 -1.51783157]\n",
      "[CartPole-v0 8:20 :12 ] train iteration=6  step=112  reward=1.0   done=False action=1 observation=[ 0.06892175  1.15920465 -0.13053553 -1.84003059]\n",
      "[CartPole-v0 8:20 :13 ] train iteration=6  step=113  reward=1.0   done=False action=0 observation=[ 0.09210584  0.96574346 -0.16733614 -1.59057621]\n",
      "[CartPole-v0 8:20 :14 ] train iteration=6  step=114  reward=1.0   done=False action=1 observation=[ 0.11142071  1.16241041 -0.19914766 -1.9304236 ]\n",
      "[CartPole-v0 8:21 :15 ] train iteration=6  step=115  reward=1.0   done=True  action=1 observation=[ 0.13466892  1.35903118 -0.23775613 -2.27768878]\n",
      "[CartPole-v0 8:21 :1  ] train iteration=7  step=1    reward=1.0   done=False action=0 observation=[ 0.00722404 -0.17550065 -0.03192268  0.32143564]\n",
      "[CartPole-v0 8:21 :2  ] train iteration=7  step=2    reward=1.0   done=False action=1 observation=[ 0.00371403  0.02006101 -0.02549397  0.01885892]\n",
      "[CartPole-v0 8:21 :3  ] train iteration=7  step=3    reward=1.0   done=False action=0 observation=[ 0.00411525 -0.17468622 -0.02511679  0.30339044]\n",
      "[CartPole-v0 8:21 :4  ] train iteration=7  step=4    reward=1.0   done=False action=0 observation=[ 0.00062153 -0.36944138 -0.01904898  0.58804747]\n",
      "[CartPole-v0 8:21 :5  ] train iteration=7  step=5    reward=1.0   done=False action=0 observation=[-0.0067673  -0.56429146 -0.00728803  0.87466951]\n",
      "[CartPole-v0 8:21 :6  ] train iteration=7  step=6    reward=1.0   done=False action=1 observation=[-0.01805313 -0.36907119  0.01020536  0.57970421]\n",
      "[CartPole-v0 8:21 :7  ] train iteration=7  step=7    reward=1.0   done=False action=1 observation=[-0.02543455 -0.17409373  0.02179944  0.29025358]\n",
      "[CartPole-v0 8:21 :8  ] train iteration=7  step=8    reward=1.0   done=False action=0 observation=[-0.02891643 -0.36951963  0.02760451  0.58973131]\n",
      "[CartPole-v0 8:21 :9  ] train iteration=7  step=9    reward=1.0   done=False action=1 observation=[-0.03630682 -0.17479486  0.03939914  0.30587012]\n",
      "[CartPole-v0 8:21 :10 ] train iteration=7  step=10   reward=1.0   done=False action=1 observation=[-0.03980272  0.01974415  0.04551654  0.02586842]\n",
      "[CartPole-v0 8:21 :11 ] train iteration=7  step=11   reward=1.0   done=False action=0 observation=[-0.03940784 -0.176       0.04603391  0.33255778]\n",
      "[CartPole-v0 8:21 :12 ] train iteration=7  step=12   reward=1.0   done=False action=1 observation=[-0.04292784  0.01843753  0.05268507  0.05473965]\n",
      "[CartPole-v0 8:21 :13 ] train iteration=7  step=13   reward=1.0   done=False action=0 observation=[-0.04255909 -0.17739871  0.05377986  0.36356867]\n",
      "[CartPole-v0 8:21 :14 ] train iteration=7  step=14   reward=1.0   done=False action=0 observation=[-0.04610706 -0.37324212  0.06105123  0.67271272]\n",
      "[CartPole-v0 8:21 :15 ] train iteration=7  step=15   reward=1.0   done=False action=1 observation=[-0.0535719  -0.17901952  0.07450549  0.39985951]\n",
      "[CartPole-v0 8:21 :16 ] train iteration=7  step=16   reward=1.0   done=False action=1 observation=[-0.05715229  0.01497082  0.08250268  0.13156561]\n",
      "[CartPole-v0 8:21 :17 ] train iteration=7  step=17   reward=1.0   done=False action=0 observation=[-0.05685288 -0.18123009  0.08513399  0.44909421]\n",
      "[CartPole-v0 8:21 :18 ] train iteration=7  step=18   reward=1.0   done=False action=0 observation=[-0.06047748 -0.37744656  0.09411587  0.76735212]\n",
      "[CartPole-v0 8:21 :19 ] train iteration=7  step=19   reward=1.0   done=False action=0 observation=[-0.06802641 -0.57372948  0.10946292  1.08810273]\n",
      "[CartPole-v0 8:21 :20 ] train iteration=7  step=20   reward=1.0   done=False action=0 observation=[-0.079501   -0.7701111   0.13122497  1.41302999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:21 :21 ] train iteration=7  step=21   reward=1.0   done=False action=1 observation=[-0.09490322 -0.57683682  0.15948557  1.16408064]\n",
      "[CartPole-v0 8:21 :22 ] train iteration=7  step=22   reward=1.0   done=False action=0 observation=[-0.10643996 -0.77363432  0.18276718  1.50222081]\n",
      "[CartPole-v0 8:22 :23 ] train iteration=7  step=23   reward=1.0   done=True  action=1 observation=[-0.12191264 -0.58114066  0.2128116   1.27172434]\n",
      "[CartPole-v0 8:22 :1  ] train iteration=7  step=24   reward=1.0   done=False action=1 observation=[-0.02317509  0.19447801  0.02944519 -0.25700798]\n",
      "[CartPole-v0 8:22 :2  ] train iteration=7  step=25   reward=1.0   done=False action=1 observation=[-0.01928553  0.38916747  0.02430503 -0.54025994]\n",
      "[CartPole-v0 8:22 :3  ] train iteration=7  step=26   reward=1.0   done=False action=1 observation=[-0.01150218  0.58393949  0.01349983 -0.82518671]\n",
      "[CartPole-v0 8:22 :4  ] train iteration=7  step=27   reward=1.0   done=False action=1 observation=[ 1.76611922e-04  7.78874228e-01 -3.00390397e-03 -1.11359334e+00]\n",
      "[CartPole-v0 8:22 :5  ] train iteration=7  step=28   reward=1.0   done=False action=0 observation=[ 0.0157541   0.58379185 -0.02527577 -0.82185424]\n",
      "[CartPole-v0 8:22 :6  ] train iteration=7  step=29   reward=1.0   done=False action=1 observation=[ 0.02742993  0.77925035 -0.04171286 -1.12237863]\n",
      "[CartPole-v0 8:22 :7  ] train iteration=7  step=30   reward=1.0   done=False action=1 observation=[ 0.04301494  0.97489369 -0.06416043 -1.42784839]\n",
      "[CartPole-v0 8:22 :8  ] train iteration=7  step=31   reward=1.0   done=False action=0 observation=[ 0.06251281  0.78062028 -0.0927174  -1.15588809]\n",
      "[CartPole-v0 8:22 :9  ] train iteration=7  step=32   reward=1.0   done=False action=0 observation=[ 0.07812522  0.58682129 -0.11583516 -0.89365809]\n",
      "[CartPole-v0 8:22 :10 ] train iteration=7  step=33   reward=1.0   done=False action=0 observation=[ 0.08986165  0.39344472 -0.13370832 -0.63951651]\n",
      "[CartPole-v0 8:22 :11 ] train iteration=7  step=34   reward=1.0   done=False action=0 observation=[ 0.09773054  0.20041539 -0.14649865 -0.39175009]\n",
      "[CartPole-v0 8:22 :12 ] train iteration=7  step=35   reward=1.0   done=False action=1 observation=[ 0.10173885  0.39727961 -0.15433365 -0.72679999]\n",
      "[CartPole-v0 8:22 :13 ] train iteration=7  step=36   reward=1.0   done=False action=1 observation=[ 0.10968444  0.59416031 -0.16886965 -1.0638051 ]\n",
      "[CartPole-v0 8:22 :14 ] train iteration=7  step=37   reward=1.0   done=False action=1 observation=[ 0.12156765  0.79106579 -0.19014575 -1.40437399]\n",
      "[CartPole-v0 8:23 :15 ] train iteration=7  step=38   reward=1.0   done=True  action=1 observation=[ 0.13738896  0.98797111 -0.21823323 -1.74997525]\n",
      "[CartPole-v0 8:23 :1  ] train iteration=7  step=39   reward=1.0   done=False action=0 observation=[-0.00983232 -0.20795695  0.02817655  0.26935678]\n",
      "[CartPole-v0 8:23 :2  ] train iteration=7  step=40   reward=1.0   done=False action=0 observation=[-0.01399146 -0.40346943  0.03356369  0.57079191]\n",
      "[CartPole-v0 8:23 :3  ] train iteration=7  step=41   reward=1.0   done=False action=0 observation=[-0.02206085 -0.59904559  0.04497953  0.87385679]\n",
      "[CartPole-v0 8:23 :4  ] train iteration=7  step=42   reward=1.0   done=False action=1 observation=[-0.03404176 -0.40456312  0.06245666  0.59564765]\n",
      "[CartPole-v0 8:23 :5  ] train iteration=7  step=43   reward=1.0   done=False action=0 observation=[-0.04213302 -0.600501    0.07436961  0.90733175]\n",
      "[CartPole-v0 8:23 :6  ] train iteration=7  step=44   reward=1.0   done=False action=0 observation=[-0.05414304 -0.79654673  0.09251625  1.222432  ]\n",
      "[CartPole-v0 8:23 :7  ] train iteration=7  step=45   reward=1.0   done=False action=1 observation=[-0.07007397 -0.60273039  0.11696489  0.96011179]\n",
      "[CartPole-v0 8:23 :8  ] train iteration=7  step=46   reward=1.0   done=False action=1 observation=[-0.08212858 -0.40935837  0.13616713  0.70634494]\n",
      "[CartPole-v0 8:23 :9  ] train iteration=7  step=47   reward=1.0   done=False action=0 observation=[-0.09031575 -0.60607779  0.15029402  1.03860222]\n",
      "[CartPole-v0 8:23 :10 ] train iteration=7  step=48   reward=1.0   done=False action=0 observation=[-0.10243731 -0.80284252  0.17106607  1.37444244]\n",
      "[CartPole-v0 8:23 :11 ] train iteration=7  step=49   reward=1.0   done=False action=1 observation=[-0.11849416 -0.61022102  0.19855492  1.13977598]\n",
      "[CartPole-v0 8:24 :12 ] train iteration=7  step=50   reward=1.0   done=True  action=1 observation=[-0.13069858 -0.41816915  0.22135044  0.91535048]\n",
      "[CartPole-v0 9:6  :1  ] train iteration=8  step=50  play  episode=0  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 0.03702274  0.22412742  0.02434186 -0.32344455]\n",
      "[CartPole-v0 9:6  :2  ] train iteration=8  step=50  play  episode=0  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.04150529  0.02866746  0.01787297 -0.02318568]\n",
      "[CartPole-v0 9:6  :3  ] train iteration=8  step=50  play  episode=0  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.04207864  0.2235286   0.01740926 -0.31017632]\n",
      "[CartPole-v0 9:6  :4  ] train iteration=8  step=50  play  episode=0  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.04654921  0.02816299  0.01120573 -0.01205425]\n",
      "[CartPole-v0 9:6  :5  ] train iteration=8  step=50  play  episode=0  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.04711247  0.22312246  0.01096465 -0.30118068]\n",
      "[CartPole-v0 9:6  :6  ] train iteration=8  step=50  play  episode=0  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[ 0.05157492  0.02784596  0.00494103 -0.00506   ]\n",
      "[CartPole-v0 9:6  :7  ] train iteration=8  step=50  play  episode=0  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.05213184  0.2228967   0.00483983 -0.29617988]\n",
      "[CartPole-v0 9:6  :8  ] train iteration=8  step=50  play  episode=0  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[ 0.05658977  0.02770609 -0.00108376 -0.00197449]\n",
      "[CartPole-v0 9:6  :9  ] train iteration=8  step=50  play  episode=0  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.05714389  0.22284357 -0.00112325 -0.29499916]\n",
      "[CartPole-v0 9:6  :10 ] train iteration=8  step=50  play  episode=0  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.06160077  0.02773765 -0.00702324 -0.0026707 ]\n",
      "[CartPole-v0 9:6  :11 ] train iteration=8  step=50  play  episode=0  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.06215552  0.22295961 -0.00707665 -0.29756124]\n",
      "[CartPole-v0 9:6  :12 ] train iteration=8  step=50  play  episode=0  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[ 0.06661471  0.02793925 -0.01302788 -0.00711854]\n",
      "[CartPole-v0 9:6  :13 ] train iteration=8  step=50  play  episode=0  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=1 observation=[ 0.0671735   0.22324559 -0.01317025 -0.30388328]\n",
      "[CartPole-v0 9:6  :14 ] train iteration=8  step=50  play  episode=0  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=0 observation=[ 0.07163841  0.02831379 -0.01924791 -0.01538288]\n",
      "[CartPole-v0 9:6  :15 ] train iteration=8  step=50  play  episode=0  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.07220468  0.22370642 -0.01955557 -0.31407606]\n",
      "[CartPole-v0 9:6  :16 ] train iteration=8  step=50  play  episode=0  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[ 0.07667881  0.02886842 -0.02583709 -0.02762392]\n",
      "[CartPole-v0 9:6  :17 ] train iteration=8  step=50  play  episode=0  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=1 observation=[ 0.07725618  0.22435118 -0.02638957 -0.32834545]\n",
      "[CartPole-v0 9:6  :18 ] train iteration=8  step=50  play  episode=0  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=0 observation=[ 0.0817432   0.02961466 -0.03295648 -0.04410002]\n",
      "[CartPole-v0 9:6  :19 ] train iteration=8  step=50  play  episode=0  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[ 0.0823355   0.22519332 -0.03383848 -0.34699615]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:6  :20 ] train iteration=8  step=50  play  episode=0  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=0 observation=[ 0.08683936  0.03056861 -0.0407784  -0.06517283]\n",
      "[CartPole-v0 9:6  :21 ] train iteration=8  step=50  play  episode=0  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=1 observation=[ 0.08745074  0.22625077 -0.04208186 -0.37043759]\n",
      "[CartPole-v0 9:6  :22 ] train iteration=8  step=50  play  episode=0  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=0 observation=[ 0.09197575  0.03175118 -0.04949061 -0.0913149 ]\n",
      "[CartPole-v0 9:6  :23 ] train iteration=8  step=50  play  episode=0  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=1 observation=[ 0.09261077  0.22754628 -0.05131691 -0.39919225]\n",
      "[CartPole-v0 9:6  :24 ] train iteration=8  step=50  play  episode=0  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=0 observation=[ 0.0971617   0.03318844 -0.05930075 -0.12311982]\n",
      "[CartPole-v0 9:6  :25 ] train iteration=8  step=50  play  episode=0  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[ 0.09782547 -0.161036   -0.06176315  0.15028053]\n",
      "[CartPole-v0 9:6  :26 ] train iteration=8  step=50  play  episode=0  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[ 0.09460475  0.03491349 -0.05875754 -0.16123009]\n",
      "[CartPole-v0 9:6  :27 ] train iteration=8  step=50  play  episode=0  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[ 0.09530302 -0.15932021 -0.06198214  0.11235289]\n",
      "[CartPole-v0 9:6  :28 ] train iteration=8  step=50  play  episode=0  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[ 0.09211661  0.0366326  -0.05973508 -0.19922299]\n",
      "[CartPole-v0 9:6  :29 ] train iteration=8  step=50  play  episode=0  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[ 0.09284927 -0.15758636 -0.06371954  0.07403416]\n",
      "[CartPole-v0 9:6  :30 ] train iteration=8  step=50  play  episode=0  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[ 0.08969754  0.03838847 -0.06223886 -0.23805238]\n",
      "[CartPole-v0 9:6  :31 ] train iteration=8  step=50  play  episode=0  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[ 0.09046531 -0.15579166 -0.06699991  0.03436744]\n",
      "[CartPole-v0 9:6  :32 ] train iteration=8  step=50  play  episode=0  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[ 0.08734948  0.04022393 -0.06631256 -0.2786795 ]\n",
      "[CartPole-v0 9:6  :33 ] train iteration=8  step=50  play  episode=0  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[ 0.08815395 -0.15389244 -0.07188615 -0.00762651]\n",
      "[CartPole-v0 9:6  :34 ] train iteration=8  step=50  play  episode=0  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[ 0.0850761   0.0421829  -0.07203868 -0.32209625]\n",
      "[CartPole-v0 9:6  :35 ] train iteration=8  step=50  play  episode=0  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[ 0.08591976 -0.15184322 -0.0784806  -0.05297299]\n",
      "[CartPole-v0 9:6  :36 ] train iteration=8  step=50  play  episode=0  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[ 0.0828829   0.04431121 -0.07954006 -0.3693486 ]\n",
      "[CartPole-v0 9:6  :37 ] train iteration=8  step=50  play  episode=0  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=0 observation=[ 0.08376912 -0.14959583 -0.08692704 -0.10276777]\n",
      "[CartPole-v0 9:6  :38 ] train iteration=8  step=50  play  episode=0  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=1 observation=[ 0.08077721  0.04665738 -0.08898239 -0.42156045]\n",
      "[CartPole-v0 9:6  :39 ] train iteration=8  step=50  play  episode=0  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[ 0.08171035 -0.14709861 -0.0974136  -0.15820262]\n",
      "[CartPole-v0 9:6  :40 ] train iteration=8  step=50  play  episode=0  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[ 0.07876838 -0.3407007  -0.10057765  0.1022294 ]\n",
      "[CartPole-v0 9:6  :41 ] train iteration=8  step=50  play  episode=0  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[ 0.07195437 -0.14429194 -0.09853306 -0.22041486]\n",
      "[CartPole-v0 9:6  :42 ] train iteration=8  step=50  play  episode=0  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[ 0.06906853 -0.33787749 -0.10294136  0.03963314]\n",
      "[CartPole-v0 9:6  :43 ] train iteration=8  step=50  play  episode=0  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[ 0.06231098 -0.14144155 -0.1021487  -0.28367227]\n",
      "[CartPole-v0 9:6  :44 ] train iteration=8  step=50  play  episode=0  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[ 0.05948215 -0.33496947 -0.10782214 -0.0248731 ]\n",
      "[CartPole-v0 9:6  :45 ] train iteration=8  step=50  play  episode=0  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[ 0.05278276 -0.13847972 -0.10831961 -0.34953448]\n",
      "[CartPole-v0 9:6  :46 ] train iteration=8  step=50  play  episode=0  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[ 0.05001316 -0.3319078  -0.1153103  -0.09287656]\n",
      "[CartPole-v0 9:6  :47 ] train iteration=8  step=50  play  episode=0  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[ 0.04337501 -0.52520439 -0.11716783  0.1613167 ]\n",
      "[CartPole-v0 9:6  :48 ] train iteration=8  step=50  play  episode=0  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[ 0.03287092 -0.32861696 -0.11394149 -0.16591124]\n",
      "[CartPole-v0 9:6  :49 ] train iteration=8  step=50  play  episode=0  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[ 0.02629858 -0.52193913 -0.11725972  0.08876531]\n",
      "[CartPole-v0 9:7  :50 ] train iteration=8  step=50  play  episode=0  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.0158598  -0.32534866 -0.11548441 -0.23849081]\n",
      "[CartPole-v0 9:7  :1  ] train iteration=8  step=50  play  episode=1  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 2.61865283e-04  1.71471112e-01 -1.88614158e-02 -3.15043135e-01]\n",
      "[CartPole-v0 9:7  :2  ] train iteration=8  step=50  play  episode=1  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.00369129 -0.02337716 -0.02516228 -0.02836764]\n",
      "[CartPole-v0 9:7  :3  ] train iteration=8  step=50  play  episode=1  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.00322374  0.17209643 -0.02572963 -0.32888214]\n",
      "[CartPole-v0 9:7  :4  ] train iteration=8  step=50  play  episode=1  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.00666567 -0.02264997 -0.03230727 -0.04442291]\n",
      "[CartPole-v0 9:7  :5  ] train iteration=8  step=50  play  episode=1  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[ 0.00621267 -0.21729411 -0.03319573  0.23789426]\n",
      "[CartPole-v0 9:7  :6  ] train iteration=8  step=50  play  episode=1  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[ 0.00186679 -0.02171403 -0.02843785 -0.06507199]\n",
      "[CartPole-v0 9:7  :7  ] train iteration=8  step=50  play  episode=1  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[ 0.00143251 -0.21641696 -0.02973929  0.21850472]\n",
      "[CartPole-v0 9:7  :8  ] train iteration=8  step=50  play  episode=1  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.00289583 -0.02088279 -0.02536919 -0.08340891]\n",
      "[CartPole-v0 9:7  :9  ] train iteration=8  step=50  play  episode=1  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.00331348 -0.21563207 -0.02703737  0.20116327]\n",
      "[CartPole-v0 9:7  :10 ] train iteration=8  step=50  play  episode=1  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.00762613 -0.02013407 -0.02301411 -0.09992456]\n",
      "[CartPole-v0 9:7  :11 ] train iteration=8  step=50  play  episode=1  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.00802881 -0.21491876 -0.0250126   0.18540955]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:7  :12 ] train iteration=8  step=50  play  episode=1  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.01232718 -0.01944802 -0.02130441 -0.11505778]\n",
      "[CartPole-v0 9:7  :13 ] train iteration=8  step=50  play  episode=1  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.01271614 -0.21425834 -0.02360556  0.17082836]\n",
      "[CartPole-v0 9:7  :14 ] train iteration=8  step=50  play  episode=1  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.01700131 -0.01880661 -0.02018899 -0.12920694]\n",
      "[CartPole-v0 9:7  :15 ] train iteration=8  step=50  play  episode=1  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[-0.01737744 -0.21363362 -0.02277313  0.15703886]\n",
      "[CartPole-v0 9:7  :16 ] train iteration=8  step=50  play  episode=1  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[-0.02165011 -0.01819315 -0.01963236 -0.14274056]\n",
      "[CartPole-v0 9:7  :17 ] train iteration=8  step=50  play  episode=1  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.02201398 -0.21302851 -0.02248717  0.14368462]\n",
      "[CartPole-v0 9:7  :18 ] train iteration=8  step=50  play  episode=1  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.02627455 -0.01759185 -0.01961347 -0.15600692]\n",
      "[CartPole-v0 9:7  :19 ] train iteration=8  step=50  play  episode=1  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[-0.02662638 -0.21242757 -0.02273361  0.13042446]\n",
      "[CartPole-v0 9:7  :20 ] train iteration=8  step=50  play  episode=1  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[-0.03087494 -0.01698747 -0.02012512 -0.16934305]\n",
      "[CartPole-v0 9:7  :21 ] train iteration=8  step=50  play  episode=1  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.03121468 -0.21181566 -0.02351198  0.11692367]\n",
      "[CartPole-v0 9:7  :22 ] train iteration=8  step=50  play  episode=1  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.035451   -0.01636486 -0.02117351 -0.18308339]\n",
      "[CartPole-v0 9:7  :23 ] train iteration=8  step=50  play  episode=1  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.0357783  -0.21117754 -0.02483518  0.10284559]\n",
      "[CartPole-v0 9:7  :24 ] train iteration=8  step=50  play  episode=1  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[-0.04000185 -0.01570864 -0.02277827 -0.19756814]\n",
      "[CartPole-v0 9:7  :25 ] train iteration=8  step=50  play  episode=1  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[-0.04031602 -0.2104975  -0.02672963  0.08784313]\n",
      "[CartPole-v0 9:7  :26 ] train iteration=8  step=50  play  episode=1  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[-0.04452597 -0.01500281 -0.02497277 -0.21315173]\n",
      "[CartPole-v0 9:7  :27 ] train iteration=8  step=50  play  episode=1  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[-0.04482603 -0.20975899 -0.0292358   0.07155021]\n",
      "[CartPole-v0 9:7  :28 ] train iteration=8  step=50  play  episode=1  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[-0.0490212  -0.01423036 -0.0278048  -0.23021149]\n",
      "[CartPole-v0 9:7  :29 ] train iteration=8  step=50  play  episode=1  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[-0.04930581 -0.20894418 -0.03240903  0.05357279]\n",
      "[CartPole-v0 9:7  :30 ] train iteration=8  step=50  play  episode=1  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[-0.0534847  -0.01337288 -0.03133757 -0.2491567 ]\n",
      "[CartPole-v0 9:7  :31 ] train iteration=8  step=50  play  episode=1  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[-0.05375215 -0.20803361 -0.03632071  0.0334793 ]\n",
      "[CartPole-v0 9:7  :32 ] train iteration=8  step=50  play  episode=1  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[-0.05791283 -0.01241014 -0.03565112 -0.27043832]\n",
      "[CartPole-v0 9:7  :33 ] train iteration=8  step=50  play  episode=1  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[-0.05816103 -0.20700569 -0.04105989  0.01079031]\n",
      "[CartPole-v0 9:7  :34 ] train iteration=8  step=50  play  episode=1  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[-0.06230114 -0.01131967 -0.04084408 -0.29455953]\n",
      "[CartPole-v0 9:7  :35 ] train iteration=8  step=50  play  episode=1  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[-0.06252754 -0.20583624 -0.04673527 -0.01503285]\n",
      "[CartPole-v0 9:7  :36 ] train iteration=8  step=50  play  episode=1  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[-0.06664426 -0.01007628 -0.04703593 -0.32208732]\n",
      "[CartPole-v0 9:7  :37 ] train iteration=8  step=50  play  episode=1  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=0 observation=[-0.06684579 -0.20449798 -0.05347767 -0.04460079]\n",
      "[CartPole-v0 9:7  :38 ] train iteration=8  step=50  play  episode=1  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=1 observation=[-0.07093575 -0.00865158 -0.05436969 -0.35366535]\n",
      "[CartPole-v0 9:7  :39 ] train iteration=8  step=50  play  episode=1  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[-0.07110878 -0.20295997 -0.061443   -0.07861027]\n",
      "[CartPole-v0 9:7  :40 ] train iteration=8  step=50  play  episode=1  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[-0.07516798 -0.00701349 -0.0630152  -0.39002824]\n",
      "[CartPole-v0 9:7  :41 ] train iteration=8  step=50  play  episode=1  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[-0.07530825 -0.2011871  -0.07081577 -0.11786012]\n",
      "[CartPole-v0 9:7  :42 ] train iteration=8  step=50  play  episode=1  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[-0.07933199 -0.00512572 -0.07317297 -0.43201752]\n",
      "[CartPole-v0 9:7  :43 ] train iteration=8  step=50  play  episode=1  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[-0.0794345  -0.19913945 -0.08181332 -0.16326935]\n",
      "[CartPole-v0 9:7  :44 ] train iteration=8  step=50  play  episode=1  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[-0.08341729 -0.0029474  -0.08507871 -0.48059937]\n",
      "[CartPole-v0 9:7  :45 ] train iteration=8  step=50  play  episode=1  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=0 observation=[-0.08347624 -0.19677182 -0.09469069 -0.21589732]\n",
      "[CartPole-v0 9:7  :46 ] train iteration=8  step=50  play  episode=1  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.08741168 -0.3904215  -0.09900864  0.04547845]\n",
      "[CartPole-v0 9:7  :47 ] train iteration=8  step=50  play  episode=1  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[-0.09522011 -0.19402948 -0.09809907 -0.27672787]\n",
      "[CartPole-v0 9:7  :48 ] train iteration=8  step=50  play  episode=1  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[-0.0991007  -0.38762499 -0.10363363 -0.01652567]\n",
      "[CartPole-v0 9:7  :49 ] train iteration=8  step=50  play  episode=1  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=1 observation=[-0.1068532  -0.19118125 -0.10396414 -0.34002413]\n",
      "[CartPole-v0 9:8  :50 ] train iteration=8  step=50  play  episode=1  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.11067682 -0.38468215 -0.11076463 -0.08185039]\n",
      "[CartPole-v0 9:8  :1  ] train iteration=8  step=50  play  episode=2  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=0 observation=[ 0.00256538 -0.15460694 -0.00928383  0.27996784]\n",
      "[CartPole-v0 9:8  :2  ] train iteration=8  step=50  play  episode=2  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=1 observation=[-0.00052676  0.04064621 -0.00368447 -0.01562867]\n",
      "[CartPole-v0 9:8  :3  ] train iteration=8  step=50  play  episode=2  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 2.86162609e-04  2.35820807e-01 -3.99704546e-03 -3.09471807e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:8  :4  ] train iteration=8  step=50  play  episode=2  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.00500258  0.04075603 -0.01018648 -0.01805211]\n",
      "[CartPole-v0 9:8  :5  ] train iteration=8  step=50  play  episode=2  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[ 0.0058177  -0.15421836 -0.01054752  0.27139953]\n",
      "[CartPole-v0 9:8  :6  ] train iteration=8  step=50  play  episode=2  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[ 0.00273333  0.0410525  -0.00511953 -0.02459138]\n",
      "[CartPole-v0 9:8  :7  ] train iteration=8  step=50  play  episode=2  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[ 0.00355438 -0.15399566 -0.00561136  0.26647189]\n",
      "[CartPole-v0 9:8  :8  ] train iteration=8  step=50  play  episode=2  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[ 0.00047447  0.04120592 -0.00028192 -0.02797561]\n",
      "[CartPole-v0 9:8  :9  ] train iteration=8  step=50  play  episode=2  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.00129859  0.23633192 -0.00084144 -0.32074747]\n",
      "[CartPole-v0 9:8  :10 ] train iteration=8  step=50  play  episode=2  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.00602523  0.04122196 -0.00725638 -0.02833002]\n",
      "[CartPole-v0 9:8  :11 ] train iteration=8  step=50  play  episode=2  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[ 0.00684966 -0.15379518 -0.00782298  0.26205463]\n",
      "[CartPole-v0 9:8  :12 ] train iteration=8  step=50  play  episode=2  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[ 0.00377376  0.04143756 -0.00258189 -0.03308545]\n",
      "[CartPole-v0 9:8  :13 ] train iteration=8  step=50  play  episode=2  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[ 0.00460251 -0.15364727 -0.0032436   0.25878174]\n",
      "[CartPole-v0 9:8  :14 ] train iteration=8  step=50  play  episode=2  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[ 0.00152957  0.04152083  0.00193203 -0.03492249]\n",
      "[CartPole-v0 9:8  :15 ] train iteration=8  step=50  play  episode=2  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.00235998  0.23661503  0.00123358 -0.32699522]\n",
      "[CartPole-v0 9:8  :16 ] train iteration=8  step=50  play  episode=2  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[ 0.00709228  0.04147553 -0.00530632 -0.03392353]\n",
      "[CartPole-v0 9:8  :17 ] train iteration=8  step=50  play  episode=2  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[ 0.00792179 -0.15356992 -0.00598479  0.25708049]\n",
      "[CartPole-v0 9:8  :18 ] train iteration=8  step=50  play  episode=2  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[ 0.0048504   0.04163696 -0.00084318 -0.03748411]\n",
      "[CartPole-v0 9:8  :19 ] train iteration=8  step=50  play  episode=2  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[ 0.00568314 -0.15347289 -0.00159286  0.25493266]\n",
      "[CartPole-v0 9:8  :20 ] train iteration=8  step=50  play  episode=2  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[ 0.00261368  0.04167177  0.00350579 -0.03825225]\n",
      "[CartPole-v0 9:8  :21 ] train iteration=8  step=50  play  episode=2  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=1 observation=[ 0.00344711  0.23674327  0.00274074 -0.32982701]\n",
      "[CartPole-v0 9:8  :22 ] train iteration=8  step=50  play  episode=2  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=0 observation=[ 0.00818198  0.04158241 -0.0038558  -0.03628104]\n",
      "[CartPole-v0 9:8  :23 ] train iteration=8  step=50  play  episode=2  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[ 0.00901363 -0.15348404 -0.00458142  0.25518285]\n",
      "[CartPole-v0 9:8  :24 ] train iteration=8  step=50  play  episode=2  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[ 0.00594395  0.04170303  0.00052224 -0.0389416 ]\n",
      "[CartPole-v0 9:8  :25 ] train iteration=8  step=50  play  episode=2  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[ 6.77800653e-03  2.36817487e-01 -2.56591788e-04 -3.31459714e-01]\n",
      "[CartPole-v0 9:8  :26 ] train iteration=8  step=50  play  episode=2  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[ 0.01151436  0.04169919 -0.00688579 -0.03885771]\n",
      "[CartPole-v0 9:8  :27 ] train iteration=8  step=50  play  episode=2  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[ 0.01234834 -0.15332335 -0.00766294  0.25164475]\n",
      "[CartPole-v0 9:8  :28 ] train iteration=8  step=50  play  episode=2  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[ 0.00928187  0.04190719 -0.00263005 -0.04344533]\n",
      "[CartPole-v0 9:8  :29 ] train iteration=8  step=50  play  episode=2  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[ 0.01012002 -0.15317695 -0.00349895  0.24840663]\n",
      "[CartPole-v0 9:8  :30 ] train iteration=8  step=50  play  episode=2  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[ 0.00705648  0.04199479  0.00146918 -0.04537789]\n",
      "[CartPole-v0 9:8  :31 ] train iteration=8  step=50  play  episode=2  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[ 0.00789637  0.23709565  0.00056162 -0.33759691]\n",
      "[CartPole-v0 9:8  :32 ] train iteration=8  step=50  play  episode=2  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[ 0.01263829  0.04196571 -0.00619032 -0.04473693]\n",
      "[CartPole-v0 9:8  :33 ] train iteration=8  step=50  play  episode=2  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[ 0.0134776  -0.15306693 -0.00708505  0.24598648]\n",
      "[CartPole-v0 9:8  :34 ] train iteration=8  step=50  play  episode=2  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[ 0.01041626  0.04215549 -0.00216532 -0.04892279]\n",
      "[CartPole-v0 9:8  :35 ] train iteration=8  step=50  play  episode=2  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[ 0.01125937 -0.15293535 -0.00314378  0.24307617]\n",
      "[CartPole-v0 9:8  :36 ] train iteration=8  step=50  play  episode=2  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[ 0.00820066  0.04223137  0.00171774 -0.05059672]\n",
      "[CartPole-v0 9:8  :37 ] train iteration=8  step=50  play  episode=2  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[ 0.00904529  0.23732865  0.00070581 -0.34273719]\n",
      "[CartPole-v0 9:8  :38 ] train iteration=8  step=50  play  episode=2  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[ 0.01379187  0.04219666 -0.00614894 -0.04983178]\n",
      "[CartPole-v0 9:8  :39 ] train iteration=8  step=50  play  episode=2  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[ 0.0146358  -0.15283658 -0.00714557  0.24090478]\n",
      "[CartPole-v0 9:8  :40 ] train iteration=8  step=50  play  episode=2  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[ 0.01157907  0.04238671 -0.00232748 -0.05402346]\n",
      "[CartPole-v0 9:8  :41 ] train iteration=8  step=50  play  episode=2  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[ 0.0124268  -0.15270179 -0.00340794  0.23792422]\n",
      "[CartPole-v0 9:8  :42 ] train iteration=8  step=50  play  episode=2  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[ 0.00937277  0.04246868  0.00135054 -0.05583172]\n",
      "[CartPole-v0 9:8  :43 ] train iteration=8  step=50  play  episode=2  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[ 1.02221387e-02 -1.52672610e-01  2.33905625e-04  2.37277006e-01]\n",
      "[CartPole-v0 9:8  :44 ] train iteration=8  step=50  play  episode=2  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[ 0.00716869  0.042446    0.00497945 -0.05533213]\n",
      "[CartPole-v0 9:8  :45 ] train iteration=8  step=50  play  episode=2  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[ 0.00801761  0.2374962   0.0038728  -0.34643985]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:8  :46 ] train iteration=8  step=50  play  episode=2  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[ 0.01276753  0.04231937 -0.00305599 -0.05253821]\n",
      "[CartPole-v0 9:8  :47 ] train iteration=8  step=50  play  episode=2  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[ 0.01361392 -0.15275862 -0.00410676  0.23917896]\n",
      "[CartPole-v0 9:8  :48 ] train iteration=8  step=50  play  episode=2  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[ 0.01055875  0.04242175  0.00067682 -0.05479652]\n",
      "[CartPole-v0 9:8  :49 ] train iteration=8  step=50  play  episode=2  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[ 0.01140718 -0.1527099  -0.00041911  0.23809987]\n",
      "[CartPole-v0 9:9  :50 ] train iteration=8  step=50  play  episode=2  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.00835298  0.04241804  0.00434289 -0.05471523]\n",
      "[CartPole-v0 8:24 :1  ] train iteration=8  step=1    reward=1.0   done=False action=0 observation=[-0.02713179 -0.24484472 -0.01489691  0.24024356]\n",
      "[CartPole-v0 8:24 :2  ] train iteration=8  step=2    reward=1.0   done=False action=1 observation=[-0.03202868 -0.04951316 -0.01009204 -0.05710078]\n",
      "[CartPole-v0 8:24 :3  ] train iteration=8  step=3    reward=1.0   done=False action=1 observation=[-0.03301895  0.14575203 -0.01123405 -0.35295066]\n",
      "[CartPole-v0 8:24 :4  ] train iteration=8  step=4    reward=1.0   done=False action=0 observation=[-0.03010391 -0.04920839 -0.01829306 -0.06383123]\n",
      "[CartPole-v0 8:24 :5  ] train iteration=8  step=5    reward=1.0   done=False action=0 observation=[-0.03108807 -0.24406335 -0.01956969  0.22302445]\n",
      "[CartPole-v0 8:24 :6  ] train iteration=8  step=6    reward=1.0   done=False action=0 observation=[-0.03596934 -0.43890021 -0.0151092   0.50947065]\n",
      "[CartPole-v0 8:24 :7  ] train iteration=8  step=7    reward=1.0   done=False action=0 observation=[-0.04474734 -0.63380608 -0.00491979  0.79735414]\n",
      "[CartPole-v0 8:24 :8  ] train iteration=8  step=8    reward=1.0   done=False action=0 observation=[-0.05742347 -0.82886018  0.0110273   1.08848534]\n",
      "[CartPole-v0 8:24 :9  ] train iteration=8  step=9    reward=1.0   done=False action=0 observation=[-0.07400067 -1.02412578  0.032797    1.3846079 ]\n",
      "[CartPole-v0 8:24 :10 ] train iteration=8  step=10   reward=1.0   done=False action=0 observation=[-0.09448319 -1.21964104  0.06048916  1.68736366]\n",
      "[CartPole-v0 8:24 :11 ] train iteration=8  step=11   reward=1.0   done=False action=0 observation=[-0.11887601 -1.41540811  0.09423643  1.99825017]\n",
      "[CartPole-v0 8:24 :12 ] train iteration=8  step=12   reward=1.0   done=False action=1 observation=[-0.14718417 -1.22138879  0.13420144  1.73617701]\n",
      "[CartPole-v0 8:24 :13 ] train iteration=8  step=13   reward=1.0   done=False action=1 observation=[-0.17161194 -1.02802827  0.16892498  1.48808103]\n",
      "[CartPole-v0 8:24 :14 ] train iteration=8  step=14   reward=1.0   done=False action=1 observation=[-0.19217251 -0.83531848  0.1986866   1.25255895]\n",
      "[CartPole-v0 8:25 :15 ] train iteration=8  step=15   reward=1.0   done=True  action=1 observation=[-0.20887888 -0.64321709  0.22373778  1.02810606]\n",
      "[CartPole-v0 8:25 :1  ] train iteration=8  step=16   reward=1.0   done=False action=0 observation=[-0.00272278 -0.2439735  -0.03841203  0.30063826]\n",
      "[CartPole-v0 8:25 :2  ] train iteration=8  step=17   reward=1.0   done=False action=0 observation=[-0.00760225 -0.4385275  -0.03239927  0.58096363]\n",
      "[CartPole-v0 8:25 :3  ] train iteration=8  step=18   reward=1.0   done=False action=1 observation=[-0.0163728  -0.2429669  -0.02077999  0.27825296]\n",
      "[CartPole-v0 8:25 :4  ] train iteration=8  step=19   reward=1.0   done=False action=0 observation=[-0.02123214 -0.43778634 -0.01521493  0.56431015]\n",
      "[CartPole-v0 8:25 :5  ] train iteration=8  step=20   reward=1.0   done=False action=1 observation=[-0.02998787 -0.24245425 -0.00392873  0.26687291]\n",
      "[CartPole-v0 8:25 :6  ] train iteration=8  step=21   reward=1.0   done=False action=1 observation=[-0.03483695 -0.04727645  0.00140873 -0.02704657]\n",
      "[CartPole-v0 8:25 :7  ] train iteration=8  step=22   reward=1.0   done=False action=1 observation=[-0.03578248  0.14782527  0.0008678  -0.3192847 ]\n",
      "[CartPole-v0 8:25 :8  ] train iteration=8  step=23   reward=1.0   done=False action=1 observation=[-0.03282598  0.34293485 -0.0055179  -0.61169383]\n",
      "[CartPole-v0 8:25 :9  ] train iteration=8  step=24   reward=1.0   done=False action=1 observation=[-0.02596728  0.53813349 -0.01775178 -0.90610958]\n",
      "[CartPole-v0 8:25 :10 ] train iteration=8  step=25   reward=1.0   done=False action=0 observation=[-0.01520461  0.34325634 -0.03587397 -0.61905867]\n",
      "[CartPole-v0 8:25 :11 ] train iteration=8  step=26   reward=1.0   done=False action=0 observation=[-0.00833948  0.14865334 -0.04825514 -0.33788666]\n",
      "[CartPole-v0 8:25 :12 ] train iteration=8  step=27   reward=1.0   done=False action=0 observation=[-0.00536642 -0.04574991 -0.05501287 -0.06080274]\n",
      "[CartPole-v0 8:25 :13 ] train iteration=8  step=28   reward=1.0   done=False action=1 observation=[-0.00628142  0.15011589 -0.05622893 -0.37032259]\n",
      "[CartPole-v0 8:25 :14 ] train iteration=8  step=29   reward=1.0   done=False action=1 observation=[-0.0032791   0.34598976 -0.06363538 -0.68019165]\n",
      "[CartPole-v0 8:25 :15 ] train iteration=8  step=30   reward=1.0   done=False action=1 observation=[ 0.0036407   0.54193519 -0.07723921 -0.99221107]\n",
      "[CartPole-v0 8:25 :16 ] train iteration=8  step=31   reward=1.0   done=False action=1 observation=[ 0.0144794   0.73800093 -0.09708343 -1.30811859]\n",
      "[CartPole-v0 8:25 :17 ] train iteration=8  step=32   reward=1.0   done=False action=1 observation=[ 0.02923942  0.93420976 -0.12324581 -1.62954366]\n",
      "[CartPole-v0 8:25 :18 ] train iteration=8  step=33   reward=1.0   done=False action=1 observation=[ 0.04792362  1.1305458  -0.15583668 -1.95795647]\n",
      "[CartPole-v0 8:25 :19 ] train iteration=8  step=34   reward=1.0   done=False action=1 observation=[ 0.07053453  1.32694002 -0.19499581 -2.2946087 ]\n",
      "[CartPole-v0 8:26 :20 ] train iteration=8  step=35   reward=1.0   done=True  action=1 observation=[ 0.09707333  1.52325353 -0.24088798 -2.64046446]\n",
      "[CartPole-v0 8:26 :1  ] train iteration=8  step=36   reward=1.0   done=False action=1 observation=[-0.04332689  0.16322662 -0.02759062 -0.29919049]\n",
      "[CartPole-v0 8:26 :2  ] train iteration=8  step=37   reward=1.0   done=False action=0 observation=[-0.04006236 -0.0314914  -0.03357443 -0.01533523]\n",
      "[CartPole-v0 8:26 :3  ] train iteration=8  step=38   reward=1.0   done=False action=1 observation=[-0.04069219  0.16409556 -0.03388113 -0.31841936]\n",
      "[CartPole-v0 8:26 :4  ] train iteration=8  step=39   reward=1.0   done=False action=0 observation=[-0.03741028 -0.03052787 -0.04024952 -0.03661091]\n",
      "[CartPole-v0 8:26 :5  ] train iteration=8  step=40   reward=1.0   done=False action=1 observation=[-0.03802083  0.16514746 -0.04098173 -0.34171635]\n",
      "[CartPole-v0 8:26 :6  ] train iteration=8  step=41   reward=1.0   done=False action=1 observation=[-0.03471788  0.36082779 -0.04781606 -0.64703565]\n",
      "[CartPole-v0 8:26 :7  ] train iteration=8  step=42   reward=1.0   done=False action=1 observation=[-0.02750133  0.5565822  -0.06075677 -0.95438422]\n",
      "[CartPole-v0 8:26 :8  ] train iteration=8  step=43   reward=1.0   done=False action=0 observation=[-0.01636968  0.3623279  -0.07984446 -0.6813919 ]\n",
      "[CartPole-v0 8:26 :9  ] train iteration=8  step=44   reward=1.0   done=False action=0 observation=[-0.00912313  0.16840031 -0.0934723  -0.41487661]\n",
      "[CartPole-v0 8:26 :10 ] train iteration=8  step=45   reward=1.0   done=False action=0 observation=[-0.00575512 -0.02528112 -0.10176983 -0.15306355]\n",
      "[CartPole-v0 8:26 :11 ] train iteration=8  step=46   reward=1.0   done=False action=0 observation=[-0.00626074 -0.21880976 -0.1048311   0.10585871]\n",
      "[CartPole-v0 8:26 :12 ] train iteration=8  step=47   reward=1.0   done=False action=1 observation=[-0.01063694 -0.02235391 -0.10271393 -0.21797126]\n",
      "[CartPole-v0 8:26 :13 ] train iteration=8  step=48   reward=1.0   done=False action=0 observation=[-0.01108402 -0.21586902 -0.10707335  0.04062673]\n",
      "[CartPole-v0 8:26 :14 ] train iteration=8  step=49   reward=1.0   done=False action=1 observation=[-0.0154014  -0.01938756 -0.10626082 -0.28382708]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:26 :15 ] train iteration=8  step=50   reward=1.0   done=False action=1 observation=[-0.01578915  0.17707684 -0.11193736 -0.6080434 ]\n",
      "[CartPole-v0 8:26 :16 ] train iteration=8  step=51   reward=1.0   done=False action=1 observation=[-0.01224761  0.37357107 -0.12409823 -0.93378102]\n",
      "[CartPole-v0 8:26 :17 ] train iteration=8  step=52   reward=1.0   done=False action=0 observation=[-0.00477619  0.180322   -0.14277385 -0.68252794]\n",
      "[CartPole-v0 8:26 :18 ] train iteration=8  step=53   reward=1.0   done=False action=1 observation=[-0.00116975  0.37710763 -0.15642441 -1.01653603]\n",
      "[CartPole-v0 8:26 :19 ] train iteration=8  step=54   reward=1.0   done=False action=1 observation=[ 0.0063724   0.57392994 -0.17675513 -1.35396634]\n",
      "[CartPole-v0 8:26 :20 ] train iteration=8  step=55   reward=1.0   done=False action=1 observation=[ 0.017851    0.77077454 -0.20383445 -1.69632866]\n",
      "[CartPole-v0 8:27 :21 ] train iteration=8  step=56   reward=1.0   done=True  action=1 observation=[ 0.03326649  0.96758112 -0.23776103 -2.04494017]\n",
      "[CartPole-v0 8:27 :1  ] train iteration=9  step=1    reward=1.0   done=False action=0 observation=[-0.04495382 -0.24024451 -0.00600389  0.32411136]\n",
      "[CartPole-v0 8:27 :2  ] train iteration=9  step=2    reward=1.0   done=False action=1 observation=[-0.04975871 -0.04503759  0.00047833  0.02954112]\n",
      "[CartPole-v0 8:27 :3  ] train iteration=9  step=3    reward=1.0   done=False action=0 observation=[-0.05065946 -0.24016639  0.00106915  0.32237492]\n",
      "[CartPole-v0 8:27 :4  ] train iteration=9  step=4    reward=1.0   done=False action=1 observation=[-0.05546279 -0.04505968  0.00751665  0.03002936]\n",
      "[CartPole-v0 8:27 :5  ] train iteration=9  step=5    reward=1.0   done=False action=1 observation=[-0.05636398  0.14995367  0.00811724 -0.26027254]\n",
      "[CartPole-v0 8:27 :6  ] train iteration=9  step=6    reward=1.0   done=False action=0 observation=[-0.05336491 -0.04528321  0.00291179  0.03495958]\n",
      "[CartPole-v0 8:27 :7  ] train iteration=9  step=7    reward=1.0   done=False action=0 observation=[-0.05427057 -0.2404468   0.00361098  0.32855978]\n",
      "[CartPole-v0 8:27 :8  ] train iteration=9  step=8    reward=1.0   done=False action=0 observation=[-0.05907951 -0.43561997  0.01018218  0.62237926]\n",
      "[CartPole-v0 8:27 :9  ] train iteration=9  step=9    reward=1.0   done=False action=1 observation=[-0.06779191 -0.24064166  0.02262976  0.33292047]\n",
      "[CartPole-v0 8:27 :10 ] train iteration=9  step=10   reward=1.0   done=False action=1 observation=[-0.07260474 -0.045849    0.02928817  0.04745886]\n",
      "[CartPole-v0 8:27 :11 ] train iteration=9  step=11   reward=1.0   done=False action=1 observation=[-0.07352172  0.14884101  0.03023735 -0.23584141]\n",
      "[CartPole-v0 8:27 :12 ] train iteration=9  step=12   reward=1.0   done=False action=1 observation=[-0.0705449   0.3435182   0.02552052 -0.51883528]\n",
      "[CartPole-v0 8:27 :13 ] train iteration=9  step=13   reward=1.0   done=False action=1 observation=[-0.06367454  0.53827173  0.01514382 -0.80336823]\n",
      "[CartPole-v0 8:27 :14 ] train iteration=9  step=14   reward=1.0   done=False action=0 observation=[-0.0529091   0.34294544 -0.00092355 -0.50596028]\n",
      "[CartPole-v0 8:27 :15 ] train iteration=9  step=15   reward=1.0   done=False action=1 observation=[-0.04605019  0.53808039 -0.01104276 -0.79893411]\n",
      "[CartPole-v0 8:27 :16 ] train iteration=9  step=16   reward=1.0   done=False action=0 observation=[-0.03528858  0.34311166 -0.02702144 -0.50974534]\n",
      "[CartPole-v0 8:27 :17 ] train iteration=9  step=17   reward=1.0   done=False action=0 observation=[-0.02842635  0.1483806  -0.03721634 -0.22569872]\n",
      "[CartPole-v0 8:27 :18 ] train iteration=9  step=18   reward=1.0   done=False action=0 observation=[-0.02545874 -0.04619025 -0.04173032  0.05501637]\n",
      "[CartPole-v0 8:27 :19 ] train iteration=9  step=19   reward=1.0   done=False action=1 observation=[-0.02638254  0.14950444 -0.04062999 -0.25053526]\n",
      "[CartPole-v0 8:27 :20 ] train iteration=9  step=20   reward=1.0   done=False action=0 observation=[-0.02339246 -0.04501447 -0.0456407   0.02906037]\n",
      "[CartPole-v0 8:27 :21 ] train iteration=9  step=21   reward=1.0   done=False action=0 observation=[-0.02429275 -0.23945319 -0.04505949  0.30700103]\n",
      "[CartPole-v0 8:27 :22 ] train iteration=9  step=22   reward=1.0   done=False action=1 observation=[-0.02908181 -0.0437191  -0.03891947  0.00045489]\n",
      "[CartPole-v0 8:27 :23 ] train iteration=9  step=23   reward=1.0   done=False action=0 observation=[-0.02995619 -0.2382619  -0.03891037  0.28060868]\n",
      "[CartPole-v0 8:27 :24 ] train iteration=9  step=24   reward=1.0   done=False action=1 observation=[-0.03472143 -0.04260713 -0.0332982  -0.0240881 ]\n",
      "[CartPole-v0 8:27 :25 ] train iteration=9  step=25   reward=1.0   done=False action=1 observation=[-0.03557357  0.15297613 -0.03377996 -0.32708822]\n",
      "[CartPole-v0 8:27 :26 ] train iteration=9  step=26   reward=1.0   done=False action=1 observation=[-0.03251405  0.34856232 -0.04032172 -0.63022956]\n",
      "[CartPole-v0 8:27 :27 ] train iteration=9  step=27   reward=1.0   done=False action=0 observation=[-0.0255428   0.15402552 -0.05292631 -0.35051292]\n",
      "[CartPole-v0 8:27 :28 ] train iteration=9  step=28   reward=1.0   done=False action=0 observation=[-0.02246229 -0.04030535 -0.05993657 -0.07497785]\n",
      "[CartPole-v0 8:27 :29 ] train iteration=9  step=29   reward=1.0   done=False action=0 observation=[-0.0232684  -0.23451912 -0.06143613  0.19820888]\n",
      "[CartPole-v0 8:27 :30 ] train iteration=9  step=30   reward=1.0   done=False action=1 observation=[-0.02795878 -0.0385747  -0.05747195 -0.1132041 ]\n",
      "[CartPole-v0 8:27 :31 ] train iteration=9  step=31   reward=1.0   done=False action=0 observation=[-0.02873028 -0.23282806 -0.05973603  0.16080739]\n",
      "[CartPole-v0 8:27 :32 ] train iteration=9  step=32   reward=1.0   done=False action=1 observation=[-0.03338684 -0.03690404 -0.05651989 -0.15010639]\n",
      "[CartPole-v0 8:27 :33 ] train iteration=9  step=33   reward=1.0   done=False action=1 observation=[-0.03412492  0.15897978 -0.05952201 -0.46007094]\n",
      "[CartPole-v0 8:27 :34 ] train iteration=9  step=34   reward=1.0   done=False action=0 observation=[-0.03094532 -0.03525254 -0.06872343 -0.18672755]\n",
      "[CartPole-v0 8:27 :35 ] train iteration=9  step=35   reward=1.0   done=False action=1 observation=[-0.03165037  0.16078193 -0.07245798 -0.50027392]\n",
      "[CartPole-v0 8:27 :36 ] train iteration=9  step=36   reward=1.0   done=False action=0 observation=[-0.02843473 -0.03324777 -0.08246346 -0.23127707]\n",
      "[CartPole-v0 8:27 :37 ] train iteration=9  step=37   reward=1.0   done=False action=1 observation=[-0.02909969  0.16294977 -0.087089   -0.5487901 ]\n",
      "[CartPole-v0 8:27 :38 ] train iteration=9  step=38   reward=1.0   done=False action=0 observation=[-0.02584069 -0.03084778 -0.09806481 -0.28476728]\n",
      "[CartPole-v0 8:27 :39 ] train iteration=9  step=39   reward=1.0   done=False action=0 observation=[-0.02645765 -0.22444429 -0.10376015 -0.02455258]\n",
      "[CartPole-v0 8:27 :40 ] train iteration=9  step=40   reward=1.0   done=False action=0 observation=[-0.03094654 -0.41793701 -0.1042512   0.23367474]\n",
      "[CartPole-v0 8:27 :41 ] train iteration=9  step=41   reward=1.0   done=False action=0 observation=[-0.03930528 -0.61142688 -0.09957771  0.49173943]\n",
      "[CartPole-v0 8:27 :42 ] train iteration=9  step=42   reward=1.0   done=False action=0 observation=[-0.05153381 -0.80501363 -0.08974292  0.75145359]\n",
      "[CartPole-v0 8:27 :43 ] train iteration=9  step=43   reward=1.0   done=False action=0 observation=[-0.06763409 -0.99879092 -0.07471385  1.01460081]\n",
      "[CartPole-v0 8:27 :44 ] train iteration=9  step=44   reward=1.0   done=False action=1 observation=[-0.0876099  -0.80275633 -0.05442183  0.69942383]\n",
      "[CartPole-v0 8:27 :45 ] train iteration=9  step=45   reward=1.0   done=False action=1 observation=[-0.10366503 -0.60692379 -0.04043335  0.39011779]\n",
      "[CartPole-v0 8:27 :46 ] train iteration=9  step=46   reward=1.0   done=False action=1 observation=[-0.11580351 -0.41125199 -0.032631    0.08496582]\n",
      "[CartPole-v0 8:27 :47 ] train iteration=9  step=47   reward=1.0   done=False action=1 observation=[-0.12402855 -0.21567786 -0.03093168 -0.21783102]\n",
      "[CartPole-v0 8:27 :48 ] train iteration=9  step=48   reward=1.0   done=False action=1 observation=[-0.1283421  -0.0201277  -0.0352883  -0.52010841]\n",
      "[CartPole-v0 8:27 :49 ] train iteration=9  step=49   reward=1.0   done=False action=1 observation=[-0.12874466  0.17547279 -0.04569047 -0.82369909]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:28 :50 ] train iteration=9  step=50   reward=1.0   done=True  action=0 observation=[-0.1252352  -0.01899536 -0.06216445 -0.54572963]\n",
      "[CartPole-v0 8:28 :1  ] train iteration=9  step=51   reward=1.0   done=False action=1 observation=[ 0.03178433  0.23239601  0.00656717 -0.30991708]\n",
      "[CartPole-v0 8:28 :2  ] train iteration=9  step=52   reward=1.0   done=False action=1 observation=[ 3.64322491e-02  4.27423783e-01  3.68831377e-04 -6.00521691e-01]\n",
      "[CartPole-v0 8:28 :3  ] train iteration=9  step=53   reward=1.0   done=False action=0 observation=[ 0.04498072  0.23229667 -0.0116416  -0.30772261]\n",
      "[CartPole-v0 8:28 :4  ] train iteration=9  step=54   reward=1.0   done=False action=0 observation=[ 0.04962666  0.03734252 -0.01779605 -0.01873375]\n",
      "[CartPole-v0 8:28 :5  ] train iteration=9  step=55   reward=1.0   done=False action=0 observation=[ 0.05037351 -0.15751975 -0.01817073  0.26828161]\n",
      "[CartPole-v0 8:28 :6  ] train iteration=9  step=56   reward=1.0   done=False action=0 observation=[ 0.04722311 -0.35237773 -0.0128051   0.55517843]\n",
      "[CartPole-v0 8:28 :7  ] train iteration=9  step=57   reward=1.0   done=False action=0 observation=[ 0.04017556 -0.54731757 -0.00170153  0.84379962]\n",
      "[CartPole-v0 8:28 :8  ] train iteration=9  step=58   reward=1.0   done=False action=1 observation=[ 0.02922921 -0.35217244  0.01517446  0.5505821 ]\n",
      "[CartPole-v0 8:28 :9  ] train iteration=9  step=59   reward=1.0   done=False action=1 observation=[ 0.02218576 -0.15726688  0.02618611  0.26271853]\n",
      "[CartPole-v0 8:28 :10 ] train iteration=9  step=60   reward=1.0   done=False action=1 observation=[ 0.01904042  0.03747169  0.03144048 -0.02159134]\n",
      "[CartPole-v0 8:28 :11 ] train iteration=9  step=61   reward=1.0   done=False action=1 observation=[ 0.01978985  0.23212898  0.03100865 -0.30419099]\n",
      "[CartPole-v0 8:28 :12 ] train iteration=9  step=62   reward=1.0   done=False action=0 observation=[ 0.02443243  0.03657915  0.02492483 -0.00189218]\n",
      "[CartPole-v0 8:28 :13 ] train iteration=9  step=63   reward=1.0   done=False action=0 observation=[ 0.02516402 -0.15889122  0.02488699  0.29854945]\n",
      "[CartPole-v0 8:28 :14 ] train iteration=9  step=64   reward=1.0   done=False action=1 observation=[0.02198619 0.0358673  0.03085798 0.01381815]\n",
      "[CartPole-v0 8:28 :15 ] train iteration=9  step=65   reward=1.0   done=False action=0 observation=[ 0.02270354 -0.15968329  0.03113434  0.31607521]\n",
      "[CartPole-v0 8:28 :16 ] train iteration=9  step=66   reward=1.0   done=False action=1 observation=[0.01950987 0.03498166 0.03745584 0.0333713 ]\n",
      "[CartPole-v0 8:28 :17 ] train iteration=9  step=67   reward=1.0   done=False action=1 observation=[ 0.02020951  0.22954702  0.03812327 -0.2472626 ]\n",
      "[CartPole-v0 8:28 :18 ] train iteration=9  step=68   reward=1.0   done=False action=1 observation=[ 0.02480045  0.42410435  0.03317802 -0.52768102]\n",
      "[CartPole-v0 8:28 :19 ] train iteration=9  step=69   reward=1.0   done=False action=1 observation=[ 0.03328253  0.61874417  0.0226244  -0.80972753]\n",
      "[CartPole-v0 8:28 :20 ] train iteration=9  step=70   reward=1.0   done=False action=0 observation=[ 0.04565742  0.42331965  0.00642985 -0.51001476]\n",
      "[CartPole-v0 8:28 :21 ] train iteration=9  step=71   reward=1.0   done=False action=0 observation=[ 0.05412381  0.22810771 -0.00377045 -0.21531255]\n",
      "[CartPole-v0 8:28 :22 ] train iteration=9  step=72   reward=1.0   done=False action=0 observation=[ 0.05868596  0.03303987 -0.0080767   0.07617863]\n",
      "[CartPole-v0 8:28 :23 ] train iteration=9  step=73   reward=1.0   done=False action=1 observation=[ 0.05934676  0.22827667 -0.00655313 -0.21904154]\n",
      "[CartPole-v0 8:28 :24 ] train iteration=9  step=74   reward=1.0   done=False action=1 observation=[ 0.0639123   0.42349168 -0.01093396 -0.51378437]\n",
      "[CartPole-v0 8:28 :25 ] train iteration=9  step=75   reward=1.0   done=False action=0 observation=[ 0.07238213  0.22852541 -0.02120965 -0.22456698]\n",
      "[CartPole-v0 8:28 :26 ] train iteration=9  step=76   reward=1.0   done=False action=0 observation=[ 0.07695264  0.03371292 -0.02570099  0.06135088]\n",
      "[CartPole-v0 8:28 :27 ] train iteration=9  step=77   reward=1.0   done=False action=0 observation=[ 0.0776269  -0.16103129 -0.02447397  0.34581546]\n",
      "[CartPole-v0 8:28 :28 ] train iteration=9  step=78   reward=1.0   done=False action=1 observation=[ 0.07440627  0.03443009 -0.01755766  0.04551656]\n",
      "[CartPole-v0 8:28 :29 ] train iteration=9  step=79   reward=1.0   done=False action=0 observation=[ 0.07509487 -0.16043575 -0.01664733  0.33260858]\n",
      "[CartPole-v0 8:28 :30 ] train iteration=9  step=80   reward=1.0   done=False action=1 observation=[ 0.07188616  0.03491915 -0.00999516  0.03472275]\n",
      "[CartPole-v0 8:28 :31 ] train iteration=9  step=81   reward=1.0   done=False action=1 observation=[ 0.07258454  0.230183   -0.0093007  -0.26109692]\n",
      "[CartPole-v0 8:28 :32 ] train iteration=9  step=82   reward=1.0   done=False action=1 observation=[ 0.0771882   0.42543647 -0.01452264 -0.55669883]\n",
      "[CartPole-v0 8:28 :33 ] train iteration=9  step=83   reward=1.0   done=False action=1 observation=[ 0.08569693  0.62075926 -0.02565662 -0.85392163]\n",
      "[CartPole-v0 8:28 :34 ] train iteration=9  step=84   reward=1.0   done=False action=0 observation=[ 0.09811211  0.42599623 -0.04273505 -0.56941545]\n",
      "[CartPole-v0 8:28 :35 ] train iteration=9  step=85   reward=1.0   done=False action=0 observation=[ 0.10663204  0.23149888 -0.05412336 -0.29049607]\n",
      "[CartPole-v0 8:28 :36 ] train iteration=9  step=86   reward=1.0   done=False action=1 observation=[ 0.11126202  0.42734913 -0.05993328 -0.59974577]\n",
      "[CartPole-v0 8:28 :37 ] train iteration=9  step=87   reward=1.0   done=False action=1 observation=[ 0.119809    0.62325611 -0.07192819 -0.91068845]\n",
      "[CartPole-v0 8:28 :38 ] train iteration=9  step=88   reward=1.0   done=False action=0 observation=[ 0.13227412  0.42917736 -0.09014196 -0.64145173]\n",
      "[CartPole-v0 8:28 :39 ] train iteration=9  step=89   reward=1.0   done=False action=0 observation=[ 0.14085767  0.23541993 -0.102971   -0.37846145]\n",
      "[CartPole-v0 8:28 :40 ] train iteration=9  step=90   reward=1.0   done=False action=0 observation=[ 0.14556607  0.04189956 -0.11054023 -0.11993847]\n",
      "[CartPole-v0 8:28 :41 ] train iteration=9  step=91   reward=1.0   done=False action=1 observation=[ 0.14640406  0.2384174  -0.112939   -0.44534879]\n",
      "[CartPole-v0 8:28 :42 ] train iteration=9  step=92   reward=1.0   done=False action=0 observation=[ 0.15117241  0.04505932 -0.12184597 -0.19029295]\n",
      "[CartPole-v0 8:28 :43 ] train iteration=9  step=93   reward=1.0   done=False action=1 observation=[ 0.15207359  0.24169462 -0.12565183 -0.51879326]\n",
      "[CartPole-v0 8:28 :44 ] train iteration=9  step=94   reward=1.0   done=False action=1 observation=[ 0.15690749  0.43834081 -0.1360277  -0.84828157]\n",
      "[CartPole-v0 8:28 :45 ] train iteration=9  step=95   reward=1.0   done=False action=1 observation=[ 0.1656743   0.63502976 -0.15299333 -1.18045854]\n",
      "[CartPole-v0 8:28 :46 ] train iteration=9  step=96   reward=1.0   done=False action=0 observation=[ 0.1783749   0.4421884  -0.1766025  -0.93938005]\n",
      "[CartPole-v0 8:28 :47 ] train iteration=9  step=97   reward=1.0   done=False action=1 observation=[ 0.18721866  0.63919458 -0.1953901  -1.28194471]\n",
      "[CartPole-v0 8:29 :48 ] train iteration=9  step=98   reward=1.0   done=True  action=0 observation=[ 0.20000256  0.44702278 -0.22102899 -1.05625185]\n",
      "[CartPole-v0 8:29 :1  ] train iteration=9  step=99   reward=1.0   done=False action=1 observation=[-0.0342561   0.16679549 -0.01208295 -0.31296932]\n",
      "[CartPole-v0 8:29 :2  ] train iteration=9  step=100  reward=1.0   done=False action=1 observation=[-0.03092019  0.36208747 -0.01834234 -0.60943821]\n",
      "[CartPole-v0 8:29 :3  ] train iteration=9  step=101  reward=1.0   done=False action=1 observation=[-0.02367844  0.55746097 -0.0305311  -0.90784149]\n",
      "[CartPole-v0 8:29 :4  ] train iteration=9  step=102  reward=1.0   done=False action=1 observation=[-0.01252922  0.75298263 -0.04868793 -1.20996206]\n",
      "[CartPole-v0 8:29 :5  ] train iteration=9  step=103  reward=1.0   done=False action=0 observation=[ 0.00253043  0.55852202 -0.07288717 -0.9329254 ]\n",
      "[CartPole-v0 8:29 :6  ] train iteration=9  step=104  reward=1.0   done=False action=1 observation=[ 0.01370088  0.75454768 -0.09154568 -1.24759306]\n",
      "[CartPole-v0 8:29 :7  ] train iteration=9  step=105  reward=1.0   done=False action=1 observation=[ 0.02879183  0.95071643 -0.11649754 -1.56749088]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 8:29 :8  ] train iteration=9  step=106  reward=1.0   done=False action=1 observation=[ 0.04780616  1.14702137 -0.14784736 -1.89412526]\n",
      "[CartPole-v0 8:29 :9  ] train iteration=9  step=107  reward=1.0   done=False action=0 observation=[ 0.07074658  0.95378022 -0.18572987 -1.65073473]\n",
      "[CartPole-v0 8:30 :10 ] train iteration=9  step=108  reward=1.0   done=True  action=1 observation=[ 0.08982219  1.15052314 -0.21874456 -1.99506485]\n",
      "[CartPole-v0 9:9  :1  ] train iteration=10 step=108 play  episode=0  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 0.0404217   0.17985274 -0.0010204  -0.31721629]\n",
      "[CartPole-v0 9:9  :2  ] train iteration=10 step=108 play  episode=0  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.04401875 -0.01525466 -0.00736473 -0.02485534]\n",
      "[CartPole-v0 9:9  :3  ] train iteration=10 step=108 play  episode=0  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.04371366  0.17997213 -0.00786184 -0.31985279]\n",
      "[CartPole-v0 9:9  :4  ] train iteration=10 step=108 play  episode=0  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.0473131  -0.01503698 -0.01425889 -0.02965953]\n",
      "[CartPole-v0 9:9  :5  ] train iteration=10 step=108 play  episode=0  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.04701236  0.18028652 -0.01485208 -0.32680696]\n",
      "[CartPole-v0 9:9  :6  ] train iteration=10 step=108 play  episode=0  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[ 0.05061809 -0.01462086 -0.02138822 -0.03884448]\n",
      "[CartPole-v0 9:9  :7  ] train iteration=10 step=108 play  episode=0  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.05032568  0.18080116 -0.02216511 -0.33819813]\n",
      "[CartPole-v0 9:9  :8  ] train iteration=10 step=108 play  episode=0  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[ 0.0539417  -0.01399849 -0.02892907 -0.05258644]\n",
      "[CartPole-v0 9:9  :9  ] train iteration=10 step=108 play  episode=0  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.05366173  0.18152607 -0.0299808  -0.35425453]\n",
      "[CartPole-v0 9:9  :10 ] train iteration=10 step=108 play  episode=0  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.05729225 -0.01315704 -0.03706589 -0.07117413]\n",
      "[CartPole-v0 9:9  :11 ] train iteration=10 step=108 play  episode=0  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.05702911  0.18247616 -0.03848938 -0.37531725]\n",
      "[CartPole-v0 9:9  :12 ] train iteration=10 step=108 play  episode=0  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[ 0.06067863 -0.01207855 -0.04599572 -0.0950144 ]\n",
      "[CartPole-v0 9:9  :13 ] train iteration=10 step=108 play  episode=0  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[ 0.06043706 -0.20651211 -0.04789601  0.18280951]\n",
      "[CartPole-v0 9:9  :14 ] train iteration=10 step=108 play  episode=0  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[ 0.05630682 -0.01073871 -0.04423982 -0.12458987]\n",
      "[CartPole-v0 9:9  :15 ] train iteration=10 step=108 play  episode=0  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[ 0.05609205 -0.20519986 -0.04673162  0.1538142 ]\n",
      "[CartPole-v0 9:9  :16 ] train iteration=10 step=108 play  episode=0  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[ 0.05198805 -0.00944102 -0.04365533 -0.15323758]\n",
      "[CartPole-v0 9:9  :17 ] train iteration=10 step=108 play  episode=0  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[ 0.05179923 -0.20391159 -0.04672008  0.12535975]\n",
      "[CartPole-v0 9:9  :18 ] train iteration=10 step=108 play  episode=0  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[ 0.047721   -0.00815254 -0.04421289 -0.18168912]\n",
      "[CartPole-v0 9:9  :19 ] train iteration=10 step=108 play  episode=0  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[ 0.04755795 -0.20261486 -0.04784667  0.09672497]\n",
      "[CartPole-v0 9:9  :20 ] train iteration=10 step=108 play  episode=0  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[ 0.04350565 -0.00684097 -0.04591217 -0.21066135]\n",
      "[CartPole-v0 9:9  :21 ] train iteration=10 step=108 play  episode=0  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[ 0.04336883 -0.20127742 -0.0501254   0.06719255]\n",
      "[CartPole-v0 9:9  :22 ] train iteration=10 step=108 play  episode=0  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[ 0.03934328 -0.00547399 -0.04878155 -0.2408744 ]\n",
      "[CartPole-v0 9:9  :23 ] train iteration=10 step=108 play  episode=0  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[ 0.0392338  -0.19986639 -0.05359904  0.03603125]\n",
      "[CartPole-v0 9:9  :24 ] train iteration=10 step=108 play  episode=0  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[ 0.03523647 -0.00401842 -0.05287841 -0.2730694 ]\n",
      "[CartPole-v0 9:9  :25 ] train iteration=10 step=108 play  episode=0  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[ 0.0351561  -0.19834755 -0.0583398   0.00247786]\n",
      "[CartPole-v0 9:9  :26 ] train iteration=10 step=108 play  episode=0  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[ 0.03118915 -0.00243955 -0.05829024 -0.30802637]\n",
      "[CartPole-v0 9:9  :27 ] train iteration=10 step=108 play  episode=0  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[ 0.03114036 -0.19668459 -0.06445077 -0.03428131]\n",
      "[CartPole-v0 9:9  :28 ] train iteration=10 step=108 play  episode=0  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[ 0.02720667 -0.00070043 -0.06513639 -0.34658258]\n",
      "[CartPole-v0 9:9  :29 ] train iteration=10 step=108 play  episode=0  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[ 0.02719266 -0.19483832 -0.07206805 -0.07512986]\n",
      "[CartPole-v0 9:9  :30 ] train iteration=10 step=108 play  episode=0  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[ 0.0232959  -0.38885707 -0.07357064  0.19397316]\n",
      "[CartPole-v0 9:9  :31 ] train iteration=10 step=108 play  episode=0  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[ 0.01551875 -0.19276403 -0.06969118 -0.12098098]\n",
      "[CartPole-v0 9:9  :32 ] train iteration=10 step=108 play  episode=0  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[ 0.01166347 -0.38682189 -0.0721108   0.14892657]\n",
      "[CartPole-v0 9:9  :33 ] train iteration=10 step=108 play  episode=0  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=1 observation=[ 0.00392704 -0.19074538 -0.06913227 -0.16560604]\n",
      "[CartPole-v0 9:9  :34 ] train iteration=10 step=108 play  episode=0  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[ 1.12128043e-04 -3.84813115e-01 -7.24443893e-02  1.04491521e-01]\n",
      "[CartPole-v0 9:9  :35 ] train iteration=10 step=108 play  episode=0  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.00758413 -0.18873177 -0.07035456 -0.21013905]\n",
      "[CartPole-v0 9:9  :36 ] train iteration=10 step=108 play  episode=0  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.01135877 -0.38278093 -0.07455734  0.05954742]\n",
      "[CartPole-v0 9:9  :37 ] train iteration=10 step=108 play  episode=0  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.01901439 -0.18667355 -0.07336639 -0.25569599]\n",
      "[CartPole-v0 9:9  :38 ] train iteration=10 step=108 play  episode=0  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.02274786 -0.38067549 -0.07848031  0.01297373]\n",
      "[CartPole-v0 9:9  :39 ] train iteration=10 step=108 play  episode=0  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.03036137 -0.18452087 -0.07822084 -0.3034021 ]\n",
      "[CartPole-v0 9:9  :40 ] train iteration=10 step=108 play  episode=0  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.03405179 -0.37844596 -0.08428888 -0.03637738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:9  :41 ] train iteration=10 step=108 play  episode=0  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[-0.04162071 -0.18222278 -0.08501643 -0.35441881]\n",
      "[CartPole-v0 9:9  :42 ] train iteration=10 step=108 play  episode=0  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[-0.04526516 -0.37603949 -0.0921048  -0.08970849]\n",
      "[CartPole-v0 9:9  :43 ] train iteration=10 step=108 play  episode=0  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[-0.05278595 -0.17972631 -0.09389897 -0.40997065]\n",
      "[CartPole-v0 9:9  :44 ] train iteration=10 step=108 play  episode=0  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[-0.05638048 -0.37340031 -0.10209839 -0.14830518]\n",
      "[CartPole-v0 9:9  :45 ] train iteration=10 step=108 play  episode=0  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.06384848 -0.17697576 -0.10506449 -0.47137248]\n",
      "[CartPole-v0 9:9  :46 ] train iteration=10 step=108 play  episode=0  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.067388   -0.37046902 -0.11449194 -0.21356519]\n",
      "[CartPole-v0 9:9  :47 ] train iteration=10 step=108 play  episode=0  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[-0.07479738 -0.17391219 -0.11876324 -0.54005728]\n",
      "[CartPole-v0 9:9  :48 ] train iteration=10 step=108 play  episode=0  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[-0.07827562 -0.36718206 -0.12956439 -0.28702896]\n",
      "[CartPole-v0 9:9  :49 ] train iteration=10 step=108 play  episode=0  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[-0.08561926 -0.56024116 -0.13530497 -0.037853  ]\n",
      "[CartPole-v0 9:10 :50 ] train iteration=10 step=108 play  episode=0  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[-0.09682409 -0.36346452 -0.13606203 -0.36997862]\n",
      "[CartPole-v0 9:10 :1  ] train iteration=10 step=108 play  episode=1  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=0 observation=[-0.01310465 -0.14877215 -0.05026826  0.2543471 ]\n",
      "[CartPole-v0 9:10 :2  ] train iteration=10 step=108 play  episode=1  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=1 observation=[-0.01608009  0.04703016 -0.04518132 -0.05375801]\n",
      "[CartPole-v0 9:10 :3  ] train iteration=10 step=108 play  episode=1  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=0 observation=[-0.01513949 -0.14741581 -0.04625648  0.2243345 ]\n",
      "[CartPole-v0 9:10 :4  ] train iteration=10 step=108 play  episode=1  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=1 observation=[-0.01808781  0.04833569 -0.04176979 -0.08257322]\n",
      "[CartPole-v0 9:10 :5  ] train iteration=10 step=108 play  episode=1  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[-0.01712109 -0.14616338 -0.04342125  0.19664417]\n",
      "[CartPole-v0 9:10 :6  ] train iteration=10 step=108 play  episode=1  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[-0.02004436  0.04955189 -0.03948837 -0.10941387]\n",
      "[CartPole-v0 9:10 :7  ] train iteration=10 step=108 play  episode=1  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.01905332 -0.1449826  -0.04167665  0.17055383]\n",
      "[CartPole-v0 9:10 :8  ] train iteration=10 step=108 play  episode=1  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.02195297  0.05071032 -0.03826557 -0.13498005]\n",
      "[CartPole-v0 9:10 :9  ] train iteration=10 step=108 play  episode=1  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.02093877 -0.14384323 -0.04096517  0.14538931]\n",
      "[CartPole-v0 9:10 :10 ] train iteration=10 step=108 play  episode=1  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.02381563  0.05184071 -0.03805739 -0.15993073]\n",
      "[CartPole-v0 9:10 :11 ] train iteration=10 step=108 play  episode=1  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.02277882 -0.14271631 -0.041256    0.12050731]\n",
      "[CartPole-v0 9:10 :12 ] train iteration=10 step=108 play  episode=1  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.02563315  0.0529717  -0.03884586 -0.18490076]\n",
      "[CartPole-v0 9:10 :13 ] train iteration=10 step=108 play  episode=1  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.02457371 -0.14157353 -0.04254387  0.09527913]\n",
      "[CartPole-v0 9:10 :14 ] train iteration=10 step=108 play  episode=1  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.02740518  0.05413154 -0.04063829 -0.21051699]\n",
      "[CartPole-v0 9:10 :15 ] train iteration=10 step=108 play  episode=1  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[-0.02632255 -0.1403865  -0.04484863  0.06907481]\n",
      "[CartPole-v0 9:10 :16 ] train iteration=10 step=108 play  episode=1  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[-0.02913028  0.05534879 -0.04346713 -0.23741397]\n",
      "[CartPole-v0 9:10 :17 ] train iteration=10 step=108 play  episode=1  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.02802331 -0.13912609 -0.04821541  0.0412475 ]\n",
      "[CartPole-v0 9:10 :18 ] train iteration=10 step=108 play  episode=1  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.03080583  0.05665291 -0.04739046 -0.26624956]\n",
      "[CartPole-v0 9:10 :19 ] train iteration=10 step=108 play  episode=1  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[-0.02967277 -0.13776176 -0.05271545  0.01111745]\n",
      "[CartPole-v0 9:10 :20 ] train iteration=10 step=108 play  episode=1  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[-0.032428    0.05807502 -0.0524931  -0.29772081]\n",
      "[CartPole-v0 9:10 :21 ] train iteration=10 step=108 play  episode=1  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.0312665  -0.13626087 -0.05844752 -0.02204439]\n",
      "[CartPole-v0 9:10 :22 ] train iteration=10 step=108 play  episode=1  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.03399172  0.05964845 -0.05888841 -0.33258037]\n",
      "[CartPole-v0 9:10 :23 ] train iteration=10 step=108 play  episode=1  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.03279875 -0.13458803 -0.06554001 -0.05903388]\n",
      "[CartPole-v0 9:10 :24 ] train iteration=10 step=108 play  episode=1  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[-0.03549051  0.06140944 -0.06672069 -0.37165384]\n",
      "[CartPole-v0 9:10 :25 ] train iteration=10 step=108 play  episode=1  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[-0.03426232 -0.13270433 -0.07415377 -0.10073238]\n",
      "[CartPole-v0 9:10 :26 ] train iteration=10 step=108 play  episode=1  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[-0.03691641  0.06339771 -0.07616842 -0.41585831]\n",
      "[CartPole-v0 9:10 :27 ] train iteration=10 step=108 play  episode=1  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[-0.03564846 -0.13056675 -0.08448558 -0.14812705]\n",
      "[CartPole-v0 9:10 :28 ] train iteration=10 step=108 play  episode=1  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[-0.03825979 -0.32438363 -0.08744812  0.11675209]\n",
      "[CartPole-v0 9:10 :29 ] train iteration=10 step=108 play  episode=1  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[-0.04474746 -0.12812463 -0.08511308 -0.2021885 ]\n",
      "[CartPole-v0 9:10 :30 ] train iteration=10 step=108 play  episode=1  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[-0.04730996 -0.32193273 -0.08915685  0.06247824]\n",
      "[CartPole-v0 9:10 :31 ] train iteration=10 step=108 play  episode=1  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[-0.05374861 -0.1256531  -0.08790729 -0.25694921]\n",
      "[CartPole-v0 9:10 :32 ] train iteration=10 step=108 play  episode=1  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[-0.05626167 -0.3194172  -0.09304627  0.00676317]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:10 :33 ] train iteration=10 step=108 play  episode=1  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=1 observation=[-0.06265002 -0.12309253 -0.09291101 -0.31376612]\n",
      "[CartPole-v0 9:10 :34 ] train iteration=10 step=108 play  episode=1  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[-0.06511187 -0.31677658 -0.09918633 -0.05176968]\n",
      "[CartPole-v0 9:10 :35 ] train iteration=10 step=108 play  episode=1  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.0714474  -0.12038263 -0.10022172 -0.37402569]\n",
      "[CartPole-v0 9:10 :36 ] train iteration=10 step=108 play  episode=1  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.07385505 -0.31394873 -0.10770224 -0.1145494 ]\n",
      "[CartPole-v0 9:10 :37 ] train iteration=10 step=108 play  episode=1  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.08013403 -0.11746159 -0.10999323 -0.43917563]\n",
      "[CartPole-v0 9:10 :38 ] train iteration=10 step=108 play  episode=1  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.08248326 -0.3108689  -0.11877674 -0.18309069]\n",
      "[CartPole-v0 9:10 :39 ] train iteration=10 step=108 play  episode=1  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.08870064 -0.11426537 -0.12243855 -0.5107565 ]\n",
      "[CartPole-v0 9:10 :40 ] train iteration=10 step=108 play  episode=1  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.09098594 -0.30746908 -0.13265368 -0.25902755]\n",
      "[CartPole-v0 9:10 :41 ] train iteration=10 step=108 play  episode=1  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[-0.09713533 -0.50047243 -0.13783423 -0.0109519 ]\n",
      "[CartPole-v0 9:10 :42 ] train iteration=10 step=108 play  episode=1  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[-0.10714477 -0.30367054 -0.13805327 -0.34375008]\n",
      "[CartPole-v0 9:10 :43 ] train iteration=10 step=108 play  episode=1  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[-0.11321818 -0.4965862  -0.14492827 -0.0975886 ]\n",
      "[CartPole-v0 9:10 :44 ] train iteration=10 step=108 play  episode=1  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[-0.12314991 -0.29971655 -0.14688004 -0.4322571 ]\n",
      "[CartPole-v0 9:10 :45 ] train iteration=10 step=108 play  episode=1  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=0 observation=[-0.12914424 -0.49248675 -0.15552519 -0.18924291]\n",
      "[CartPole-v0 9:10 :46 ] train iteration=10 step=108 play  episode=1  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=1 observation=[-0.13899397 -0.29552135 -0.15931004 -0.52666534]\n",
      "[CartPole-v0 9:10 :47 ] train iteration=10 step=108 play  episode=1  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[-0.1449044  -0.48808536 -0.16984335 -0.28811627]\n",
      "[CartPole-v0 9:10 :48 ] train iteration=10 step=108 play  episode=1  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[-0.15466611 -0.29099988 -0.17560568 -0.62918499]\n",
      "[CartPole-v0 9:10 :49 ] train iteration=10 step=108 play  episode=1  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[-0.16048611 -0.48329288 -0.18818938 -0.39654457]\n",
      "[CartPole-v0 9:11 :50 ] train iteration=10 step=108 play  episode=1  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.17015196 -0.67531613 -0.19612027 -0.16859674]\n",
      "[CartPole-v0 9:11 :1  ] train iteration=10 step=108 play  episode=2  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 0.0465928   0.17036295  0.04264826 -0.2425029 ]\n",
      "[CartPole-v0 9:11 :2  ] train iteration=10 step=108 play  episode=2  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.05000006 -0.02534142  0.0377982   0.06332151]\n",
      "[CartPole-v0 9:11 :3  ] train iteration=10 step=108 play  episode=2  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.04949323  0.16921878  0.03906463 -0.21720032]\n",
      "[CartPole-v0 9:11 :4  ] train iteration=10 step=108 play  episode=2  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.05287761 -0.02643921  0.03472063  0.08754484]\n",
      "[CartPole-v0 9:11 :5  ] train iteration=10 step=108 play  episode=2  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.05234882  0.1681683   0.03647152 -0.19398467]\n",
      "[CartPole-v0 9:11 :6  ] train iteration=10 step=108 play  episode=2  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[ 0.05571219 -0.02745587  0.03259183  0.1099767 ]\n",
      "[CartPole-v0 9:11 :7  ] train iteration=10 step=108 play  episode=2  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.05516307  0.16718426  0.03479136 -0.17224814]\n",
      "[CartPole-v0 9:11 :8  ] train iteration=10 step=108 play  episode=2  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[ 0.05850676 -0.02841793  0.0313464   0.13120418]\n",
      "[CartPole-v0 9:11 :9  ] train iteration=10 step=108 play  episode=2  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.0579384   0.1662413   0.03397048 -0.15142689]\n",
      "[CartPole-v0 9:11 :10 ] train iteration=10 step=108 play  episode=2  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.06126322 -0.02935019  0.03094195  0.15177648]\n",
      "[CartPole-v0 9:11 :11 ] train iteration=10 step=108 play  episode=2  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.06067622  0.16531535  0.03397748 -0.13098658]\n",
      "[CartPole-v0 9:11 :12 ] train iteration=10 step=108 play  episode=2  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[ 0.06398253 -0.03027643  0.03135774  0.1722192 ]\n",
      "[CartPole-v0 9:11 :13 ] train iteration=10 step=108 play  episode=2  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=1 observation=[ 0.063377    0.16438301  0.03480213 -0.11040874]\n",
      "[CartPole-v0 9:11 :14 ] train iteration=10 step=108 play  episode=2  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=0 observation=[ 0.06666466 -0.03121991  0.03259395  0.19304774]\n",
      "[CartPole-v0 9:11 :15 ] train iteration=10 step=108 play  episode=2  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.06604026  0.16342099  0.03645491 -0.08917761]\n",
      "[CartPole-v0 9:11 :16 ] train iteration=10 step=108 play  episode=2  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[ 0.06930868 -0.03220402  0.03467136  0.21478031]\n",
      "[CartPole-v0 9:11 :17 ] train iteration=10 step=108 play  episode=2  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=1 observation=[ 0.0686646   0.16240554  0.03896696 -0.06676726]\n",
      "[CartPole-v0 9:11 :18 ] train iteration=10 step=108 play  episode=2  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=0 observation=[ 0.07191271 -0.03325279  0.03763162  0.23795083]\n",
      "[CartPole-v0 9:11 :19 ] train iteration=10 step=108 play  episode=2  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[ 0.07124765  0.1613119   0.04239063 -0.0426285 ]\n",
      "[CartPole-v0 9:11 :20 ] train iteration=10 step=108 play  episode=2  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[ 0.07447389  0.35580115  0.04153806 -0.32164119]\n",
      "[CartPole-v0 9:11 :21 ] train iteration=10 step=108 play  episode=2  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[ 0.08158991  0.16011305  0.03510524 -0.01615356]\n",
      "[CartPole-v0 9:11 :22 ] train iteration=10 step=108 play  episode=2  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[ 0.08479218  0.35471443  0.03478217 -0.29755695]\n",
      "[CartPole-v0 9:11 :23 ] train iteration=10 step=108 play  episode=2  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[0.09188646 0.15911436 0.02883103 0.00588959]\n",
      "[CartPole-v0 9:11 :24 ] train iteration=10 step=108 play  episode=2  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[ 0.09506875  0.35381123  0.02894882 -0.27755919]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CartPole-v0 9:11 :25 ] train iteration=10 step=108 play  episode=2  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[0.10214498 0.1582885  0.02339764 0.02411178]\n",
      "[CartPole-v0 9:11 :26 ] train iteration=10 step=108 play  episode=2  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[ 0.10531075  0.35306723  0.02387987 -0.26109807]\n",
      "[CartPole-v0 9:11 :27 ] train iteration=10 step=108 play  episode=2  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[0.11237209 0.15761268 0.01865791 0.03902019]\n",
      "[CartPole-v0 9:11 :28 ] train iteration=10 step=108 play  episode=2  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[ 0.11552434  0.35246218  0.01943832 -0.24771808]\n",
      "[CartPole-v0 9:11 :29 ] train iteration=10 step=108 play  episode=2  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[0.12257359 0.15706809 0.01448395 0.05103219]\n",
      "[CartPole-v0 9:11 :30 ] train iteration=10 step=108 play  episode=2  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[ 0.12571495  0.35197939  0.0155046  -0.23704597]\n",
      "[CartPole-v0 9:11 :31 ] train iteration=10 step=108 play  episode=2  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[0.13275454 0.1566394  0.01076368 0.06048697]\n",
      "[CartPole-v0 9:11 :32 ] train iteration=10 step=108 play  episode=2  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[ 0.13588732  0.35160538  0.01197342 -0.2287806 ]\n",
      "[CartPole-v0 9:11 :33 ] train iteration=10 step=108 play  episode=2  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[0.14291943 0.15631439 0.00739781 0.06765499]\n",
      "[CartPole-v0 9:11 :34 ] train iteration=10 step=108 play  episode=2  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[ 0.14604572  0.3513295   0.00875091 -0.22268474]\n",
      "[CartPole-v0 9:11 :35 ] train iteration=10 step=108 play  episode=2  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[0.15307231 0.15608358 0.00429721 0.07274567]\n",
      "[CartPole-v0 9:11 :36 ] train iteration=10 step=108 play  episode=2  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[ 0.15619398  0.35114366  0.00575212 -0.21857838]\n",
      "[CartPole-v0 9:11 :37 ] train iteration=10 step=108 play  episode=2  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=0 observation=[0.16321686 0.15593995 0.00138056 0.07591345]\n",
      "[CartPole-v0 9:11 :38 ] train iteration=10 step=108 play  episode=2  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=1 observation=[ 0.16633565  0.35104209  0.00289883 -0.21633359]\n",
      "[CartPole-v0 9:11 :39 ] train iteration=10 step=108 play  episode=2  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[ 0.1733565   0.15587882 -0.00142785  0.07726234]\n",
      "[CartPole-v0 9:11 :40 ] train iteration=10 step=108 play  episode=2  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[ 1.76474072e-01  3.51021207e-01  1.17400385e-04 -2.15870731e-01]\n",
      "[CartPole-v0 9:11 :41 ] train iteration=10 step=108 play  episode=2  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[ 0.1834945   0.15589758 -0.00420001  0.07684923]\n",
      "[CartPole-v0 9:11 :42 ] train iteration=10 step=108 play  episode=2  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[ 0.18661245  0.35107949 -0.00266303 -0.21715585]\n",
      "[CartPole-v0 9:11 :43 ] train iteration=10 step=108 play  episode=2  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[ 0.19363404  0.15599571 -0.00700615  0.07468585]\n",
      "[CartPole-v0 9:11 :44 ] train iteration=10 step=108 play  episode=2  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[ 0.19675395  0.35121739 -0.00551243 -0.22019928]\n",
      "[CartPole-v0 9:11 :45 ] train iteration=10 step=108 play  episode=2  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=0 observation=[ 0.2037783   0.15617467 -0.00991642  0.07073971]\n",
      "[CartPole-v0 9:11 :46 ] train iteration=10 step=108 play  episode=2  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=1 observation=[ 0.20690179  0.35143737 -0.00850162 -0.22505532]\n",
      "[CartPole-v0 9:11 :47 ] train iteration=10 step=108 play  episode=2  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[ 0.21393054  0.15643795 -0.01300273  0.06493379]\n",
      "[CartPole-v0 9:11 :48 ] train iteration=10 step=108 play  episode=2  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[ 0.2170593   0.35174389 -0.01170405 -0.23182305]\n",
      "[CartPole-v0 9:11 :49 ] train iteration=10 step=108 play  episode=2  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[ 0.22409418  0.15679112 -0.01634051  0.05714517]\n",
      "[CartPole-v0 9:12 :50 ] train iteration=10 step=108 play  episode=2  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.22723     0.35214351 -0.01519761 -0.24064819]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<easyagents.core.PpoTrainContext at 0x212540c3348>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1224x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([log.Step(), duration.Fast()], default_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For each call to the gym environments step method you get a log entry, along with the action taken and current\n",
    "observation. Each entry starts with \n",
    "\n",
    "[{gym_env_id} {instance_id}:{episode_in_instance}:{step_in_episode}]\n",
    "\n",
    "followed by the id of the current training iteration as well as the current iteration step count.\n",
    "If in a evaluation period you get the same statistics for the current evaluation episode.\n",
    "\n",
    "You may easily implement other log callbacks to produce statistics specific to your problem domain.\n",
    "\n",
    "## Fixing jupyter output cell clearing\n",
    "It seems that jupyter / matplotlib backend changes its behaviour of outputing the current figure of an \n",
    "evaluated cell (if you can help here, please let use know by \n",
    "[creating an issue](https://github.com/christianhidber/easyagents/issues/new/choose)).\n",
    "\n",
    "Nonetheless you may directly control easyagents jupyter ouput cell clearing behaviour through the plot.Clear()\n",
    "callback:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMAAAAGoCAYAAACg1ZkGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXhdVbnH8e+bTulI57lNCoLIUAYpIqOICMooyDyDgAqCl3tFEPB6ERQBERGQVpktMg8VUGSQUWZknqlNGzqndG6SpmfdP5JiKS1N2yT7DN/P8+RJzj45+/zenA2r5z1rrx0pJSRJkiRJkqRiVZZ1AEmSJEmSJKk12QCTJEmSJElSUbMBJkmSJEmSpKJmA0ySJEmSJElFzQaYJEmSJEmSilr7rAOsjRtuuCEdeeSRWcdodbW1tQCUl5dnnKR1lUqdUDq1lkqdUDq11tbWUl5eHlnnaCmOI8WnVGotlTqhdGotlTrBsaQQldrxCdZaTEqlTiidWtd0HCnoGWCLFi3KOoIkqYA5jkiS1pZjiSQVhoJugEmSJEmSJEmrYgNMkiRJkiRJRc0GmCRJkiRJkoqaDTBJkiRJkiQVNRtgkiRJkiRJKmo2wCRJkiRJklTUbIBJkiRJkiSpqNkAkyRJkiRJUlGzASZJkiRJkqSiZgNMkiRJkiRJRc0GmCRJkiRJkoqaDTBJkiRJkiQVNRtgkiRJkiRJKmo2wCRJkiRJklTUbIBJyht1tTnqanNZx9BnyOVS1hEkSZIkabXZAJOUF6745WR6d13A+gOns2jhkqzjaCVOOnhK1hEkSZIkabXZAJOUqZrp9XxlZBUn/2QwETBpzkD233lS1rG0AldfOpXr/1KZdQxJkiRJWm02wCRl5tarp7Pu0IU89loFu2xRRfX0crbfqIq/PlfJJT/9MOt4WsbLz87lpNN60KPDnKyjSJIkSdJqswEmqc0tWriEfXaYwEHf6cuSXDv+8OupPPRSBT17d+C+p4bQr/NMzjyvNy8+ZbMlH8yd3cDuu9SxJLXj1lvrs44jSZIkSavNBpikNvXQuFlU9J3FuCcr2Wrdat4d34HvnDbw4/t79GzPXX9pTy6VsedudSyY73pgWdt9m8lMW9CPc0+fwY67r5N1HEmSJElabTbAJLWJhobEsftOYLd9ejC3tivn/6ia5z8YzuDh5Z/63e126cnP/mcGUxf0Z9+dXA8sS6ccXsXT7wxnr20ncOavhmYdR5IkSZLWiA0wSa3uxafmsF6/aVx7TyWf6z+Nl19O/OTCz26mnHXRUHYeWcVDL1Xyyx9Xt1FSLevmP07n8rFDWa/PZG7/x/Cs40iSJEnSGrMBJqnV5HKJs74/hW22L2fy7F7811FVvDVlMBuO7Nqsx497YggDus7gfy/sy7OPuh5YW3rn9QUcd2Jnurafz8PP9qJjR4cLSZIkSYXLdzSSWsUHby1gq/Vmcsm1IxjYYzZPPVbLJddVUFYWzd5Htx7tGXd/RwjYe4965s9taMXEWmrRwiV8bbv51OXKuXnsYirW65x1JEmSJElaKzbAJLW4i86qZpON4Z2pgzjsG+P5YEY/tt5xzRZP33rHdTjvjBqmL+zHXtt/2MJJtSJ7bldN9dwBnPH9KexxYN+s40iSJEnSWrMBJqnFTK2uY5sNJnL6L4bSrdMi7vrzTP545+C1Pn3u9F8MYdcvVvHoaxX8/DQXxW9NP/neRB55uYJdtqjivCtc90uSJElScbABJqlFXPe7qaw/opZn3xvKnl+ewL+n9eTr+/Zssf3f8/hQBnWbzrm/6c8TD37UYvvVf9x7y0wuvGoQw9aZyl+e9IqPkiRJkoqHDTBJa2Xu7AZ222oCx5wygDISY6+awV/+WUm3Hu1b9Hk6d2nHvX8vpyxy7LfPEubOdj2wljThvYUccngHOpXV8uCT3encpV3WkSRJkiSpxdgAk7TGxv15BpUD5/L3FyvZ7gsTeX9SFw49cUCrPd+WX+7BBT+dxcxFffnmtq4H1lLq63Ps8uXZLGzoyrVjFvH5TZp3lU5JkiRJKhQ2wCSttrraHId8fQL7HtqbRYs7cen/TebJNyvoN7Bjqz/3f/1sCN/80gSeequCs0+a2OrPVwr2/8pExtcM5uQjPuTA4/pnHUeSJEmSWpwNMEmr5amHZzOi30xufrCSTYZO5q23g1N/OrhNM9z56HCG9JjGBVcO5B/3ux7Y2vjF6dXc+3Ql225YxW9vqMg6jiRJkiS1Chtgkpoll0ucfGgVO32tCzMX9OCs70/k5aqhVK7fpc2zdCov468Pd6F9NPDt/XLMmrm4zTMUg0funcX/XtSPgV2n88CzQ7KOI0mSJEmtxgaYpFV6/aX5bDBgClf8uYLhvWt44dnFnHfFcMrKIrNMm27VnV+fP5tZdb355rZTMstRqKZW17H//kH7aOCBf3Ru8YsWSJIkSVI+sQEm6TP97NRJfHGrdkyY2Y/vHlDFu9MGMnJU96xjAXDSmYPZe/sqnn1vOD8+3vXAmquhIbHzqBnMqV+HK38zL29eT0mSJElqLTbAJK1Q1QeL2KJyEv932TB6d5nHw/fP5/e3VtC+fXazvlbktoeHM7znVH79x0E8eE9N1nEKwmG7V/H21KEc+62JHHPqwKzjSJIkSVKrswEm6VOu+OVkvrDBEl6pGsy3vzqBCTP7stM3emUda4U6dizjr//oRoeyeg46MJgxtT7rSHntt+dO5taHK9i8YhJjbnfRe0mSJEmlwQaYpI/VTK/nKyOrOPkngylvX8+dN87itocr6VSe3/+r2Gjzblx24Vw+qu/FN7abSi6Xso6Ul55+ZDY/+llv+pbX8PALAzNdw02SJEmS2lJ+v6uV1GZu/uN01h26kMdeq2CXLaoYP6U7+x7eL+tYzXb8fw/i2ztX8eL44Zx2zKSs4+Sdmun17LXHEoLEvX/tQO++HbKOJEmSJEltxgaYVOIWzF/CPjtM4JDj+7Ik144//HoqD71UQc/ehdcgGfu34YzoPYXf3TCI+293PbClcrnE17aeRk1tby4+9yO+9JV1so4kSZIkSW3KBphUwp544CPWHTCLcU9WMmq9at4d34HvnFa4i6J37FjGA4/3oFNZHYcc2o6p1XVZR8oL39mviperhnHwrlX84OzBWceRJEmSpDaXVw2wiOgaES9GxJ5ZZ5GKWS6X+NF3JrLz7l2Zvagb5/+omufeH87g4eVZR1tr62/clSsvnc/cxT3YbdvpJb8e2NW/mcp19wxno0HVjP2bi95LkiRJKk2t2gCLiGsiYnpEvL7c9t0j4p2IeD8izljmrh8Dt7ZmJqnUTZ5YyxfXrebiq4czeJ1ZPP9sAz+5cGjWsVrU0T8YyMFfn8irk4bxg8MmZh0nMy8/O5eT/rsH63Scw8PP9XPRe0mSJEklq30r7/864HLghqUbIqIdcAWwK1ANPB8R44DBwJtAs6eg5HI5amtrWzJvXiqFGqF06oTsar39mhq+d2o3FjQMYf+dx3PN3QPp2LGs1fJk+Zr+4Y4BPD/iQ666eQg77zaFPQ/u1arPl2/H79zZDez+1VqWpHW45ZZ6evbt3CIZa2trKS8v/JmCkiRJkkpLqzbAUkqPR0Tlcpu3Bt5PKY0HiIibgX2AbkBXYCNgUUTcn1LKLb/PiDgBOAHg5z//eeuFV0Gpq83x3huLePf1Wsa/u5iJVTk+rIZpM9pR81EHZi8op66hI7ttP53Rt/SnR8/W7v3ml/r6HMfvP5XbHqqkS7v5XHPZZA4+vrjXgmrfPvjLw13YastFHHt8F17Zro5BwzplHatNpJTYe8eZTFtYyXn/U8WOuw/IOpIkSZIkZSqLLsAQYNIyt6uBL6WUTgaIiKOBmStqfgGklMYAYwBGjx6dSmkmQqnUumyduVxi0r9refvVhbz3Zh0TPmhg4sQcU6YEM2e1Z9bcjsyr7cyiXBegyyf2E+To3G4BPcoXMaTvQuoW13L34+vyyPDZXHDuPL53xqA2ruzT2uI1ff2l+ez5tXlUfbQuI4dN4r4n+jG0om1Peczq2P3CyHJG/24aR36/H3t9ZTKvTurR6qcB5sN/p6ccXsWz71Wy93YTOOuiyqzjSJIkSVLmsmiArejd58erVKeUrmu7KMrS3NkNvPXyAt5+vZYP3q2navxiJk8OZtS0p2Z2R+Yu7MT8hq7k6Ax0/sRjO8ZCundaRM9udYwYsohBA2cydFhQsW571t+wI5/ftAuf26gL7dt3B7p//LjfXzCFM37ame+fOYirrpzE2Lt7scmW3dq28Db0659+yE/O68WS1IfTjp7IRVcPK7l1oA7/3gAevG8CN9xXyYkHVPGHO4p7Ifib/zidy8cOZb0+k7ntkeFZx5EkSZKkvJBFA6waGLbM7aHA5AxytJgF85fQuUtZyTUWVmXWzMVcf/l0Pni3gUmTEtOmlTFzVns+mt+J+fVdqE+dgXWavhq1YzFdOyxgnS61rDtkHv37zmbIUBhe0Y71Pt+Rz29SzoYju9Kj56dnfDXH984YxGHfbeC4/SZw5z+GssUXl3D0tyZw+U3D6VSeVxdFXStzZzew704f8o9XK+jbeSa33t6Onb9Zus2Qa8dV8OzgD7n6zqF8/drpHHBM/6wjtYp3XlvAsSd2oVv7+Tz8bC86diyeY1qSJEmS1kYWDbDngfUjYgTwIXAwcGgGOVrMEXtO4tFnerDPbnM5+4J+rPeFrllHytT9t9dw4bnz+edrA1jMkKatOTqXLaRH+SL691rEJn3nM2hgYlhFGZXrtWeDjToxYoP2DK7oSJcuPVs1X4+e7bntkUqeeng2Rx20kD/eVck9vWdyxeU5Dji28Bsjj9w7iwMPSNTUVrDLFlXc/egQuvUorTXPlldWFjzwVG82+fwCjj2+nG2+sohhIzqv+oEFZNHCJXxt+/nU53pz25/nULHeOqt+UIGLiAnAPGAJ0JBS2ioiLgL2AuqBD4BjUkqzs0spScpXjiOSVFpadXpARPwZeBr4fERUR8RxKaUG4GTgAeAt4NaU0hutmaO1bbFlOzq1b+C6cZWsv1E5mw6t5nfnTaa+foXLmBWlmun1/PcxExnUbTp7HNCHJ14bwqYjZvD7X03htRfnU7sIFi7pxtQF/XhrylAee62Cmx+s5KI/DuekMwez6z59GDqiU5vOottul568O30Q5/7XJObXlXPgcf3YYeMqJv17UZtlaEm5XOLUI6v4+l7dmV/XmUv+90Meeqmi5JtfS1Ws15mrR9eyYElXvr7tLHK5tOoHFZA9tq2meu4Azvj+FPY4sG/WcdrSzimlzVNKWzXdfhDYJKU0EngXODO7aJKkAuA4IkklorWvAnnISrbfD9zfms/dls65ZBjnXAIP3lPDhefO4/F/DeCUczpz5s/mseu2NfzkF70ZtX2PrGO2intvmcmFP1/A028MpIHh9Oo4i+O+NYFzLhpAxXrDVr2DjJWVBedcMozjT6vjsL0m8sjLw9hgvUX88ISJnH9l4ayXNenfi/jmDjW8/mEFI3pP4d6Hu7PR5kNW/cASc+Bx/fn7fRO4+q5Kjt1nAtf9pTLrSC3iJ9+byD9eaZzxd94Vxb3G2aqklP6+zM1ngG9/1u/ncjlqa2tbN1QeKIUalyqVWkulTiidWkulTmisNR8uGrMiqzuOQGmMJcVe37KstfiUSp1QOrWu6TjiAjEtaNd9+vDgi5XUzOnIuadNYmDPedz9RAVb79CddftM4aenTGLu7IasY661GVPr+eFRExnYbQZ7HdyXp94YzObrTuPGK6cxc1Ev/nhnJRXrFdbpZQOHduLhf1Vwz0019OyygAtGD2dEn2k8cu+srKOt0p9+P40vrL+YNz4cxOHfmMC70way0ebFu7D/2hpzewUbD67mhnuHcdPoaVnHWWt/uXkGF141iGHrTOUvT7bt1T3zQAL+HhEvRsQJK7j/WOCvy2+MiBMi4oWIeKGmpqbVQ0qS8tYajSPgWCJJhShSKtzTgEaPHp1OPPHErGN8ppeenssvz5rF3x7vzfwlPegYi9hu0+n891ldm32a0tIubtaflN0zdgYXnb+QZ98aSAOd6NVpFvvvMY+zL+zfIg2vfKmzoSFx2tETueqmATSkDuzx5UlcP24Ivft2aLHnaIla6+tzHLb7RG7/x3C6t5/H1WPq8m5x93x5TZdXXVXLFz5XRy6V8dob7Vj386t/QYXlZVHrhPcWsulGi8nlynjplTI+v0nrrz/Y9GlLXkyNjIjBKaXJEdGfxlNWfpBSerzpvrOArYD90mcMdIUwjrSEfP1vsTWUSq2lUieUTq2lUifkz1jSEuMIlMZYUmrHJ1hrMSmVOqF0al3TccQZYK1syy/34LZHKvmotju/v2AKGw6dyWOvDmHPg/oysOsMTj60iskT83ea4rTJdZx6ZBUDus5g38P78fRbg9livWmMvWoaMxf24g93VBTcbK9Vad8+uOxPFbzx2hK2Wu9D7n26koqBC7nkpx9mHe1jLz87l8/1n87t/6hki8pq3v13ed41v/LZ0Ipybry2ntolndlth9k0NBTeBwH19Tl2+fJsFjZ05bo/LmqT5le+SSlNbvo+HbgL2BogIo4C9gQOW9WbFklS6XIckaTSYgOsjbRvH3z3x4N4ZeIwPni3nu/sV0VDrowr/lzB8Ip2bLXeRK797dS8WZj77j/NYPsvVDF0CFx2YwVLcmWc8O0qJoxv4Ln3h3PoiQMKZn2sNbX+xl157v3hXHvZVDq0X8J//3wIGw2u5qWn52aa65c/ruZLX+7AlDm9OOPEibz07+EMHNop00yFaN/D+3HiQR/y/ozBHLVnVdZxVtt+X5nI+JrB/ODIySXZ/IyIrhHRfenPwNeB1yNid+DHwN4ppYVZZpQk5S/HEUkqPTbAMlC5fhf+cEcF0xf05vbrZrDNFybzyvgBHPvDgfQqn8Nhu0/gzZfnt3muqdV1/OCwKvp3mcG3jujHM28PZsv1p/HnP0xn+oLejL6tgmEjimu2V3Mc/YOBTJq5DoftPoF3pwxg623LOWKPCSxauKRNc3xUs5gdNq7iJxcOpWfn+Tzy94X88qrhbZqh2Fx+03BGDpvEnx8YznW/m5p1nGb7xY+que/pSrbdsIpLry/ZY2AA8GREvAI8B9yXUvobcDnQHXgwIl6OiKuyDClJyluOI5JUYmyAZaisLNj/qH48+WYF02aUcfrxE+nRuY6bHqhkky26sOHAD7norGrqanOtliGXS9x+/Qy23XAiQ4cFl99UQS6V8b2DqphYtYRn3x3Owd/pX/SzvVala7d2/OmvlTz75ELWHziDP91fydDes7nhirZZRP2BO2ey3pB5PPlmBbuPmsD4ab3ZYddebfLcxaysLHjgn/3p3mEu3/9hN957Y0HWkVbp4b/M4n8v7sfArtN54NnSvdJnSml8Smmzpq+NU0rnN23/XEppWNMl7TdPKX0366ySpPzjOCJJpccGWJ7o3bcDvxoznElzBvD4Ax/xjW0mUjWjJ6f/YigD++T41o6TeeKBj1rs+SZPrOWkQ6oY0K2GA47ux3PvDGTUBlO49ZrG2V5X3lzB4OHFvXDemvjiduvw1pQh/OrMD6lr6MBRJw/gS+tPZPzbrdM4yeUSJx1cxTf3X4dFiztx+S8m89fnKunarV2rPF8pGji0E2NvbKAuV85uO86lvr71Gs5ra8qkWvbfP2gfDTzwj85069E+60iSJEmSVBBsgOWhHb7ei/ueruSj+Z258CcfMrzfbB54vpIdd+/FsHWm8ePjJ1IzvX6195vLJW69ejrbbDCR4RVlXHlzBQAnHVJF9aTE0+9UcMAxzvZqjtN/MYSqyeV880sTeP79IXxhozJ+eGRViy6mPuG9hWwy5EOuvKWCEX1n8OqrcNKZg1ts//qPPQ/qy8lHfMi/Zw3isG9MzDrOCjU0JL669UzmLl6HK38zj5GjumcdSZIkSZIKhg2wPFbeuYwfnT+EVyb05aVnPuLQ3Scwd1EnLvzjcAYOSGy/URW3Xz9jlQvnV1fV8r0Dq+jfdRYHfac/L7w3kC9tOIU7rp/BtPl9uPymChdRXwN9+nfkvmcqeeDu2fTvPpff3lhBRe/p3H/bzLXe9zWXTmHjDZfw9tRBHLPPBN6eMoj1Ny69q/y1pd9cN5wtKidy+yPD+cOvp2Qd51MO272Kt6cO5dhvTeSYUwdmHUeSJEmSCornzxSIDTfryti/9iGXS1x/+VSu+O1innlrMAcc3YE+361h32/M4+xf9ady/S5A42yvW/44g0svquXF9wexhAr6dZ7BDw6r4qwLBzJgcEXGFRWPXffpQ9VHiTNPnMhvr+7LngeW87UtJ3DjXwYxYPDqNRbranMctOtE7nmygnU6zOamG2axz2GVrRNcn1BWFjzw9EA2qJjDKaf3YIddF7DhyNZtOi5csISpk2qZ+uFipk9ZzPSpDdTMWMKsmTk+mpXjo9kwdw58NKeMF8dXsEXlRMbc7n+7kiRJkrS6bIAVmLKy4JhTBnLMKY3reP3izMncfncXrr6rkmvvamCTYZMYuckS7n+kO7Pq+tOeOrbZcDL/c1YX9j28X9bxi1ZZWfCrPwzn+2cs4rA9J/HgS5WsO2weZ/7XdH5y4dBmnVb6/JNz2febi5g8r5Kt15/IvY8PpN/Ajm2QXkv1G9iRm2+exx77dWT3nWp4d1pnOnZc8UTZutocUz+sY1p1PVMn1zOlupaaGUuYM7uMj2YlPvooMXcOzJtfxrwFwcJF7VhY257axR2obejI4lxHltAB+OwmWzvq6VRWx4YDJ/PQ84M8RVmSJEmS1oANsAI2eHg5l4+t4HLg/ttquPj8+Tz1an9endSZAV1mcMoRVfzkAmd7taWK9Trz5FsV/HnMdE45tYxzfj2M66+fzI23dmGbnXuu9HE/++EkfvHbfiQ6cc7Jkzj3d8PbMLWWtdu3+vDDYyby62uHs9HgyXTtsoQFS5tX9e2pbehIfa4jS+gIdG76WrF2LKZDWT3l7esp77CYLuUN9OtVR7euie7dcqzTE3r1DHr2Dvr0bUef/u0YMKg9/Qd1YMCQjgwc0olO5R2BjjRekV2SJEmStCZsgBWJbx7Qh28e0Ie5sxt4+7W5bL2Ds72ydMgJ/dnvyBzfO3gCN94ziO2+Wsb+X53ANXcN/cSV+2qm17PnDlN45t0KBnWbzt33dWLrHYdlmFwAF18znNdfm8BjL/Wj49zFdO6wmM6dGui9Tj3dusyne/ccPXpAz55B7z5B7z5lrNMr0bd/O4ZUdGHQ0I4MGNKJrt06QDNmeUmSJEmSWpcNsCLTo2d7tt6hR9YxBHQqL+Oauyv5rxfmcei+c7jtkUr+3vcjLvxFLUee3Iv7b5vFcd/pzOz64ey17QRueXAYnbu0yzq2mvzt+crV+v3a2loAysvLWyGNJEmSJGlteBVIqZVtulV3XqseymU/n0wulXHijwax0ZBZHHBkf+oaOjDm4qmMe6rS5pckSZIkSa3EBpjURn5w9mAmTuvCt3acQNWs/nyu/1Ref7OM4/97UNbRJEmSJEkqap4CKbWhnr07cOdjlUypnsc6vfvQpcvKF1CXJEmSJEktwwaYlIFefTtkHUGSJEmSpJLhKZCSJEmSJEkqajbAJEmSJEmSVNRsgEmSJEmSJKmo2QCTJEmSJElSUbMBJkmSJEmSpKJmA0ySJEmSJElFzQaYJEmSJEmSipoNMEmSJEmSJBU1G2CSJEmSJEkqajbAJEmSJEmSVNRsgEmSJEmSJKmo2QCTJEmSJElSUbMBJkmSJEmSpKJmA0ySJEmSJElFzQaYJEmSJEmSipoNMEmSJEmSJBU1G2CSJEmSJEkqajbAJEmSJEmSVNRsgEmSJEmSJKmo2QCTJEmSJElSUbMBJkmSJEmSpKJmA0ySJEmSJElFzQaYJEmSJEmSipoNMEmSJEmSJBU1G2CSJEmSJEkqajbAJEmSJEmSVNRsgEmSJEmSJKmo2QCTJEmSJElSUbMBJkmSJEmSpKJmA0ySJEmSJElFzQaYJEmSJEmSipoNMEmSJEmSJBU1G2CSJEmSJEkqajbAJEmSJEmSVNRsgEmSJEmSJKmo2QCTJEmSJElSUbMBJkmSJEmSpKJmA0ySJEmSJElFLW8aYBHxhYi4KiJuj4jvZZ1HkiRJkiRJxaFVG2ARcU1ETI+I15fbvntEvBMR70fEGQAppbdSSt8FDgS2as1ckiRJkiRJKh3tW3n/1wGXAzcs3RAR7YArgF2BauD5iBiXUnozIvYGzmh6zCrlcjlqa2tbPHS+KYUaoXTqhNKptVTqhNKptba2lvLy8qxjSJIkSdJqadUZYCmlx4FZy23eGng/pTQ+pVQP3Azs0/T741JK2wKHrWyfEXFCRLwQES/U1NS0VnRJkiRJkiQVidaeAbYiQ4BJy9yuBr4UEV8B9gM6Afev7MEppTHAGIDRo0enUpqJUCq1lkqdUDq1lkqdUFq1SpIkSVKhyKIBFivYllJKjwKPtm0USZIkSZIkFbssrgJZDQxb5vZQYHIGOSRJkiRJklQCsmiAPQ+sHxEjIqIjcDAwLoMckiRJkiRJKgGt2gCLiD8DTwOfj4jqiDgupdQAnAw8ALwF3JpSeqM1c0iSJEmSJKl0teoaYCmlQ1ay/X4+Y6F7SZIkSZIkqaVkcQqkJElrLSImRMRrEfFyRLzQtO2AiHgjInIRsVXWGSVJ+ctxRJJKSxZXgZQkqaXsnFKauczt14H9gNEZ5ZEkFRbHEUkqETbAJElFI6X0FkBENOv3c7kctbW1rZopH5RCjUuVSq2lUieUTq2lUic01lpeXp51jBVa3XEESmMsKfb6lmWtxadU6oTSqXVNxxFPgZQkFaoE/D0iXoyIE5r7oIg4ISJeiIgXampqWjGeJCnPrdE4Ao4lklSInAEmSSpU26WUJkdEf+DBiHg7pfT4qh6UUhoDjAEYPXp0ytdZCK3BWotPqdQJpVNrqdSZJ9ZoHIHSHUtKpU6w1mJUKnVCadW6OpwBJkkqSCmlyU3fpwN3AVtnm0iSVEgcRySptNgAkyQVnIjoGhHdl/4MfJ3GhYslSVolxxFJKj02wCRJhWgA8GREvAI8B9yXUtTOzYcAACAASURBVPpbRHwrIqqBLwP3RcQDmaaUJOUrxxFJKjGuASZJKjgppfHAZivYfheNp7FIkrRSjiOSVHqcASZJkiRJkqSiZgNMkiRJkiRJRc0GmCRJkiRJkoqaDTBJkiRJkiQVNRtgkiRJkiRJKmo2wCRJkiRJklTUbIBJkiRJkiSpqNkAkyRJkiRJUlGzASZJkiRJkqSiZgNMkiRJkiRJRc0GmCRJkiRJkoqaDTBJkiRJkiQVNRtgkiRJkiRJKmo2wCRJkiRJklTUbIBJkiRJkiSpqNkAkyRJkiRJUlGzASZJkiRJkqSiZgNMkiRJkiRJRc0GmCRJkiRJkoqaDTBJkiRJkiQVNRtgkiRJkiRJKmo2wCRJkiQVpIg4ICK6N/18dkTcGRFbZp1LkpR/bIBJkiRJKlTnpJTmRcT2wG7A9cDvM84kScpDNsAkSZIkFaolTd/3AH6fUroH6JhhHklSnrIBJkmSJKlQfRgRo4EDgfsjohO+x5EkrYCDgyRJkqRCdSDwALB7Smk20Bv4UbaRJEn5qH3WASRJkiRpdURE72VuPrrMtjrghSwySZLymw0wSZIkSYXmRSABAQwHPmr6uScwERiRXTRJUj7yFEhJkiRJBSWlNCKltC6Npz/ulVLqm1LqA+wJ3JltOklSPrIBJkmSJKlQjUop3b/0Rkrpr8BOGeaRJOUpT4GUJEmSVKhmRsTZwJ9oPCXycKAm20iSpHzkDDBJkiRJheoQoB9wV9NXv6ZtkiR9gjPAJEmSJBWciGgHnJlSOjXrLJKk/OcMMEmSJEkFJ6W0BPhi1jkkSYXBGWCSJEmSCtW/ImIccBuwYOnGlJJXgpQkfYINMEmSJEmFqjeNi95/dZltCbABJkn6BBtgkiRJkgpSSumYrDNIkgqDDTBJkiRJBSkiyoHjgI2B8qXbU0rHZhZKkpSXXARfkiRJUqG6ERgI7AY8BgwF5mWaSJKUl5wBJknNtHjxYqqrq6mtrf3UfSklACKirWO1mvLycoYOHUqHDh2yjiJJ0sp8LqV0QETsk1K6PiJuAh7IOpQkKf/YAJOkZqqurqZ79+5UVlZ+qtGVy+UAKCsrjom1KSVqamqorq5mxIgRWceRJGllFjd9nx0RmwBTgcrs4kiS8lVxvFOTpDZQW1tLnz59imqW18pEBH369FnhbDdJkvLImIjoBZwDjAPeBH6VbSRJUj5yBpgkrYZSaH4tVUq1SpIKU0rpj00/Pgasm2UWSVJ+swEmSZIkqSBFxAfAM8ATwOMppTczjiRJylOeAilJBWL27NlceeWVn/k7EyZM4KabblrlviZMmMAmm2zSUtEkScrKRsBooA9wcUSMj4i7Ms4kScpDNsAkqUC0ZANMkqQisYTGhfCXADlgGjA900SSpLzkKZCSVCDOOOMMPvjgAzbffHN23XVXAP76178SEZx99tkcdNBBnHHGGbz11ltsvvnmHHXUUXzrW9/iiCOOYMGCBQBcfvnlbLvttlmWsVIRUQZ0SynNzTqLJKlgzAVeAy4B/pBSqsk4jyQpT+VVAywi9gX2APoDV6SU/p5xJElaoTE/fIDxL09bZktq+r7mC8evu/kATrh0t5Xef8EFF/D666/z8ssvc8cdd3DVVVfxyiuvMHPmTEaNGsWOO+7IBRdcwMUXX8y9994LwMKFC3nwwQcpLy/nvffe45BDDuGFF15Y44wtLSJuAr5L4yf3LwLrRMQlKaWLsk0mSSoQhwDbA98HvhMR/6RxLbCHs40lSco3rX4KZERcExHTI+L15bbvHhHvRMT7EXEGQErp7pTS8cDRwEGtnU2SCtWTTz7JIYccQrt27RgwYAA77bQTzz///Kd+b/HixRx//PFsuummHHDAAbz5Zt6tDbxR04yvfYH7geHAEdlGkiQVipTSPSmlHwEn0jiOHA3cm2koSVJeaosZYNcBlwM3LN0QEe2AK4BdgWrg+YgYt8xVW85uuv8z5XI5amtrWzxwvimFGqF06oTSqbXY6kwpkcvlAPjOJbt+4r6l28vK1u5zhaX7+az7crncJ76WzZbL5T6R85JLLqF///7861//IpfL0aVLl0887rOeb+l+l30da2trKS8vX6sal9MhIjrQ2AC7PKW0OCLSqh4kSRJARNwBbA68T+OVII8Ens00lCQpL7X6DLCU0uPArOU2bw28n1Ian1KqB24G9olGvwL+mlJ6aUX7i4gTIuKFiHihpsZT/CWVju7duzNv3jwAdthhB2699VaWLFnCjBkzeOKJJ9h6663p3r078+fP//gxc+bMYdCgQZSVlXHjjTeyZMmSrOKvzGhgAtAVeDwiKmhcz0WSpOa4ANggpbRbSum8lNJjKaXi+gROktQisloDbAgwaZnb1cCXgB8AX6NxDZjPpZSuWv6BKaUxwBiA0aNHpxaeiZDXSqXWUqkTSqfWYqkzIlY5w2ttZ4B9ln79+rHddtsxcuRIvvGNb7DZZpuxxRZbEBFceOGFDB48mH79+tG+fXu22GILjj76aE466ST2339/br/9dnbeeWe6du1KWVnZxzlXlTciWvX1SyldBly2zKaqiNi51Z5QklRs3gDOjIjhKaUTImJ94PMpJU+DlCR9QlYNsBWtEp1W8EZIkrSMm2666RO3L7rok2vFd+jQgYcf/uS6v6+++urHP//yl78EoLKyktdf/8TSjJmIiD7A/9K4gHECngTOBZziK0lqjmtpvIjK0kscVwO34TpgkqTltPopkCtRDQxb5vZQYHJGWSRJ2bkZmAHsD3y76edbMk0kSSok66WULgQWA6SUFrE2l2SWJBWtrBpgzwPrR8SIiOgIHAyMyyiLJCk7vVNKP08p/bvp6zygZ9ahJEkFoz4iOtM4i5iIWA+oyzaSJCkftXoDLCL+DDwNfD4iqiPiuJRSA3Ay8ADwFnBrSumN1s4iSco7/4iIgyOirOnrQOC+rENJkgrG/wJ/A4ZFxFjgYeD0bCNJkvJRq68BllI6ZCXb7wfub+3nlyTltROB04A/0fjpfTtgQUScRuPakD2yDCdJyl8REcDbwH7ANjSe+nhqSmlmpsEkSXmpWTPAIuLUiOgRja6OiJci4uutHU6SVNxSSt1TSmUppfYppQ5NP3dv+rL5JUlaqZRSAu5OKdWklO5LKd1r80uStDLNPQXy2JTSXODrQD/gGOCCVkslSSoJTR+sHB4R5zTdHhYRW2edS5JUMJ6JiFFZh5Ak5b/mNsCWXknlm8C1KaVX8OoqkpS3Hn30Uf75z39mHaM5rgS+DBzadHs+cEV2cSRJBWZn4OmI+CAiXo2I1yLi1axDSZLyT3MbYC9GxN9pbIA9EBHdgVzrxZIkrY01aYA1NDS0UprP9KWU0klALUBK6SOgY3MeGBETmt7ovBwRLzRt6x0RD0bEe03fe33WPl56KaishLFj17IKFb2xY6GyEsrK8JhRs3jMrNjYsbDBBh2JaLH3Et8A1gO+CuwF7Nn0fZVaYhwBeGnqS1ReWsnY13yRtXJjXxtL5aWVlP1fmceLmsVjZsXGvjaWDX6/AfF/sdrjSHMbYMcBZwCjUkoLgQ40ngYpSWpD++67L1/84hfZeOONGTNmDAB/+9vf2HLLLdlss83YZZddmDBhAldddRW/+c1v2HzzzXniiSeoqqpil112YeTIkeyyyy5MnDgRgKOPPprTTjuNnXfemR//+MdZlLQ4Itrxn8vX92P1PmDZOaW0eUppq6bbZwAPp5TWp/FKYGesagdVVXDCCb451cqNHdt4jFRVQUoeM1o1j5kVW/p3mTSpDFrobJKUUtWKvlZjF2s9jgBUzanihL+c4BtUrdDY18Zywl9OoGpOFYnk8aJV8phZsaV/l0lzJ8EajCPNvQrkl4GXU0oLIuJwYEvgt6v7ZJJULH74tx/y8tSXW3Sfmw/cnEt3v/Qzf+eaa66hd+/eLFq0iFGjRrHPPvtw/PHH8/jjjzNixAhmzZpF7969+e53v0u3bt34n//5HwD22msvjjzySI466iiuueYaTjnlFO6++24A3n33XR566CHatWvXovU002XAXUD/iDgf+DZwzlrsbx/gK00/Xw88Cqyys7dwIRx3XGL06LQWT52/crnG4b6srPgnb7dGrc89F9TVffLfWFkfM76m+W1NjplCrHN1rejvkofWaBwBWLh4Icfdcxyjnx/dOskylMs1HpdlZc2dP1G4WqPW5yY/R92Suk9sy4fjpVRe10Ksc02PmUKsdXWs6O+yOprbAPs9sFlEbAacDlwN3ADstMbPLElabZdddhl33XUXAJMmTWLMmDHsuOOOjBgxAoDevXuv8HFPP/00d955JwBHHHEEp59++sf3HXDAAVk1v0gpjY2IF4FdaPwUZ9+U0lvNfTjw94hIwOiU0hhgQEppStO+p0RE/+UfFBEnACcAnHDCf/4BUVcH9fVrVU7eavq3EEX6b6FPaI1a61by76wsjxlf0/y2JsdMIda5ulb2d1kTEdEppbS2e1yjcaTp+f8zlvzshI+31y2po35J8Q0mH7+pTkV8gDZpjVpX9oY96+OlVF7XQqxzTY+ZQqx1daxN8wua3wBrSCmliNgH+G1K6eqIOGqtnlmSCtjyM7Xa4tOWRx99lIceeoinn36aLl268JWvfIXNNtuMd955Z7X3FfGfT+C7du3akjFXN8eNKaUjgLdXsG1VtkspTW56c/JgRLy9ykcATW9wxgCceOKYj6diVFQEzzyT9zMT1khtbeM/lMrLyzNO0vpao9bKysZT2JaX5THja5rf1uSYKcQ6V9fK/i5r6Glgy9UYM1ZkjcYRWG4s+b8T/zOWrFPBM8c/s4Zx8ldtbS1Q3MfnUq1Ra+WllVTN+fTBn/XxUiqvayHWuabHTCHWujpW9ndprua+U5sXEWcCRwD3Na3X0mGNn1WStNrmzJlDr1696NKlC2+//TbPPPMMdXV1PPbYY/z73/8GYNasWQB0796defPmffzYbbfdlptvvhmAsWPHsv3227d9ASu28bI3msaXLzbngSmlyU3fp9N4GuXWwLSIGNS0r0HA9Obsq0sXOP/81UitknL++Y3HyLI8ZvRZPGZWbEV/l7XQsekD+W0jYr/lv5qzg5YcRwC6dOjC+buU+IusFTp/l/Pp0uGTB7/Hiz6Lx8yKrejvsjqa2wA7CKgDjk0pTQWGABet8bNKklbb7rvvTkNDAyNHjuScc85hm222oV+/fowZM4b99tuPzTbbjIMOOghoXPPrrrvu+ngR/Msuu4xrr72WkSNHcuONN/Lb32a7jGNEnBkR84CRETG36WsejW807mnG47s2XZGYiOgKfB14HRgHLJ2hfFRz9lVRAWPGwGGHrWExKnqHHdZ4jFRUQITHjFbNY2bFlv5dhg3LQdPFT9bCd4FtgJ40XvVx2a89V/XglhxHoHFWxpi9xnDYpiX+ImuFDtv0MMbsNYaKdSoIwuNFq+Qxs2JL/y7DegyDNRhHIqXmPSYiBgCjmm4+1/RJSaZGjx6dTjzxxKxjtLpin8a4VKnUCaVTa7HV+dZbb/GFL3xhhfcV64KTy9dcW1tLeXl5i53zFRG/TCmduQaPW5fGT+uh8XT+m1JK50dEH+BWYDgwETggpTRrZftxHCk+pVJrqdQJpVNrqdQJLTuWRMRxKaWr1+BxLTKOQGmMJaV2fIK1FpNSqRNKp9Y1HUeatQZYRBxI44yvR2lcpPh3EfGjlNLtq/uEkiQt496I6Lr8VYZXdQn7lNJ4YLMVbK+hcUF9SVJpuDEiTgF2bLr9GHBVSmnxZz3IcUSSSk9zF8E/Cxi1dNZXRPQDHgJsgEmS1oZXGZYkrY0raVyb+Mqm20fQOLZ8J7NEkqS81NwGWNlypzzW0Pz1wyRJWhmvMixJWhujUkrLzuR6JCJeySyNJClvNbcB9reIeAD4c9Ptg4D7WyeSJKmELL3K8OHAjl5lWJK0mpZExHoppQ/g47W9lmScSZKUh5rVAEsp/Sgi9ge2o3ENsDEppbtW8TBJklblIOBQ4LiU0tSIGI5XGZYkNd+PgH9ExHga36dUAMdkG0mSlI+aOwOMlNIdwB2tmEWSVGJSSlOBS5a5PZHGNcAkSVqllNLDEbE+8HkaG2Bvp5TqMo4lScpDn7mOV0TMi4i5K/iaFxFz2yqkJKl5xo0bxwUXXADA3XffzZtvvvnxfT/96U956KGHsoomSVKrSCnVpZReTSm9YvNLkrQynzkDLKXUva2CSJLWTkNDA3vvvTd777030NgA23PPPdloo40AOPfcc7OMJ0mSJEmZafYpkJKk7N1www1cfPHFRAQjR46kXbt29O7dm3/9619sueWWbLrpprzwwgsceuihjBs3jscee4zzzjuPO+64g5///OfsueeefPvb3+b555/n1FNPZcGCBXTq1ImHH36Y7t3b7jOPiBiUUpoSEV2B9YAGYHxKqbbNQkiSJEkqGTbAJGkN/PCH8PLLy26Jtd7n5pvDpZeu/P433niD888/n6eeeoq+ffsya9YsTjvtNN59910eeugh2rVrx3XXXQfAtttuy9577/1xw2tZ9fX1HHTQQdxyyy2MGjWKuXPn0rlz57XO31wR0Rm4PCIWA7sA/6bxyo9DI+Jq4OyUUkObBZIkFbSIGAlUssx7m5TSnZkFkiTlJRtgklQgHnnkEb797W/Tt29fAHr37g3AAQccQLt27Zq9n3feeYdBgwYxatQoAHr06NHyYT9DSmlRREwCdgeuSSn9GCAi1gF+DVwInNamoSRJBSkirgFGAm8AuabNCbABJkn6BBtgkrQGlp+plcslAMrK1n4m2MqklIj49P67du3aIvtpY7sBmwFHRcStwDEppTkRcSLwNjbAJEnNs01KaaOsQ0iS8t9nXgVSkpQ/dtllF2699VZqamoAmDVr1mf+fvfu3Zk3b96ntm+44YZMnjyZ559/HoB58+bR0NDmZxxG01W7xgCXAHdHxPoppSWA64BJkprr6YiwASZJWiVngElSgdh4440566yz2GmnnWjXrh1bbLHFZ/7+wQcfzPHHH89ll13G7bff/vH2jh07csstt/CDH/yARYsW0blzZx566CG6devW2iUs682IODSldFNK6ZmIOAz4Q0SMB95ryyCSpIJ2PY1NsKlAHY2LcqaU0shsY0mS8o0NMEkqIEcddRRHHXXUSu8/+uijOfroowHYbrvtePPNNz++b+kC+QCjRo3imWeeaa2YzXEycFdEHA+8BCwGegL7AXdkGUySVFCuAY4AXuM/a4BJkvQpNsAkSW0upTQZ+FJEfBXYGGgHnJdSejAi9oiITimlumxTSpIKwMSU0risQ0iS8p8NMElSZlJKjwCPLLftvoziSJIKz9sRcRPwFxpPgQQgpeRVICVJn2ADTJJWQ55cQbFNpJSyjiBJ0qp0prHx9fVltiXABpgk6RNsgElSM5WXl1NTU0OfPn2KvgmWUqKmpoby8vKso0iStFIppWOyziBJKgw2wCSpmYYOHUp1dTUzZsz41H1LZ0sVU2OsvLycoUOHZh1DkqSViohraZzx9QkppWMziCNJymM2wCSpmTp06MCIESNWeF9tbS2AM6YkSWpb9y7zcznwLWByRlkkSXnMBpgkSZKkgpRSumPZ2xHxZ+ChjOJIkvJYWdYBJEmSJKmFrA8MzzqEJCn/OANMkiRJUkGKiHl8cg2wqcCPM4ojScpjNsAkSZIkFaSUUvesM0iSCoOnQEqSJEkqSBGxXUR0bfr58Ii4JCIqss4lSco/NsAkSZIkFarfAwsjYjPgdKAKuCHbSJKkfGQDTJIkSVKhakgpJWAf4Lcppd8CnhYpSfoU1wCTJEmSVKjmRcSZwOHAjhHRDuiQcSZJUh5yBpgkSZKkQnUQUAccl1KaCgwBLso2kiQpHzkDTJIkSVJBamp6XbLM7Ym4BpgkaQWcASZJkiRJkqSiZgNMkiRJkiRJRc0GmCRJkqSCEhGDmr53jYiREbFRRJRnnUuSlL9cA0ySJElSwYiIzsDlEbEY2AX4N41XfhwaEVcDZ6eUGrLMKEnKP84AkyRJklQwUkqLgEnA5sA1KaWtU0pbAJ8D+gIXZplPkpSfbIBJkiRJKjS7AZsBH0TErRHRNaU0BzgR2CvbaJKkfGQDTJIkSVKhiZRSXUppDHAJcHdErJ9SWgLUZpxNkpSHbIBJkiRJKjRvRsShACmlZ4DDgIsj4jfAe5kmkyTlJRfBlyRJklRoTgbuiojjgZeAxUBPYD/gjiyDSZLykw0wSZIkSQUlpTQZ+FJEfBXYGGgHnJdSejAi9oiITimlumxTSpLyiQ0wSZIkSQUppfQI8Mhy2+7LKI4kKY+5BpgkSZIkSZKKmg0wSZIkSZIkFTUbYJIkSZIkSSpqedMAi4h1I+LqiLg96yySJEmSJEkqHq3aAIuIayJiekS8vtz23SPinYh4PyLOAEgpjU8pHdeaeSRJkiRJklR6WvsqkNcBlwM3LN0QEe2AK4BdgWrg+YgYl1J6c3V3nsvlqK2tbaGo+asUaoTSqRNKp9ZSqRNKp9ba2lrKy8uzjiFJkiRJq6VVZ4CllB4HZi23eWvg/aYZX/XAzcA+zd1nRJwQES9ExP+3d/9Btt51fcDfn/11b+69iSiQTiQI2EbqiBqFxGlRSi0yFCio44+gjKIMKJUWdKqVDoJAGVSwQxxEbooULAhS0RprpsFRU6RlNAGBAFFkGCzXUCKXNrkbsnez93z7xzm72Xuze39l95493+f1mtk5z/M953n2+7nP2f3cfe/3nL3l6NGjOzhbAAAAAHq02yvAtvKwJJ/dtH8kybdU1YOTvDrJN1XVS1prr9nq4NbadUmuS5LDhw+3Ia1EGEqtQ6kzGU6tQ6kzGVatAAAAs2IaAVhtMdZaa0eT/PiFngwAAAAAfZvGX4E8kuThm/YvT3L7FOYBAAAAwABMIwC7OckVVfWoqlpKck2S66cwDwAAAAAGYFcDsKp6Z5IPJHl0VR2pque21taSvDDJjUluS/Lu1trHd3MeAAAAAAzXrr4HWGvtWduM35Dkht383AAAAACQTOclkAAAAABwwQjAAAAAAOiaAAwAAACArgnAAAAAAOiaAAwAAACArgnAAAAAAOiaAAyAmVRV81X1F1X13yb731hVH6iqW6vq96vqkmnPEYC9TS8BGA4BGACz6kVJbtu0/+YkP9ta+/okv5vkp6cyKwBmiV4CMBAL054AAJyrqro8ydOSvDrJT02GH53kfZPtP0xyY5KfO915RqNRVlZWdmuae8YQalw3lFqHUmcynFqHUmcyrnX//v3TnoZecg56r28ztfZnKHUmw6n1fPuIFWAAzKLXJ/mZJKNNYx9L8ozJ9vcmefhWB1bV86vqlqq65ejRo7s7SwD2Mr0EYECsAANgplTV05Pc0Vr7YFU9cdNdP5rkV6rqZUmuT7K61fGtteuSXJckhw8fbnthFcKFotb+DKXOZDi1DqXOadNLzs9Q6kzU2qOh1JkMq9ZzIQADYNY8PskzquqpSfYnuaSq3t5ae3aSJydJVX1Nxi9rAYCt6CUAA+MlkADMlNbaS1prl7fWHpnkmiR/3Fp7dlVdmiRVNZfkpUneNMVpArCH6SUAwyMAA6AXz6qqTyb5yyS3J/lPU54PALNHLwHolJdAAjCzWms3Jblpsn1tkmunOR8AZo9eAjAMVoABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdE4ABAAAA0DUBGAAAAABdW5j2BNZV1cEkb0yymuSm1to7pjwlAAAAADqwqyvAquotVXVHVX3slPGnVNVfVdWnqupnJ8PfneS3W2vPS/KM3ZwXAAAAAMOx2yvA3prkDUl+Y32gquaT/GqS70hyJMnNVXV9ksuT3Dp52ImzOfloNMrKyspOzndPGkKNyXDqTIZT61DqTIZT68rKSvbv3z/taSTZ6Ce3JPnb1trTq+rKJG9Ksj/JWpJ/2Vr782nOEYC9TS8BGI5dXQHWWntfki+eMnx1kk+11j7dWltN8q4kz8w4DLv8TPOqqudX1S1VdcvRo0d3Y9oAzIYXJblt0/4vJXlFa+3KJC+b7APA6eglAAMxjfcAe1iSz27aP5LkW5L8SpI3VNXTkvz+dge31q5Lcl2SHD58uO2VlQgXwlBqHUqdyXBqHUqdybBqnaaqujzJ05K8OslPTYZbkksm21+W5PYzncdK4v4Mpdah1JkMp9ah1JnsndXEesnZ672+zdTan6HUmQyn1vPtI9P4K5C1xVhrrd3dWvuR1toLvAE+AGfw+iQ/k2S0aezFSV5bVZ9N8rokL9nqQCuJAZjQSwAGZBorwI4kefim/ctzFr9ZAYAkqaqnJ7mjtfbBqnriprtekOQnW2vvqarvS/LrSZ506vFWEg/DUGodSp3JcGodSp3Tppecn6HUmai1R0OpMxlWrediGgHYzUmuGUPrIAAAEbNJREFUqKpHJfnbJNck+YEpzAOA2fT4JM+oqqdm/CbFl1TV25P8i4zfyyVJ/kuSN09pfgDsfXoJwMDs6ksgq+qdST6Q5NFVdaSqnttaW0vywiQ3ZvyGk+9urX18N+cBQD9aay9prV3eWntkxr9E+ePW2rMzXk38TyYP+/Ykfz2lKQKwx+klAMOzqyvAWmvP2mb8hiQ37ObnBmBwnpfk2qpaSLKS5PlTng8As0cvAejUNF4CCQA7orV2U5KbJtvvT/LYac4HgNmjlwAMwzT+CiQAAAAAXDACMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsCMAAAAAC6JgADAAAAoGsL054AO6u1lpaWuZJt7kVro7Usry7n6LGjWZpfykPmH5L9C/tTVdOeGntUay3HTxxPa81zBQAA4DwJwHbAF770hRz90tGsnljN6onVHD9x/L7tteOnHd/ysaOTj7tn9Z6sjlaz1tbOeL7VE6tpaVmcW8z+hf0bHxctXnTS/v0+5s/iMQv7c9HCmR+zNL/UxQ/prbXcs3ZPlleXc+z4sfHt6rGz299mfGVt5X6fZ67mcmjpUC5eujiHlg5tfFy8b7K/uMXY+v4px6w/Zt/8vi6uwV4xaqMcXzuelbWVrKyt5J61eza21z/u/NKdWVlbyahG2z7mnnsnYye2GDvNudfN13wu3ndxLtl3SS5emtyeur/d+Cn7wjQAAGBI9kwAVlVPSXJtkvkkb26t/cKUp3TWXv4nL88bb3njeR+/MLeQffP7sjS/lKX5pexbGG+vjy3UQvYt7MuBxQN50P4HnfzYyfb6MUvzS5mv+Rw/cfy+H65PrNzvB+q7jt+VO+6+Y8sfwI+fOP6A/j0qtRGG7VvYl4W5hSzMLWS+5u/bnpu/31ilslALWVpc2hhff9zmx251npPu32JsYW4hczWXu++9+5wCq1EbnfU1vHjp4o2Aaj2YuvTgpSftr98u1VLuHd2bldFKlleXNz7WP+/y6nJuP3b7SXNaXl1OSzur+czX/NZh2jbB2eLc4vjaVaVSG7cPdGxtbS2VytLS0lkfO2qjrI3Wcu+Je7M2Whtvj+7bPt19G+PtLB93hvtWT6zuyNfEXM1thMdbBc2Hlg7lIQcesm3QfNHiRUmS5dXl3HX8rhxbPTa+PX4sd67cmSN3Hcldx+/aGDub58l8zW8flC1tH6Dtr/150hVPekD/HgAAABfangjAqmo+ya8m+Y4kR5LcXFXXt9Y+cbrjRqNRVlbuv6LmQrvma6/JVZddlaW5SRA1t7QRRm2EU6eMrYdXi/OLZ3y54nqN+/fvvxDlZNRGGz/4r//wvzlI21gJs2l/fdXKevC2fv/xteNZG63lRDsxvh2d2AgoRqPRSfetrq1mpa1ktDrKidGJk4+ZBBrr2+vHbj5+fftsHFw8eF8ANFlh9eD9D84jLnnESSuuNgdGBxcPjm+XDp4cIC0eyr6Ffef0b3w+13R9Rdqx1WO5e/XuLN87DsXuXr17PDYJ99bH1+9bvve+xxy558jGY+5evfucQrW9Zq7mNsLNxbnFk0LPxfnJfi1sbM/PzW88bnFuMRfNX5TF+cVxYLrpcQs1Oedkfz2M2rew775gav6U/YX9qROVffP78qCDD8q+hX0nraxcmLtw32pba7n73vH1Pnb82Ph2/WOyf9fqXSeFaev3Hf3S0Xzm/35mY2y750d7+Ww+ZwAAgOHaEwFYkquTfKq19ukkqap3JXlmkvsFYFX1/CTPT5JXvepVF3KO27rqK6/KVV951bSnsWPmam7jh/oLaSeCvtZaRm10v1BsbbSWURvlwMKBHFg8kPm5+Z2a9gVTVTmwOJ5/Du7MOUdtlHvuvSdrbW3j/ePWb5Oc+9hkfN3KykpaWpaWlsaP23Tc+uNOHdu8gu/Uj81B1157n7sLHVRvp6o2wtnLDl32gM41aqON8HT94+ixozs0UwAAgAtnrwRgD0vy2U37R5J8y1YPbK1dl+S6JDl8+HCb9g+bF9JQah1KncneqPXARQd27dx7JRS6kHqr9cBFB/LQPHRjfy+sugUAADhXe2UJxVbvxOw1NgAAAAA8YHslADuS5OGb9i9PcvuU5gIAAABAR/ZKAHZzkiuq6lFVtZTkmiTXT3lOAAAAAHRgT7wHWGttrapemOTGJPNJ3tJa+/iUpwUAAABAB/ZEAJYkrbUbktww7XkAAAAA0Je98hJIAAAAANgVAjAAAAAAuiYAAwAAAKBrAjAAAAAAuiYAAwAAAKBrAjAAAAAAuiYAAwAAAKBrAjAAAAAAuiYAAwAAAKBrAjAAAAAAulattWnP4by99KUvPba4uPhX057HhbC8vPyQQ4cOfWHa89htQ6kzGU6tQ6kzGU6tX/ziF/dfe+21j5n2PHaCPtKnodQ6lDqT4dQ6lDoTvWQWDen5qdb+DKXOZDi1nk8fmekArKpuaa09btrzuBCGUutQ6kyGU+tQ6kyGU2tPdfZUy5motT9DqTMZTq1DqTPpq9aeajmdodSZqLVHQ6kzGU6t51Onl0ACAAAA0DUBGAAAAABdm/UA7LppT+ACGkqtQ6kzGU6tQ6kzGU6tPdXZUy1notb+DKXOZDi1DqXOpK9ae6rldIZSZ6LWHg2lzmQ4tZ5znTP9HmAAAAAAcCazvgIMAAAAAE5LAAYAAABA12YyAKuqp1TVX1XVp6rqZ6c9n91UVZ+pqlur6sNVdcu057OTquotVXVHVX1s09hXVNUfVtVfT26/fJpz3Anb1PnzVfW3k+v64ap66jTnuFOq6uFV9SdVdVtVfbyqXjQZ7+q6nqbO7q5rVe2vqj+vqo9Man3FZHzmr6leMvuG0keS4fSSofSRZDi9RB/pQ699JBlOLxlKH0mG00uG0keSneslM/ceYFU1n+STSb4jyZEkNyd5VmvtE1Od2C6pqs8keVxr7QvTnstOq6onJFlO8huttcdMxn4pyRdba78w+Y/El7fW/u005/lAbVPnzydZbq29bppz22lVdVmSy1prH6qqi5N8MMl3JnlOOrqup6nz+9LZda2qSnKwtbZcVYtJ3p/kRUm+OzN8TfWSPgyljyTD6SVD6SPJcHqJPtKHXvtIMpxeMpQ+kgynlwyljyQ710tmcQXY1Uk+1Vr7dGttNcm7kjxzynPiPLTW3pfki6cMPzPJ2ybbb8v4C3imbVNnl1prn2utfWiyfSzJbUkels6u62nq7E4bW57sLk4+Wmb/muolHRhKH0mG00uG0keS4fQSfYS9bii9ZCh9JBlOLxlKH0l2rpfMYgD2sCSf3bR/JJ1e5ImW5L1V9cGqev60J3MB/L3W2ueS8Rd0kkunPJ/d9MKq+uhkOfJML7/dSlU9Msk3JfmzdHxdT6kz6fC6VtV8VX04yR1J/rC11sM11Uv6NevPzXPV3fecdUPpI0n/vUQf6cKQ+kgy+8/Pc9HV95tTDaWX9N5Hkp3pJbMYgNUWY7P1Os5z8/jW2jcn+edJfmKydJXZ92tJ/n6SK5N8LskvT3c6O6uqDiV5T5IXt9bumvZ8dssWdXZ5XVtrJ1prVya5PMnVVfWYac9pB+gl9KDL7znJcPpIMoxeoo90QR/pU3ffbzYbSi8ZQh9JdqaXzGIAdiTJwzftX57k9inNZde11m6f3N6R5HczXm7ds89PXsu8/prmO6Y8n13RWvv85At4lOQ/pqPrOnlN9nuSvKO19juT4e6u61Z19nxdk6S19v+S3JTkKZn9a6qX9GvWn5tnrdfvOUPpI8nweok+MrsG1keS2X9+npWev98MpZcMrY8kD6yXzGIAdnOSK6rqUVW1lOSaJNdPeU67oqoOTt7MLlV1MMmTk3zs9EfNvOuT/PBk+4eT/N4U57Jr1r9IJ74rnVzXyZsT/nqS21pr/2HTXV1d1+3q7PG6VtVDq+pBk+2LkjwpyV9m9q+pXtKvWX9unrVOv+cMoo8kw+kl+sjsG2AfSWb/+XlWevt+s24ovWQofSTZuV4yc38FMklq/Gc8X59kPslbWmuvnvKUdkVVfXXGv2FJkoUkv9lTrVX1ziRPTPKQJJ9P8vIk/zXJu5N8VZL/neR7W2sz/WaN29T5xIyXpLYkn0nyY+uvXZ5lVfWtSf40ya1JRpPhf5fxa9G7ua6nqfNZ6ey6VtU3ZPyGkvMZ/9Lk3a21V1bVgzPj11QvmX1D6SPJcHrJUPpIMpxeoo/Mvp77SDKcXjKUPpIMp5cMpY8kO9dLZjIAAwAAAICzNYsvgQQAAACAsyYAAwAAAKBrAjAAAAAAuiYAAwAAAKBrAjAAAAAAuiYAgyRV9cqqetIOnGd5B87xnKr6yvM47ser6oce6OefnOutVfU9O3EugKHQS+53Lr0E4BzoI/c7lz7CjlqY9gRgL2itvWzac9jkOUk+luT2U++oqvnW2omtDmqtvWmX5wXAaeglADwQ+gjsLivA6FJVPbuq/ryqPlxVh6tqfjK+XFW/XFUfqqo/qqqHTsY3frtQVb9QVZ+oqo9W1esmY4+YPP6jk9uvmow/qqo+UFU3V9WrTpnDT0/GP1pVr5iMHayqP6iqj1TVx6rq+0855nuSPC7JOyZzv6iqPlNVL6uq9yf53qp63uS8H6mq91TVgcmxP19V/2ayfVNV/eLk3+CTVfVtk/H5qnrtpnn92GS8quoNk7r/IMmlu3NlAGaHXqKXADwQ+og+wt4iAKM7VfW1Sb4/yeNba1cmOZHkByd3H0zyodbaNyf5H0lefsqxX5Hku5J8XWvtG5L8+8ldb0jyG5OxdyT5lcn4tUl+rbV2VZL/s+k8T05yRZKrk1yZ5LFV9YQkT0lye2vtG1trj0ny3zd//tbabye5JckPttaubK3dM7lrpbX2ra21dyX5ndbaVa21b0xyW5LnbvNPsdBauzrJizfV+dwkd07me1WS51XVoyY1PzrJ1yd5XpJ/vM05AQZBL9mglwCcB31kgz7CniEAo0f/LMljk9xcVR+e7H/15L5Rkt+abL89ybeecuxdSVaSvLmqvjvJlybj/yjJb062//Om4x6f5J2bxtc9efLxF0k+lOQfZtx8bk3ypMlvQr6ttXbnWdb0W5u2H1NVf1pVt2bcRL9um2N+Z3L7wSSP3DSvH5r8u/xZkgdP5vWEJO9srZ1ord2e5I/Pcl4AvdJLxvQSgPOjj4zpI+wZ3gOMHlWSt7XWXnIWj20n7bS2VlVXZ9ygrknywiTffobj2hb3V5LXtNYO3++OqscmeWqS11TVe1trrzyLed69afutSb6ztfaRqnpOkiduc8zxye2J3Pe1Xkn+VWvtxlPm9NRt6gAYKr1kTC8BOD/6yJg+wp5hBRg9+qMk31NVlybjJcRV9YjJfXNJ1v+SyA8kef/mA6vqUJIva63dkPEy3Ssnd/2vjJtPMv4Nx/px//OU8XU3JvnRyflSVQ+rqktr/JdUvtRae3uS1yX55i3mfyzJxaep7+Ikn6uqxVM+59m4MckLJsemqr6mqg4meV+Sayavx78syT89x/MC9EYv2Z5eAnBm+sj29BGmwgowutNa+0RVvTTJe6tqLsm9SX4iyd9k/FuLr6uqDya5M+PX5W92cZLfq6r9Gf9m4icn4/86yVuq6qeT/F2SH5mMvyjJb1bVi5K8Z9Mc3jt53f8HqipJlpM8O8k/SPLaqhpN5vWCLUp4a5I3VdU9GS9zPtXPZbxU+G8yXr58usZ0qjdnvPT4QzWe2N8l+c4kv5vxb5VuTfLJjN+LAGCw9JLT0ksAzkAfOS19hKmo1qwwZDiqarm1dmja8wBgduklADwQ+ghMh5dAAgAAANA1K8AAAAAA6JoVYAAAAAB0TQAGAAAAQNcEYAAAAAB0TQAGAAAAQNcEYAAAAAB07f8DvDI2/Hw9FjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1224x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<easyagents.core.PpoTrainContext at 0x2124f0b7d88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, plot\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([plot.Clear(on_train=False,on_play=False), duration.Fast()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If your plot gets \"doubled\" after cell evaluation set on_train / on_play to True, if it disappears to False. \n",
    "Once plot.Clear() is called, the behaviour stays the same across a upcoming plots."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zpzHtN3-kQ26",
    "w3OdHyWEEEwy",
    "bzoq0VM85p46"
   ],
   "include_colab_link": true,
   "name": "easyagents_logging.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}